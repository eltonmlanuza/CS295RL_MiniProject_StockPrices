{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vo2Bg6NX7bsl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Installing FinRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ANr4K_h41A6",
    "outputId": "cb0a5d95-5e7e-4e31-966a-2f65385c67a4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
      "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-vaymlkl8\n",
      "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-vaymlkl8\n",
      "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
      "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-5geh3nz9/pyfolio_1a413da7a2c148918974ed2cdab0ad73\n",
      "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-5geh3nz9/pyfolio_1a413da7a2c148918974ed2cdab0ad73\n",
      "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
      "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-5geh3nz9/elegantrl_b4e3f18c8381491399f18bbb569a69b4\n",
      "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-5geh3nz9/elegantrl_b4e3f18c8381491399f18bbb569a69b4\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.21.6)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.3.5)\n",
      "Requirement already satisfied: stockstats>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (0.4.1)\n",
      "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (0.1.70)\n",
      "Requirement already satisfied: elegantrl in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (0.3.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.0.2)\n",
      "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (0.21.0)\n",
      "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.5.0)\n",
      "Requirement already satisfied: ray[default] in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.12.1)\n",
      "Requirement already satisfied: lz4 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (4.0.1)\n",
      "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (2.5)\n",
      "Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.4.0)\n",
      "Requirement already satisfied: exchange_calendars in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (3.6.3)\n",
      "Requirement already satisfied: alpaca_trade_api in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (2.1.0)\n",
      "Requirement already satisfied: ccxt==1.66.32 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.66.32)\n",
      "Requirement already satisfied: jqdatasdk in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.8.10)\n",
      "Requirement already satisfied: wrds in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (3.1.1)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (3.6.4)\n",
      "Requirement already satisfied: setuptools==59.5.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (59.5.0)\n",
      "Requirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (0.37.1)\n",
      "Requirement already satisfied: pre-commit in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (2.19.0)\n",
      "Requirement already satisfied: pybullet in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.5) (3.2.5)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.5) (1.11.0+cu113)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.5) (4.1.2.30)\n",
      "Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.5) (2.3.8)\n",
      "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.5.0)\n",
      "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2022.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.4.1)\n",
      "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.11.2)\n",
      "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.5.5)\n",
      "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (2.27.1)\n",
      "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (37.0.2)\n",
      "Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (3.0.0)\n",
      "Requirement already satisfied: yarl==1.7.2 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (1.7.2)\n",
      "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (2022.5.18.1)\n",
      "Requirement already satisfied: aiohttp>=3.8 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (3.8.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl==1.7.2->ccxt==1.66.32->finrl==0.3.5) (2.10)\n",
      "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.7/dist-packages (from yarl==1.7.2->ccxt==1.66.32->finrl==0.3.5) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl==1.7.2->ccxt==1.66.32->finrl==0.3.5) (4.2.0)\n",
      "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from aiodns>=1.1.1->ccxt==1.66.32->finrl==0.3.5) (4.1.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (1.2.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (0.13.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (2.0.12)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt==1.66.32->finrl==0.3.5) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt==1.66.32->finrl==0.3.5) (2.21)\n",
      "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.9.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.5) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.5) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.1->gym>=0.17->finrl==0.3.5) (3.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.1.1)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.4.2)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.0.18)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.5)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.6.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (3.0.9)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.9.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.5)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->ccxt==1.66.32->finrl==0.3.5) (1.24.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (3.1.0)\n",
      "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.5) (1.3.2)\n",
      "Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.5) (2.1.0)\n",
      "Requirement already satisfied: websockets<11,>=9.0 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.5) (10.3)\n",
      "Requirement already satisfied: msgpack==1.0.3 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.5) (1.0.3)\n",
      "Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api->finrl==0.3.5) (6.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation==2.1.0->alpaca_trade_api->finrl==0.3.5) (21.3)\n",
      "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.5) (0.2.1)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.5) (0.11.2)\n",
      "Requirement already satisfied: pyluach in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.5) (2.0.0)\n",
      "Requirement already satisfied: thriftpy2>=0.3.9 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.5) (0.4.14)\n",
      "Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.5) (1.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.5) (1.4.36)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.5) (1.1.2)\n",
      "Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.7/dist-packages (from thriftpy2>=0.3.9->jqdatasdk->finrl==0.3.5) (3.11)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.0)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.5) (1.6.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.5) (0.10.2)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.5) (3.3.1)\n",
      "Requirement already satisfied: virtualenv>=20.0.8 in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.5) (20.14.1)\n",
      "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.5) (2.5.1)\n",
      "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.5) (3.7.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.5) (0.3.4)\n",
      "Requirement already satisfied: platformdirs<3,>=2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.5) (2.5.2)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (0.7.1)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (8.13.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (1.4.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (1.11.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (7.1.2)\n",
      "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (1.43.0)\n",
      "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (3.17.3)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (4.3.3)\n",
      "Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (0.9.0)\n",
      "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (0.7.0)\n",
      "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (6.0.0)\n",
      "Requirement already satisfied: gpustat>=1.0.0b1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (1.0.0b1)\n",
      "Requirement already satisfied: prometheus-client<0.14.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (0.13.1)\n",
      "Requirement already satisfied: colorful in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (0.5.4)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (0.3.12)\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.5) (7.352.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.5) (5.4.8)\n",
      "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.5) (1.19.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]->finrl==0.3.5) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]->finrl==0.3.5) (5.7.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.5) (1.31.6)\n",
      "Requirement already satisfied: opencensus-context>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.5) (0.1.2)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (1.56.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (4.2.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (0.4.8)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (0.8.9)\n",
      "Requirement already satisfied: ale-py~=0.7.4 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.5) (0.7.5)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.5) (7.1.2)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.5) (0.4.2)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.5) (2.8.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->finrl==0.3.5) (4.64.0)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->finrl==0.3.5) (0.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (3.3.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (3.2.0)\n",
      "Requirement already satisfied: mock in /usr/local/lib/python3.7/dist-packages (from wrds->finrl==0.3.5) (4.0.3)\n",
      "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.7/dist-packages (from wrds->finrl==0.3.5) (2.9.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.5) (0.0.10)\n"
     ]
    }
   ],
   "source": [
    "## install finrl library\n",
    "%pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mqFItfM7j_L",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Making required directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TlAckkf3auKm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxra2-727tFC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mLxDO5EgksO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "#from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.finrl_meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTwlIwWBqa65",
    "outputId": "a616db25-7a84-45eb-87b8-b5ba7a721361",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2241TB27xAU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Reading stock prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEymi_7mcgHJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/stocks_dataset/stock_prices.csv')\n",
    "\n",
    "df_2 = df.loc[df['SecuritiesCode'].isin([1301, 1332, 1333, 1376, 1377, 1379, 1381, 1407, 1414, 1417])] # Security codes represents stock name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "7gTERj3XpDxy",
    "outputId": "6b20606c-c14b-4140-f6fa-301842f5dd65",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-892535c4-8e1e-48e1-b3c1-a69bca007e65\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>Date</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>ExpectedDividend</th>\n",
       "      <th>SupervisionFlag</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20170104_1301</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1301</td>\n",
       "      <td>2734.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>31400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170104_1332</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1332</td>\n",
       "      <td>568.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2798500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.012324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20170104_1333</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1333</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>270800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20170104_1376</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1376</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>11300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20170104_1377</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1377</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>150800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330537</th>\n",
       "      <td>20211203_1379</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>1379</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>1893.0</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>1891.0</td>\n",
       "      <td>27400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330538</th>\n",
       "      <td>20211203_1381</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>1381</td>\n",
       "      <td>3125.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3125.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330539</th>\n",
       "      <td>20211203_1407</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>1407</td>\n",
       "      <td>6030.0</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>5900.0</td>\n",
       "      <td>6190.0</td>\n",
       "      <td>355900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330541</th>\n",
       "      <td>20211203_1414</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>1414</td>\n",
       "      <td>4990.0</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>4965.0</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>198100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.015810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330542</th>\n",
       "      <td>20211203_1417</td>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>1417</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>133500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.015570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12020 rows × 12 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-892535c4-8e1e-48e1-b3c1-a69bca007e65')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-892535c4-8e1e-48e1-b3c1-a69bca007e65 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-892535c4-8e1e-48e1-b3c1-a69bca007e65');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                 RowId        Date  SecuritiesCode    Open    High     Low  \\\n",
       "0        20170104_1301  2017-01-04            1301  2734.0  2755.0  2730.0   \n",
       "1        20170104_1332  2017-01-04            1332   568.0   576.0   563.0   \n",
       "2        20170104_1333  2017-01-04            1333  3150.0  3210.0  3140.0   \n",
       "3        20170104_1376  2017-01-04            1376  1510.0  1550.0  1510.0   \n",
       "4        20170104_1377  2017-01-04            1377  3270.0  3350.0  3270.0   \n",
       "...                ...         ...             ...     ...     ...     ...   \n",
       "2330537  20211203_1379  2021-12-03            1379  1870.0  1893.0  1870.0   \n",
       "2330538  20211203_1381  2021-12-03            1381  3125.0  3200.0  3125.0   \n",
       "2330539  20211203_1407  2021-12-03            1407  6030.0  6200.0  5900.0   \n",
       "2330541  20211203_1414  2021-12-03            1414  4990.0  5100.0  4965.0   \n",
       "2330542  20211203_1417  2021-12-03            1417  1967.0  1994.0  1963.0   \n",
       "\n",
       "          Close   Volume  AdjustmentFactor  ExpectedDividend  SupervisionFlag  \\\n",
       "0        2742.0    31400               1.0               NaN            False   \n",
       "1         571.0  2798500               1.0               NaN            False   \n",
       "2        3210.0   270800               1.0               NaN            False   \n",
       "3        1550.0    11300               1.0               NaN            False   \n",
       "4        3330.0   150800               1.0               NaN            False   \n",
       "...         ...      ...               ...               ...              ...   \n",
       "2330537  1891.0    27400               1.0               NaN            False   \n",
       "2330538  3200.0      700               1.0               NaN            False   \n",
       "2330539  6190.0   355900               1.0               NaN            False   \n",
       "2330541  5100.0   198100               1.0               NaN            False   \n",
       "2330542  1990.0   133500               1.0               NaN            False   \n",
       "\n",
       "           Target  \n",
       "0        0.000730  \n",
       "1        0.012324  \n",
       "2        0.006154  \n",
       "3        0.011053  \n",
       "4        0.003026  \n",
       "...           ...  \n",
       "2330537  0.019058  \n",
       "2330538  0.004762  \n",
       "2330539  0.019293  \n",
       "2330541  0.015810  \n",
       "2330542  0.015570  \n",
       "\n",
       "[12020 rows x 12 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vgulMNxO790r",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Extracting the required columns for Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvdSkPv69KZr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_c = df_2[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'SecuritiesCode']]\n",
    "df_c\n",
    "\n",
    "df_c.to_csv('export_dataframe.csv', index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oflsZdZdpqyQ",
    "outputId": "0121e210-bf1e-42ad-c361-9573e3f48c37",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date               object\n",
       "Open              float64\n",
       "High              float64\n",
       "Low               float64\n",
       "Close             float64\n",
       "Volume              int64\n",
       "SecuritiesCode      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df_c.dtypes\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LeK6usS58I9m",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exporing the extracted columns to new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "T4lpvw5ZtO74",
    "outputId": "e01f2271-4bd7-4d31-82e2-359fc6abf36d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e7870417-8981-4590-9301-59b3cb5f73a2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>2734.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>31400</td>\n",
       "      <td>1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>568.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2798500</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>270800</td>\n",
       "      <td>1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>11300</td>\n",
       "      <td>1376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>150800</td>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12015</th>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>1893.0</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>1891.0</td>\n",
       "      <td>27400</td>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12016</th>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>3125.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3125.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>700</td>\n",
       "      <td>1381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12017</th>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>6030.0</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>5900.0</td>\n",
       "      <td>6190.0</td>\n",
       "      <td>355900</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12018</th>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>4990.0</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>4965.0</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>198100</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12019</th>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>133500</td>\n",
       "      <td>1417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12020 rows × 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7870417-8981-4590-9301-59b3cb5f73a2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e7870417-8981-4590-9301-59b3cb5f73a2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e7870417-8981-4590-9301-59b3cb5f73a2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "             Date    Open    High     Low   Close   Volume  SecuritiesCode\n",
       "0      2017-01-04  2734.0  2755.0  2730.0  2742.0    31400            1301\n",
       "1      2017-01-04   568.0   576.0   563.0   571.0  2798500            1332\n",
       "2      2017-01-04  3150.0  3210.0  3140.0  3210.0   270800            1333\n",
       "3      2017-01-04  1510.0  1550.0  1510.0  1550.0    11300            1376\n",
       "4      2017-01-04  3270.0  3350.0  3270.0  3330.0   150800            1377\n",
       "...           ...     ...     ...     ...     ...      ...             ...\n",
       "12015  2021-12-03  1870.0  1893.0  1870.0  1891.0    27400            1379\n",
       "12016  2021-12-03  3125.0  3200.0  3125.0  3200.0      700            1381\n",
       "12017  2021-12-03  6030.0  6200.0  5900.0  6190.0   355900            1407\n",
       "12018  2021-12-03  4990.0  5100.0  4965.0  5100.0   198100            1414\n",
       "12019  2021-12-03  1967.0  1994.0  1963.0  1990.0   133500            1417\n",
       "\n",
       "[12020 rows x 7 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3 = pd.read_csv('export_dataframe.csv')\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWmc9oHR8OOd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Converting the Securities Code from int64 to string object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTZjY2I5DntD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_3['SecuritiesCode'] = df_3['SecuritiesCode'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ePRlR5wbFRwB",
    "outputId": "533ab110-6e8d-45b0-e554-fe348f39e645",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8947c295-ca02-4ed2-ad90-36b002aa5949\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>3160.0</td>\n",
       "      <td>3105.0</td>\n",
       "      <td>3110.0</td>\n",
       "      <td>18900</td>\n",
       "      <td>1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>637.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>6031200</td>\n",
       "      <td>1332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>2580.0</td>\n",
       "      <td>2605.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>2603.0</td>\n",
       "      <td>101400</td>\n",
       "      <td>1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11823</th>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>1495.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>3700</td>\n",
       "      <td>1376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11824</th>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>42900</td>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12015</th>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>1893.0</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>1891.0</td>\n",
       "      <td>27400</td>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12016</th>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>3125.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>3125.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>700</td>\n",
       "      <td>1381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12017</th>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>6030.0</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>5900.0</td>\n",
       "      <td>6190.0</td>\n",
       "      <td>355900</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12018</th>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>4990.0</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>4965.0</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>198100</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12019</th>\n",
       "      <td>2021-12-03</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>133500</td>\n",
       "      <td>1417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8947c295-ca02-4ed2-ad90-36b002aa5949')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8947c295-ca02-4ed2-ad90-36b002aa5949 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8947c295-ca02-4ed2-ad90-36b002aa5949');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "             Date    Open    High     Low   Close   Volume SecuritiesCode\n",
       "11820  2021-11-05  3150.0  3160.0  3105.0  3110.0    18900           1301\n",
       "11821  2021-11-05   637.0   670.0   624.0   661.0  6031200           1332\n",
       "11822  2021-11-05  2580.0  2605.0  2570.0  2603.0   101400           1333\n",
       "11823  2021-11-05  1516.0  1516.0  1495.0  1500.0     3700           1376\n",
       "11824  2021-11-05  3420.0  3435.0  3420.0  3420.0    42900           1377\n",
       "...           ...     ...     ...     ...     ...      ...            ...\n",
       "12015  2021-12-03  1870.0  1893.0  1870.0  1891.0    27400           1379\n",
       "12016  2021-12-03  3125.0  3200.0  3125.0  3200.0      700           1381\n",
       "12017  2021-12-03  6030.0  6200.0  5900.0  6190.0   355900           1407\n",
       "12018  2021-12-03  4990.0  5100.0  4965.0  5100.0   198100           1414\n",
       "12019  2021-12-03  1967.0  1994.0  1963.0  1990.0   133500           1417\n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.sort_values(['Date','SecuritiesCode'],ignore_index=True).tail(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKmAwd9QE5im",
    "outputId": "d8d29578-f61d-494a-f8c2-66510d0f32d4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date               object\n",
       "Open              float64\n",
       "High              float64\n",
       "Low               float64\n",
       "Close             float64\n",
       "Volume              int64\n",
       "SecuritiesCode     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_4 = df_3.dtypes\n",
    "result_4"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Renaming the column names because it is required by Feature Engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_3.rename(columns = {'Date':'date', 'Open':'open', 'High':'high', 'Low':'low', 'Close':'close', 'Volume':'volume', 'SecuritiesCode':'tic'}, inplace = True)\n",
    "df_3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing\n",
    "## Applying Feature Engineering on the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.INDICATORS,\n",
    "                    use_vix=True,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df_3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Splitting the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PAARFxZ2HGH6",
    "outputId": "b20b9ee9-72b3-4afe-ccd0-f87969f49a32",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7416\n",
      "2853\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, '2017-01-04','2020-07-01')\n",
    "trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ErdEw8aIHiZf",
    "outputId": "37e5ee03-670d-45b7-b041-f3f5053736a0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-5a409855-2537-40dd-9295-4ad3041175f8\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>1377</td>\n",
       "      <td>3460.0</td>\n",
       "      <td>3480.0</td>\n",
       "      <td>3430.0</td>\n",
       "      <td>3440.0</td>\n",
       "      <td>102800.0</td>\n",
       "      <td>-36.593728</td>\n",
       "      <td>3647.009919</td>\n",
       "      <td>3321.990081</td>\n",
       "      <td>48.567700</td>\n",
       "      <td>-61.875671</td>\n",
       "      <td>2.520241</td>\n",
       "      <td>3533.166667</td>\n",
       "      <td>3507.250000</td>\n",
       "      <td>30.43</td>\n",
       "      <td>4.30489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>1379</td>\n",
       "      <td>2039.0</td>\n",
       "      <td>2043.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>66900.0</td>\n",
       "      <td>13.646587</td>\n",
       "      <td>2053.369565</td>\n",
       "      <td>1962.530435</td>\n",
       "      <td>56.081788</td>\n",
       "      <td>124.826036</td>\n",
       "      <td>3.329848</td>\n",
       "      <td>2006.766667</td>\n",
       "      <td>1971.700000</td>\n",
       "      <td>30.43</td>\n",
       "      <td>4.30489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>1407</td>\n",
       "      <td>2238.0</td>\n",
       "      <td>2261.0</td>\n",
       "      <td>2146.0</td>\n",
       "      <td>2184.0</td>\n",
       "      <td>159700.0</td>\n",
       "      <td>115.076965</td>\n",
       "      <td>2381.537601</td>\n",
       "      <td>1616.162399</td>\n",
       "      <td>62.467613</td>\n",
       "      <td>113.615743</td>\n",
       "      <td>35.344671</td>\n",
       "      <td>1964.666667</td>\n",
       "      <td>1774.966667</td>\n",
       "      <td>30.43</td>\n",
       "      <td>4.30489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>1414</td>\n",
       "      <td>4880.0</td>\n",
       "      <td>4880.0</td>\n",
       "      <td>4765.0</td>\n",
       "      <td>4775.0</td>\n",
       "      <td>136600.0</td>\n",
       "      <td>25.295398</td>\n",
       "      <td>5061.692039</td>\n",
       "      <td>4743.307961</td>\n",
       "      <td>53.330967</td>\n",
       "      <td>-59.574468</td>\n",
       "      <td>4.371023</td>\n",
       "      <td>4881.166667</td>\n",
       "      <td>4607.083333</td>\n",
       "      <td>30.43</td>\n",
       "      <td>4.30489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>1417</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>1656.0</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>266000.0</td>\n",
       "      <td>33.475646</td>\n",
       "      <td>1652.719311</td>\n",
       "      <td>1465.080689</td>\n",
       "      <td>58.307774</td>\n",
       "      <td>137.227631</td>\n",
       "      <td>25.152770</td>\n",
       "      <td>1544.333333</td>\n",
       "      <td>1450.883333</td>\n",
       "      <td>30.43</td>\n",
       "      <td>4.30489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a409855-2537-40dd-9295-4ad3041175f8')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5a409855-2537-40dd-9295-4ad3041175f8 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5a409855-2537-40dd-9295-4ad3041175f8');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           date   tic    open    high     low   close    volume        macd  \\\n",
       "823  2020-06-30  1377  3460.0  3480.0  3430.0  3440.0  102800.0  -36.593728   \n",
       "823  2020-06-30  1379  2039.0  2043.0  2023.0  2030.0   66900.0   13.646587   \n",
       "823  2020-06-30  1407  2238.0  2261.0  2146.0  2184.0  159700.0  115.076965   \n",
       "823  2020-06-30  1414  4880.0  4880.0  4765.0  4775.0  136600.0   25.295398   \n",
       "823  2020-06-30  1417  1640.0  1656.0  1608.0  1608.0  266000.0   33.475646   \n",
       "\n",
       "         boll_ub      boll_lb     rsi_30      cci_30      dx_30  close_30_sma  \\\n",
       "823  3647.009919  3321.990081  48.567700  -61.875671   2.520241   3533.166667   \n",
       "823  2053.369565  1962.530435  56.081788  124.826036   3.329848   2006.766667   \n",
       "823  2381.537601  1616.162399  62.467613  113.615743  35.344671   1964.666667   \n",
       "823  5061.692039  4743.307961  53.330967  -59.574468   4.371023   4881.166667   \n",
       "823  1652.719311  1465.080689  58.307774  137.227631  25.152770   1544.333333   \n",
       "\n",
       "     close_60_sma    vix  turbulence  \n",
       "823   3507.250000  30.43     4.30489  \n",
       "823   1971.700000  30.43     4.30489  \n",
       "823   1774.966667  30.43     4.30489  \n",
       "823   4607.083333  30.43     4.30489  \n",
       "823   1450.883333  30.43     4.30489  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "74NZPmyIHjkb",
    "outputId": "98e1d10d-35d8-4e94-a232-9b79e285890c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bafc9e78-3e1d-41c8-8125-bd5748e21817\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>1301</td>\n",
       "      <td>2716.0</td>\n",
       "      <td>2732.0</td>\n",
       "      <td>2673.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>22600.0</td>\n",
       "      <td>5.263214</td>\n",
       "      <td>2788.994065</td>\n",
       "      <td>2638.605935</td>\n",
       "      <td>50.170543</td>\n",
       "      <td>-45.346498</td>\n",
       "      <td>8.804069</td>\n",
       "      <td>2710.466667</td>\n",
       "      <td>2642.683333</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>13.020932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>1332</td>\n",
       "      <td>471.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>1853200.0</td>\n",
       "      <td>-6.506016</td>\n",
       "      <td>527.137010</td>\n",
       "      <td>450.462990</td>\n",
       "      <td>45.010734</td>\n",
       "      <td>-133.964248</td>\n",
       "      <td>29.873136</td>\n",
       "      <td>490.800000</td>\n",
       "      <td>478.183333</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>13.020932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>1333</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>2201.0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>2162.0</td>\n",
       "      <td>157300.0</td>\n",
       "      <td>-28.863883</td>\n",
       "      <td>2406.874113</td>\n",
       "      <td>2076.825887</td>\n",
       "      <td>45.081492</td>\n",
       "      <td>-84.222642</td>\n",
       "      <td>18.464684</td>\n",
       "      <td>2257.300000</td>\n",
       "      <td>2259.166667</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>13.020932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>1376</td>\n",
       "      <td>1492.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>22700.0</td>\n",
       "      <td>3.269222</td>\n",
       "      <td>1507.906031</td>\n",
       "      <td>1393.993969</td>\n",
       "      <td>54.778817</td>\n",
       "      <td>71.315748</td>\n",
       "      <td>9.870881</td>\n",
       "      <td>1455.066667</td>\n",
       "      <td>1456.516667</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>13.020932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>1377</td>\n",
       "      <td>3430.0</td>\n",
       "      <td>3430.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>3315.0</td>\n",
       "      <td>142400.0</td>\n",
       "      <td>-44.658664</td>\n",
       "      <td>3630.285571</td>\n",
       "      <td>3306.214429</td>\n",
       "      <td>43.852475</td>\n",
       "      <td>-127.651747</td>\n",
       "      <td>25.061859</td>\n",
       "      <td>3521.333333</td>\n",
       "      <td>3511.166667</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>13.020932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bafc9e78-3e1d-41c8-8125-bd5748e21817')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bafc9e78-3e1d-41c8-8125-bd5748e21817 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bafc9e78-3e1d-41c8-8125-bd5748e21817');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         date   tic    open    high     low   close     volume       macd  \\\n",
       "0  2020-07-01  1301  2716.0  2732.0  2673.0  2680.0    22600.0   5.263214   \n",
       "0  2020-07-01  1332   471.0   471.0   457.0   461.0  1853200.0  -6.506016   \n",
       "0  2020-07-01  1333  2195.0  2201.0  2161.0  2162.0   157300.0 -28.863883   \n",
       "0  2020-07-01  1376  1492.0  1500.0  1472.0  1486.0    22700.0   3.269222   \n",
       "0  2020-07-01  1377  3430.0  3430.0  3300.0  3315.0   142400.0 -44.658664   \n",
       "\n",
       "       boll_ub      boll_lb     rsi_30      cci_30      dx_30  close_30_sma  \\\n",
       "0  2788.994065  2638.605935  50.170543  -45.346498   8.804069   2710.466667   \n",
       "0   527.137010   450.462990  45.010734 -133.964248  29.873136    490.800000   \n",
       "0  2406.874113  2076.825887  45.081492  -84.222642  18.464684   2257.300000   \n",
       "0  1507.906031  1393.993969  54.778817   71.315748   9.870881   1455.066667   \n",
       "0  3630.285571  3306.214429  43.852475 -127.651747  25.061859   3521.333333   \n",
       "\n",
       "   close_60_sma        vix  turbulence  \n",
       "0   2642.683333  28.620001   13.020932  \n",
       "0    478.183333  28.620001   13.020932  \n",
       "0   2259.166667  28.620001   13.020932  \n",
       "0   1456.516667  28.620001   13.020932  \n",
       "0   3511.166667  28.620001   13.020932  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WY9VsmfTHxEr",
    "outputId": "656ca848-0089-4bbb-ed33-3d0f241758ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.INDICATORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5y09G54I8_vf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Defining the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDXxdsfsH3MT",
    "outputId": "7fa77510-9762-40fa-85bc-492b16ba107a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 9, State Space: 91\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rOmujac2IEcR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#num_stock_shares = [0] * stock_dimension from https://github.com/AI4Finance-Foundation/FinRL/blob/master/FinRL_StockTrading_NeurIPS_2018.ipynb\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    # initial_amount = 1000000, and hold no shares at beginning.\n",
    "    #\"initial_list\": [1000000] + [0 for i in range(stock_dimension)],\n",
    "    \"initial_amount\": 130000000, # In YEN\n",
    "    \"num_stock_shares\": [0] * stock_dimension,\n",
    "    # buy and sell cost for each stock\n",
    "    \"buy_cost_pct\": [0.001] * stock_dimension,\n",
    "    \"sell_cost_pct\": [0.001] * stock_dimension,\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.INDICATORS, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "    \n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHiZdUJ79D16",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWD_NfUkIVnP",
    "outputId": "933972da-fba3-41af-ecba-ddf3f79bcfe0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afM9F2vfIW3g",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxCDcla1-RFv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Trading\n",
    "### Assume that we have 130m Yen initial capital at 2020-07-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsPI4N5m-V6b",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setting turbulence threshold\n",
    "### Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqiVOP8L-U69",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_risk_indicator = processed_full[(processed_full.date<'2020-07-01') & (processed_full.date>='2009-01-01')]\n",
    "insample_risk_indicator = data_risk_indicator.drop_duplicates(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PwvYAw8o-jMT",
    "outputId": "d29c6479-4307-426a-fa91-b05a27515e3b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    824.000000\n",
       "mean      16.976456\n",
       "std        9.719649\n",
       "min        9.190000\n",
       "25%       11.732500\n",
       "50%       13.740000\n",
       "75%       18.030000\n",
       "max       82.690002\n",
       "Name: vix, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDVN6uTs-kdY",
    "outputId": "7f718391-4267-47fe-aa71-2c410ffc50fa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.4567608642577"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.vix.quantile(0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_AIEe9Tq-l6W",
    "outputId": "e479cbe4-1000-4905-f83c-b0785a8ed1f9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     824.000000\n",
       "mean        9.322270\n",
       "std        48.166223\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         4.561011\n",
       "75%         9.465536\n",
       "max      1343.527661\n",
       "Name: turbulence, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z_5jAd4y-ntY",
    "outputId": "5cc00ebc-59c7-48b4-801c-119036645789",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.2501502293631"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_risk_indicator.turbulence.quantile(0.996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1M4Yd1f-qzT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Trade\n",
    "\n",
    "### DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2020-07 to tune the parameters once, so there is some alpha decay here as the length of trade date extends.\n",
    "\n",
    "### Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GDsQYH5-xi9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#trade = data_split(processed_full, '2020-07-01','2021-10-31')\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 70,risk_indicator_col='vix', **env_kwargs)\n",
    "# env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "wzXYj849-zPW",
    "outputId": "b3bcef7c-64d6-432a-a46a-b7c261ec8ee6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-79d349fb-dc10-4e47-b827-2ae588fef6b0\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>1301</td>\n",
       "      <td>2716.0</td>\n",
       "      <td>2732.0</td>\n",
       "      <td>2673.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>22600.0</td>\n",
       "      <td>5.263214</td>\n",
       "      <td>2788.994065</td>\n",
       "      <td>2638.605935</td>\n",
       "      <td>50.170543</td>\n",
       "      <td>-45.346498</td>\n",
       "      <td>8.804069</td>\n",
       "      <td>2710.466667</td>\n",
       "      <td>2642.683333</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>13.020932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>1332</td>\n",
       "      <td>471.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>1853200.0</td>\n",
       "      <td>-6.506016</td>\n",
       "      <td>527.137010</td>\n",
       "      <td>450.462990</td>\n",
       "      <td>45.010734</td>\n",
       "      <td>-133.964248</td>\n",
       "      <td>29.873136</td>\n",
       "      <td>490.800000</td>\n",
       "      <td>478.183333</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>13.020932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>1333</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>2201.0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>2162.0</td>\n",
       "      <td>157300.0</td>\n",
       "      <td>-28.863883</td>\n",
       "      <td>2406.874113</td>\n",
       "      <td>2076.825887</td>\n",
       "      <td>45.081492</td>\n",
       "      <td>-84.222642</td>\n",
       "      <td>18.464684</td>\n",
       "      <td>2257.300000</td>\n",
       "      <td>2259.166667</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>13.020932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>1376</td>\n",
       "      <td>1492.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1486.0</td>\n",
       "      <td>22700.0</td>\n",
       "      <td>3.269222</td>\n",
       "      <td>1507.906031</td>\n",
       "      <td>1393.993969</td>\n",
       "      <td>54.778817</td>\n",
       "      <td>71.315748</td>\n",
       "      <td>9.870881</td>\n",
       "      <td>1455.066667</td>\n",
       "      <td>1456.516667</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>13.020932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>1377</td>\n",
       "      <td>3430.0</td>\n",
       "      <td>3430.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>3315.0</td>\n",
       "      <td>142400.0</td>\n",
       "      <td>-44.658664</td>\n",
       "      <td>3630.285571</td>\n",
       "      <td>3306.214429</td>\n",
       "      <td>43.852475</td>\n",
       "      <td>-127.651747</td>\n",
       "      <td>25.061859</td>\n",
       "      <td>3521.333333</td>\n",
       "      <td>3511.166667</td>\n",
       "      <td>28.620001</td>\n",
       "      <td>13.020932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79d349fb-dc10-4e47-b827-2ae588fef6b0')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-79d349fb-dc10-4e47-b827-2ae588fef6b0 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-79d349fb-dc10-4e47-b827-2ae588fef6b0');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         date   tic    open    high     low   close     volume       macd  \\\n",
       "0  2020-07-01  1301  2716.0  2732.0  2673.0  2680.0    22600.0   5.263214   \n",
       "0  2020-07-01  1332   471.0   471.0   457.0   461.0  1853200.0  -6.506016   \n",
       "0  2020-07-01  1333  2195.0  2201.0  2161.0  2162.0   157300.0 -28.863883   \n",
       "0  2020-07-01  1376  1492.0  1500.0  1472.0  1486.0    22700.0   3.269222   \n",
       "0  2020-07-01  1377  3430.0  3430.0  3300.0  3315.0   142400.0 -44.658664   \n",
       "\n",
       "       boll_ub      boll_lb     rsi_30      cci_30      dx_30  close_30_sma  \\\n",
       "0  2788.994065  2638.605935  50.170543  -45.346498   8.804069   2710.466667   \n",
       "0   527.137010   450.462990  45.010734 -133.964248  29.873136    490.800000   \n",
       "0  2406.874113  2076.825887  45.081492  -84.222642  18.464684   2257.300000   \n",
       "0  1507.906031  1393.993969  54.778817   71.315748   9.870881   1455.066667   \n",
       "0  3630.285571  3306.214429  43.852475 -127.651747  25.061859   3521.333333   \n",
       "\n",
       "   close_60_sma        vix  turbulence  \n",
       "0   2642.683333  28.620001   13.020932  \n",
       "0    478.183333  28.620001   13.020932  \n",
       "0   2259.166667  28.620001   13.020932  \n",
       "0   1456.516667  28.620001   13.020932  \n",
       "0   3511.166667  28.620001   13.020932  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mR64oDtio7ii",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "SEEDS = [11, 22, 33]\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9TutG-49VJf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Calling different Deep RL algorithms\n",
    "## A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0ac2d6ddf14e4193998c7d2d79501a7a",
      "5178d683afe844c9b0bcbab6b80876da",
      "7fda54a53c7c4cd0b438eacd7a44ecb7",
      "097d0ebcdb6b45d6ba515cee27ca9a06",
      "c8504cef76dd45bb9555245207a463c7",
      "08b9083a117e4c2389e58207a2a48c0b",
      "09565454f532499cbf10b68b997a9f06",
      "6550d0095c1343289ef5575b1f414ea4",
      "0a801025efaa41b481ee9a29918c5c9b",
      "53d015f578a0426e89f5fdefd2845748",
      "c9b89d31a2bf40c3b6c369537e98cf83"
     ]
    },
    "id": "OpzxjZuvIptU",
    "outputId": "bb6e671a-3c8f-4767-c1d2-63634c6cb7cb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac2d6ddf14e4193998c7d2d79501a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All seeds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 191      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.7    |\n",
      "|    explained_variance | -0.0123  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 4.27e+03 |\n",
      "|    reward             | 289.9015 |\n",
      "|    std                | 0.99     |\n",
      "|    value_loss         | 1.06e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 195      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -181     |\n",
      "|    reward             | 8.007447 |\n",
      "|    std                | 0.989    |\n",
      "|    value_loss         | 1.89e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 197       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | -0.0292   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 1.94e+03  |\n",
      "|    reward             | 20.877645 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 3.14e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 198        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0.0105     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -1.11e+03  |\n",
      "|    reward             | -170.60413 |\n",
      "|    std                | 0.986      |\n",
      "|    value_loss         | 1.11e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 333        |\n",
      "|    reward             | -0.3565516 |\n",
      "|    std                | 0.986      |\n",
      "|    value_loss         | 846        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 197       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0.0282    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -726      |\n",
      "|    reward             | 410.60492 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 1.22e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 198      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.6    |\n",
      "|    explained_variance | 0.00497  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 4.62e+03 |\n",
      "|    reward             | 86.0123  |\n",
      "|    std                | 0.984    |\n",
      "|    value_loss         | 1.59e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -0.0465   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -842      |\n",
      "|    reward             | 44.652878 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 7.26e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 0.00947   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -102      |\n",
      "|    reward             | 11.707323 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 1.72e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -416      |\n",
      "|    reward             | -7.804547 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 1.39e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -0.227    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -1.13e+03 |\n",
      "|    reward             | 43.018078 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 9.28e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 198        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 0.000268   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 7.88e+03   |\n",
      "|    reward             | -309.15958 |\n",
      "|    std                | 0.988      |\n",
      "|    value_loss         | 4.93e+05   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0.00735   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -880      |\n",
      "|    reward             | 35.512436 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 1.02e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 198        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 35         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | -0.0233    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 4.76e+03   |\n",
      "|    reward             | -277.10522 |\n",
      "|    std                | 0.992      |\n",
      "|    value_loss         | 1.66e+05   |\n",
      "--------------------------------------\n",
      "day: 823, episode: 10\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 107367185.50\n",
      "total_reward: -22632814.50\n",
      "total_cost: 1179289.82\n",
      "total_trades: 5680\n",
      "Sharpe: -0.039\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 542       |\n",
      "|    reward             | -5.877676 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 2.69e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | 0.0108    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -2.91e+03 |\n",
      "|    reward             | 131.2981  |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 5.67e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | -0.0047   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 1.56e+03  |\n",
      "|    reward             | -354.6719 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.39e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 1.2e+03   |\n",
      "|    reward             | 401.2015  |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.31e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 197       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | 0.000547  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 190       |\n",
      "|    reward             | -264.7528 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.04e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 198        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 50         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.8      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | 1.02e+03   |\n",
      "|    reward             | -59.632378 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.54e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 198        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.8      |\n",
      "|    explained_variance | 0.00389    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | 1.12e+03   |\n",
      "|    reward             | -303.72498 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.07e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | -0.00138  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 3.87e+03  |\n",
      "|    reward             | 258.43533 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.2e+05   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | 0.00284   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 1.55e+03  |\n",
      "|    reward             | 236.94803 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.66e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | -0.000622 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 5.96e+03  |\n",
      "|    reward             | -166.2054 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.31e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | 0.000265  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -684      |\n",
      "|    reward             | 117.90108 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.45e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -0.00164  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 977       |\n",
      "|    reward             | 96.864204 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.5e+04   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -4.43e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 1.48e+03  |\n",
      "|    reward             | -83.69209 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.51e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 0.00212   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -3.94e+03 |\n",
      "|    reward             | 117.62075 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.13e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 0.000311  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | -2.64e+03 |\n",
      "|    reward             | 19.475397 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 4.59e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 0.000247  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 723       |\n",
      "|    reward             | -132.0781 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.57e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -0.00133  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | 2.08e+03  |\n",
      "|    reward             | 81.881905 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.86e+04  |\n",
      "-------------------------------------\n",
      "day: 823, episode: 20\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 115511814.58\n",
      "total_reward: -14488185.42\n",
      "total_cost: 1409135.30\n",
      "total_trades: 6721\n",
      "Sharpe: 0.036\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -2.31e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 2.71e+03  |\n",
      "|    reward             | 54.347984 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.11e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 68.1      |\n",
      "|    reward             | 18.867704 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 74.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 7.9e-05   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | -484      |\n",
      "|    reward             | -235.1858 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.33e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 3.1e-06   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 518       |\n",
      "|    reward             | 40.043484 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.96e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -8.12e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 132       |\n",
      "|    reward             | -55.64839 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.14e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 92        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 1.88e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 2.2e+03   |\n",
      "|    reward             | -54.21814 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 5.08e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 522       |\n",
      "|    reward             | 11.285519 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.61e+03  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 199         |\n",
      "|    iterations         | 3900        |\n",
      "|    time_elapsed       | 97          |\n",
      "|    total_timesteps    | 19500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | 0.000351    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3899        |\n",
      "|    policy_loss        | 1.06e+03    |\n",
      "|    reward             | -0.23009235 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 8.06e+03    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -4.41e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 4.84e+03  |\n",
      "|    reward             | 440.66953 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.83e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 102       |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -0.000315 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 837       |\n",
      "|    reward             | 78.16397  |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.87e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -8.76e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 6.62e+03  |\n",
      "|    reward             | 139.6173  |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.4e+05   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -1.59e+03 |\n",
      "|    reward             | 16.483393 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.55e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 110        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | -5.36e-06  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | 1.89e+03   |\n",
      "|    reward             | -15.420705 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.45e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -2.62e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -2.37e+03 |\n",
      "|    reward             | -36.00415 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 5.49e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13       |\n",
      "|    explained_variance | -1.79e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -2.8e+03  |\n",
      "|    reward             | -306.4451 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 7.67e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13       |\n",
      "|    explained_variance | 7.45e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -4.12e+03 |\n",
      "|    reward             | 190.56248 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.3e+05   |\n",
      "-------------------------------------\n",
      "day: 823, episode: 30\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 116106065.98\n",
      "total_reward: -13893934.02\n",
      "total_cost: 1475043.49\n",
      "total_trades: 6708\n",
      "Sharpe: -0.005\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13       |\n",
      "|    explained_variance | 1.07e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 1.83e+03  |\n",
      "|    reward             | 180.45795 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.72e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 122        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | 3.96e-05   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -949       |\n",
      "|    reward             | -80.295395 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.72e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 125        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | -3.1e-06   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | 1.68e+03   |\n",
      "|    reward             | -105.54022 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 2.94e+04   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 199      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 127      |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.9    |\n",
      "|    explained_variance | 7.15e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 5.88e+03 |\n",
      "|    reward             | 72.77291 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.89e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -0.000163 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -444      |\n",
      "|    reward             | 97.86431  |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.6e+03   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 1.77e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -859      |\n",
      "|    reward             | 13.410671 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 5.13e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | -2.62e-06  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | -1.84e+03  |\n",
      "|    reward             | -127.27551 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.92e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | -5.96e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 215       |\n",
      "|    reward             | 223.55933 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.16e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | 2.38e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 1.63e+03  |\n",
      "|    reward             | -73.43028 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.83e+04  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 199         |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.8       |\n",
      "|    explained_variance | 4.35e-06    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | 102         |\n",
      "|    reward             | -124.426796 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 5.7e+03     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | -5.01e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -429      |\n",
      "|    reward             | 125.20147 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.72e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 147        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.8      |\n",
      "|    explained_variance | -2.44e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | 15.9       |\n",
      "|    reward             | -115.34072 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.94e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | 2.98e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -4.65e+03 |\n",
      "|    reward             | 112.66105 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.28e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | -335      |\n",
      "|    reward             | -5.109045 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 715       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | -1.26e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -562      |\n",
      "|    reward             | 101.07756 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 7.12e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | 9.95e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 2.37e+03  |\n",
      "|    reward             | 174.49585 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 4.65e+04  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 200         |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 159         |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.8       |\n",
      "|    explained_variance | -3.1e-06    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | 174         |\n",
      "|    reward             | -103.476295 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 3.04e+03    |\n",
      "---------------------------------------\n",
      "day: 823, episode: 40\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 116497151.88\n",
      "total_reward: -13502848.12\n",
      "total_cost: 1491650.06\n",
      "total_trades: 7105\n",
      "Sharpe: -0.000\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 162       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -5.57e+03 |\n",
      "|    reward             | 320.9251  |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.5e+05   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 43.4      |\n",
      "|    reward             | 23.931751 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 267       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 200      |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 167      |\n",
      "|    total_timesteps    | 33500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.9    |\n",
      "|    explained_variance | 4.83e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 1.42e+03 |\n",
      "|    reward             | 5.52001  |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 1.41e+04 |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 169        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | -158       |\n",
      "|    reward             | -30.683977 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 4.15e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 1.87e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -1.19e+03 |\n",
      "|    reward             | -57.16146 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.98e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -2.38e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -596      |\n",
      "|    reward             | 193.96466 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.86e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | -1.92e+03 |\n",
      "|    reward             | -54.98843 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 2.67e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13       |\n",
      "|    explained_variance | -6.2e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -790      |\n",
      "|    reward             | -89.32687 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.5e+04   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 182        |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | 2.98e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | 1.31e+03   |\n",
      "|    reward             | -207.65576 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 2.04e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 184       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 6.5e-06   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -3.49e+03 |\n",
      "|    reward             | 266.4451  |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.28e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 7500       |\n",
      "|    time_elapsed       | 187        |\n",
      "|    total_timesteps    | 37500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7499       |\n",
      "|    policy_loss        | 2.78e+03   |\n",
      "|    reward             | -164.02388 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 2.05e+05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 7600       |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 38000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | -6.91e-06  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7599       |\n",
      "|    policy_loss        | 744        |\n",
      "|    reward             | -38.506084 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 5.37e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 192       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 1.13e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 3.05e+03  |\n",
      "|    reward             | 222.38748 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 8.27e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 194       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -4.77e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -9.23e+03 |\n",
      "|    reward             | 22.61175  |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 7.07e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 197       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 4.17e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -8.25e+03 |\n",
      "|    reward             | 197.34482 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 5e+05     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 199        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | -1.94e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | 373        |\n",
      "|    reward             | -6.6635017 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.1e+03    |\n",
      "--------------------------------------\n",
      "day: 823, episode: 50\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 117077179.44\n",
      "total_reward: -12922820.56\n",
      "total_cost: 1528978.93\n",
      "total_trades: 7032\n",
      "Sharpe: 0.006\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 202       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -1.91e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -779      |\n",
      "|    reward             | 60.061985 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.27e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 204       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 2.68e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 1.43e+03  |\n",
      "|    reward             | 5.1174583 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.7e+04   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 2.56e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 4.32e+03  |\n",
      "|    reward             | 48.778202 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.66e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 209       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -1.19e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 880       |\n",
      "|    reward             | 17.558775 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.7e+04   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 212        |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | 7.15e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | -7.95e+03  |\n",
      "|    reward             | -31.286163 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 5.41e+05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 214        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13        |\n",
      "|    explained_variance | 1.94e-05   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | -462       |\n",
      "|    reward             | -139.96935 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 5.77e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 217       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 1.91e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -1.34e+03 |\n",
      "|    reward             | 16.57488  |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.27e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 219        |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | 5.36e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | 3.63e+03   |\n",
      "|    reward             | -130.11392 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 7.68e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 222        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | 1.55e-06   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | -525       |\n",
      "|    reward             | -6.0561743 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 8.16e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 224       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 8.94e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -3.7e+03  |\n",
      "|    reward             | 181.85959 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 9.87e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -4.65e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 617       |\n",
      "|    reward             | 136.17834 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.13e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 229       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 4.41e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 2.44e+03  |\n",
      "|    reward             | -4.614793 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.45e+04  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 200         |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 232         |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | 76.9        |\n",
      "|    reward             | -14.3541155 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 3.11e+04    |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 200      |\n",
      "|    iterations         | 9400     |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 47000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9399     |\n",
      "|    policy_loss        | 426      |\n",
      "|    reward             | 20.80418 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.57e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 237       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -2.03e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -6.39e+03 |\n",
      "|    reward             | 127.27779 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.7e+05   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 239        |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.9      |\n",
      "|    explained_variance | 7.75e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | -969       |\n",
      "|    reward             | -207.74402 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.24e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 241        |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.8      |\n",
      "|    explained_variance | 5.13e-06   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | 1.44e+03   |\n",
      "|    reward             | -152.29608 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.24e+04   |\n",
      "--------------------------------------\n",
      "day: 823, episode: 60\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 117643787.10\n",
      "total_reward: -12356212.90\n",
      "total_cost: 1521642.74\n",
      "total_trades: 7190\n",
      "Sharpe: -0.013\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 244        |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.8      |\n",
      "|    explained_variance | -4.77e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | -7.17e+03  |\n",
      "|    reward             | -112.62965 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.78e+05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 246        |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.8      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | 976        |\n",
      "|    reward             | -54.025356 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 9.65e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 249       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | -4.77e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -4.66e+03 |\n",
      "|    reward             | 158.5621  |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.14e+05  |\n",
      "-------------------------------------\n",
      "hit end!\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | 0.00198   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 2.31e+03  |\n",
      "|    reward             | 244.72496 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 4.23e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 205       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -233      |\n",
      "|    reward             | 34.856133 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 8.56e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 206        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | 3.53e+03   |\n",
      "|    reward             | -28.022058 |\n",
      "|    std                | 0.993      |\n",
      "|    value_loss         | 8.85e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 205        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 0.0528     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -3.65e+03  |\n",
      "|    reward             | -148.59126 |\n",
      "|    std                | 0.99       |\n",
      "|    value_loss         | 8.64e+04   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 206      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -2.05    |\n",
      "|    reward             | 5.068666 |\n",
      "|    std                | 0.991    |\n",
      "|    value_loss         | 3.13     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 204        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | -0.000104  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 2.91e+03   |\n",
      "|    reward             | -41.355778 |\n",
      "|    std                | 0.993      |\n",
      "|    value_loss         | 3.73e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 204        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | 1.14e+03   |\n",
      "|    reward             | -120.92934 |\n",
      "|    std                | 0.99       |\n",
      "|    value_loss         | 1.18e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 204        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | -0.0457    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | -289       |\n",
      "|    reward             | -22.066946 |\n",
      "|    std                | 0.988      |\n",
      "|    value_loss         | 1.59e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 204       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | -0.00239  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 457       |\n",
      "|    reward             | -97.95414 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 6.18e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 204        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 24         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -253       |\n",
      "|    reward             | -18.407835 |\n",
      "|    std                | 0.99       |\n",
      "|    value_loss         | 381        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 203       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -968      |\n",
      "|    reward             | 150.94444 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 7.33e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 1.46e+03  |\n",
      "|    reward             | -40.65143 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 1.68e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -1.31e+03 |\n",
      "|    reward             | 36.847225 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 1.51e+04  |\n",
      "-------------------------------------\n",
      "day: 823, episode: 70\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 124413311.67\n",
      "total_reward: -5586688.33\n",
      "total_cost: 951639.98\n",
      "total_trades: 6220\n",
      "Sharpe: -0.071\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 203      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.7    |\n",
      "|    explained_variance | -0.099   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -934     |\n",
      "|    reward             | 81.64189 |\n",
      "|    std                | 0.988    |\n",
      "|    value_loss         | 8.14e+03 |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 203        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 36         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | 104        |\n",
      "|    reward             | -13.923983 |\n",
      "|    std                | 0.99       |\n",
      "|    value_loss         | 116        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 203       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -84.1     |\n",
      "|    reward             | -93.62273 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 1.39e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 203        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 41         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 493        |\n",
      "|    reward             | -183.85599 |\n",
      "|    std                | 0.996      |\n",
      "|    value_loss         | 3.53e+03   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 202      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.7    |\n",
      "|    explained_variance | 0.00907  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 1.77e+03 |\n",
      "|    reward             | 427.8678 |\n",
      "|    std                | 0.994    |\n",
      "|    value_loss         | 1.75e+05 |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 202        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 46         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | -0.075     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 520        |\n",
      "|    reward             | -291.98413 |\n",
      "|    std                | 0.99       |\n",
      "|    value_loss         | 5.01e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 171       |\n",
      "|    reward             | -11.9443  |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 467       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 51         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0.08       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | 1.23e+03   |\n",
      "|    reward             | -260.96796 |\n",
      "|    std                | 0.984      |\n",
      "|    value_loss         | 1.33e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 2200       |\n",
      "|    time_elapsed       | 54         |\n",
      "|    total_timesteps    | 11000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2199       |\n",
      "|    policy_loss        | 1.97e+03   |\n",
      "|    reward             | -134.77501 |\n",
      "|    std                | 0.985      |\n",
      "|    value_loss         | 4.03e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -0.319    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 798       |\n",
      "|    reward             | 128.48758 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 5.01e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 0.0824    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 7.87e+03  |\n",
      "|    reward             | -340.4535 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 3e+05     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 61         |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | -1.4e+03   |\n",
      "|    reward             | -25.063711 |\n",
      "|    std                | 0.986      |\n",
      "|    value_loss         | 1.63e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 0.096     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 2.14e+03  |\n",
      "|    reward             | 33.093533 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 3.7e+04   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -0.169    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -2.99e+03 |\n",
      "|    reward             | -80.54904 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 5.59e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -4.25e+03 |\n",
      "|    reward             | -80.45122 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 1.32e+05  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 202        |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | 721        |\n",
      "|    reward             | -58.620193 |\n",
      "|    std                | 0.985      |\n",
      "|    value_loss         | 9.1e+03    |\n",
      "--------------------------------------\n",
      "day: 823, episode: 80\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 120294845.09\n",
      "total_reward: -9705154.91\n",
      "total_cost: 657013.08\n",
      "total_trades: 4920\n",
      "Sharpe: -0.062\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 202        |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -336       |\n",
      "|    reward             | -0.3714257 |\n",
      "|    std                | 0.986      |\n",
      "|    value_loss         | 1.4e+03    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | 1.19e+03  |\n",
      "|    reward             | 146.97945 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 1.83e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 645       |\n",
      "|    reward             | 21.735954 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 3.24e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -5.97     |\n",
      "|    reward             | 4.9105244 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 0.431     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 3400       |\n",
      "|    time_elapsed       | 84         |\n",
      "|    total_timesteps    | 17000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3399       |\n",
      "|    policy_loss        | -813       |\n",
      "|    reward             | -149.12366 |\n",
      "|    std                | 0.985      |\n",
      "|    value_loss         | 8.27e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 3500       |\n",
      "|    time_elapsed       | 86         |\n",
      "|    total_timesteps    | 17500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3499       |\n",
      "|    policy_loss        | -402       |\n",
      "|    reward             | -15.243357 |\n",
      "|    std                | 0.984      |\n",
      "|    value_loss         | 2.11e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 202        |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 89         |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0.0013     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | -1.25e+03  |\n",
      "|    reward             | -10.226086 |\n",
      "|    std                | 0.984      |\n",
      "|    value_loss         | 3.61e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | 3.45e+03   |\n",
      "|    reward             | -211.17311 |\n",
      "|    std                | 0.985      |\n",
      "|    value_loss         | 1.36e+05   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 201      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 75.2     |\n",
      "|    reward             | 6.238174 |\n",
      "|    std                | 0.981    |\n",
      "|    value_loss         | 39.9     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 96         |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 281        |\n",
      "|    reward             | -11.494179 |\n",
      "|    std                | 0.979      |\n",
      "|    value_loss         | 1.41e+03   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 201      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 1.24e+03 |\n",
      "|    reward             | 62.01468 |\n",
      "|    std                | 0.978    |\n",
      "|    value_loss         | 1e+04    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 399       |\n",
      "|    reward             | 35.758728 |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 1.13e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 104       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | -739      |\n",
      "|    reward             | 161.14758 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 5.23e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -1.16e+03 |\n",
      "|    reward             | 32.410854 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 1.23e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | -624      |\n",
      "|    reward             | 33.739994 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 5.48e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -4.71e+03 |\n",
      "|    reward             | 11.78468  |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 1.1e+05   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 114        |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0.000498   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4599       |\n",
      "|    policy_loss        | -2.53e+03  |\n",
      "|    reward             | -329.64633 |\n",
      "|    std                | 0.977      |\n",
      "|    value_loss         | 5.46e+04   |\n",
      "--------------------------------------\n",
      "day: 823, episode: 90\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 91748848.47\n",
      "total_reward: -38251151.53\n",
      "total_cost: 353525.33\n",
      "total_trades: 4088\n",
      "Sharpe: -0.429\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -1.11e+03 |\n",
      "|    reward             | 171.97427 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 2.48e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 201      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 289      |\n",
      "|    reward             | 67.9572  |\n",
      "|    std                | 0.982    |\n",
      "|    value_loss         | 822      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 121        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -873       |\n",
      "|    reward             | -221.35638 |\n",
      "|    std                | 0.979      |\n",
      "|    value_loss         | 8.71e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -3.66e+03 |\n",
      "|    reward             | 41.84163  |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 8.78e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 1.16e+03  |\n",
      "|    reward             | 132.30603 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 1.43e+04  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 129         |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | -884        |\n",
      "|    reward             | -0.96708685 |\n",
      "|    std                | 0.979       |\n",
      "|    value_loss         | 4.74e+04    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | -384      |\n",
      "|    reward             | -33.00663 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 1.43e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 134        |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | -762       |\n",
      "|    reward             | -239.59148 |\n",
      "|    std                | 0.981      |\n",
      "|    value_loss         | 6.12e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 136        |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | -1.77e+03  |\n",
      "|    reward             | 105.192474 |\n",
      "|    std                | 0.981      |\n",
      "|    value_loss         | 2.76e+04   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 201      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 864      |\n",
      "|    reward             | -45.6785 |\n",
      "|    std                | 0.981    |\n",
      "|    value_loss         | 1.04e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 3.65e+03  |\n",
      "|    reward             | -79.73754 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 9.12e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 143       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -1.46e+03 |\n",
      "|    reward             | -16.03391 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 2.1e+04   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 701       |\n",
      "|    reward             | -132.7767 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 1.3e+04   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -1.52e+03 |\n",
      "|    reward             | -79.94949 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 4.72e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 201      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 151      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -87.5    |\n",
      "|    reward             | -3.47275 |\n",
      "|    std                | 0.974    |\n",
      "|    value_loss         | 47.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | 1.42e+03  |\n",
      "|    reward             | 62.468727 |\n",
      "|    std                | 0.974     |\n",
      "|    value_loss         | 3.3e+04   |\n",
      "-------------------------------------\n",
      "day: 823, episode: 100\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 98294095.27\n",
      "total_reward: -31705904.73\n",
      "total_cost: 168983.19\n",
      "total_trades: 2565\n",
      "Sharpe: -0.346\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 4.14e+03  |\n",
      "|    reward             | 148.91455 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 1.46e+05  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 158        |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6399       |\n",
      "|    policy_loss        | -1.26e+03  |\n",
      "|    reward             | -13.021916 |\n",
      "|    std                | 0.974      |\n",
      "|    value_loss         | 1.3e+04    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 160       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -1.12e+04 |\n",
      "|    reward             | 92.64194  |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 6.26e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 217       |\n",
      "|    reward             | 30.509071 |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 524       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | -4.32e+03 |\n",
      "|    reward             | -99.81453 |\n",
      "|    std                | 0.972     |\n",
      "|    value_loss         | 1.55e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | 1.68e+03  |\n",
      "|    reward             | -88.00504 |\n",
      "|    std                | 0.969     |\n",
      "|    value_loss         | 3.87e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -722      |\n",
      "|    reward             | 19.800003 |\n",
      "|    std                | 0.969     |\n",
      "|    value_loss         | 1.36e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 174        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | 1.98e+03   |\n",
      "|    reward             | 123.611595 |\n",
      "|    std                | 0.969      |\n",
      "|    value_loss         | 2.91e+04   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 201      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 176      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -739     |\n",
      "|    reward             | -17.1956 |\n",
      "|    std                | 0.969    |\n",
      "|    value_loss         | 5.22e+03 |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 178        |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | 5.76e+03   |\n",
      "|    reward             | -34.628872 |\n",
      "|    std                | 0.968      |\n",
      "|    value_loss         | 2.68e+05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 181        |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | 425        |\n",
      "|    reward             | -224.84894 |\n",
      "|    std                | 0.968      |\n",
      "|    value_loss         | 5.94e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 183       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -1.32e+03 |\n",
      "|    reward             | 192.58713 |\n",
      "|    std                | 0.964     |\n",
      "|    value_loss         | 1.73e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 1.09e+03  |\n",
      "|    reward             | 20.096539 |\n",
      "|    std                | 0.963     |\n",
      "|    value_loss         | 3.54e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 7600       |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 38000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7599       |\n",
      "|    policy_loss        | -206       |\n",
      "|    reward             | -3.9433248 |\n",
      "|    std                | 0.967      |\n",
      "|    value_loss         | 863        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 191       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | -0.0013   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 4.49e+03  |\n",
      "|    reward             | 56.386044 |\n",
      "|    std                | 0.967     |\n",
      "|    value_loss         | 1.48e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 193       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -3.5e+03  |\n",
      "|    reward             | 37.264503 |\n",
      "|    std                | 0.964     |\n",
      "|    value_loss         | 1.9e+05   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 196       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -4.92e+03 |\n",
      "|    reward             | 44.5884   |\n",
      "|    std                | 0.965     |\n",
      "|    value_loss         | 2.95e+05  |\n",
      "-------------------------------------\n",
      "day: 823, episode: 110\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 93292037.83\n",
      "total_reward: -36707962.17\n",
      "total_cost: 276034.59\n",
      "total_trades: 4107\n",
      "Sharpe: -0.413\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 8000       |\n",
      "|    time_elapsed       | 198        |\n",
      "|    total_timesteps    | 40000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7999       |\n",
      "|    policy_loss        | -225       |\n",
      "|    reward             | -57.380997 |\n",
      "|    std                | 0.965      |\n",
      "|    value_loss         | 7.44e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 200       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -644      |\n",
      "|    reward             | 6.2502017 |\n",
      "|    std                | 0.96      |\n",
      "|    value_loss         | 3.49e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 203       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.3     |\n",
      "|    explained_variance | -0.119    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -2.49e+03 |\n",
      "|    reward             | 132.6004  |\n",
      "|    std                | 0.957     |\n",
      "|    value_loss         | 6.52e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 201      |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 41500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | 1.97e+03 |\n",
      "|    reward             | 63.00677 |\n",
      "|    std                | 0.959    |\n",
      "|    value_loss         | 3.74e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 208       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -929      |\n",
      "|    reward             | 50.229645 |\n",
      "|    std                | 0.957     |\n",
      "|    value_loss         | 3.62e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -3.41e+03 |\n",
      "|    reward             | -91.1572  |\n",
      "|    std                | 0.957     |\n",
      "|    value_loss         | 1.27e+05  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 213        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | 877        |\n",
      "|    reward             | -106.96547 |\n",
      "|    std                | 0.956      |\n",
      "|    value_loss         | 9.06e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 215       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.3     |\n",
      "|    explained_variance | -0.0119   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -409      |\n",
      "|    reward             | 148.88991 |\n",
      "|    std                | 0.955     |\n",
      "|    value_loss         | 4.81e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 218        |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | 4.66e+03   |\n",
      "|    reward             | -166.52586 |\n",
      "|    std                | 0.956      |\n",
      "|    value_loss         | 2.7e+05    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 220       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 777       |\n",
      "|    reward             | -2.484376 |\n",
      "|    std                | 0.955     |\n",
      "|    value_loss         | 1.29e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 223       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -3.55e+03 |\n",
      "|    reward             | 257.24957 |\n",
      "|    std                | 0.957     |\n",
      "|    value_loss         | 1.2e+05   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 210       |\n",
      "|    reward             | 263.70807 |\n",
      "|    std                | 0.959     |\n",
      "|    value_loss         | 6.61e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 201      |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 227      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 1.47e+03 |\n",
      "|    reward             | -74.3913 |\n",
      "|    std                | 0.959    |\n",
      "|    value_loss         | 3.55e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 230       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 2.54e+03  |\n",
      "|    reward             | -137.4115 |\n",
      "|    std                | 0.959     |\n",
      "|    value_loss         | 6.32e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 232       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | -276      |\n",
      "|    reward             | 13.777629 |\n",
      "|    std                | 0.96      |\n",
      "|    value_loss         | 485       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 235       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -566      |\n",
      "|    reward             | 90.97864  |\n",
      "|    std                | 0.955     |\n",
      "|    value_loss         | 8.62e+03  |\n",
      "-------------------------------------\n",
      "day: 823, episode: 120\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 98260851.25\n",
      "total_reward: -31739148.75\n",
      "total_cost: 252072.74\n",
      "total_trades: 3804\n",
      "Sharpe: -0.353\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 238        |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | -8.53e+03  |\n",
      "|    reward             | -177.69843 |\n",
      "|    std                | 0.952      |\n",
      "|    value_loss         | 3.57e+05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 240        |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | -386       |\n",
      "|    reward             | -63.418324 |\n",
      "|    std                | 0.953      |\n",
      "|    value_loss         | 8.24e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 242        |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.3      |\n",
      "|    explained_variance | -0.00419   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | -6.69e+03  |\n",
      "|    reward             | -65.212364 |\n",
      "|    std                | 0.954      |\n",
      "|    value_loss         | 2.74e+05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 201        |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 245        |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | -149       |\n",
      "|    reward             | -59.269386 |\n",
      "|    std                | 0.954      |\n",
      "|    value_loss         | 634        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 247       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.3     |\n",
      "|    explained_variance | -0.0709   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -2.5e+03  |\n",
      "|    reward             | 330.36188 |\n",
      "|    std                | 0.957     |\n",
      "|    value_loss         | 1.06e+05  |\n",
      "-------------------------------------\n",
      "hit end!\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 185       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | -0.00692  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 2.26e+03  |\n",
      "|    reward             | 247.33356 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 4.17e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 184       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 570       |\n",
      "|    reward             | 48.713665 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 9.67e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 189       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0.00721   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 1.19e+03  |\n",
      "|    reward             | -73.84778 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 1.56e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 191        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 0.00455    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -2.36e+03  |\n",
      "|    reward             | -95.770744 |\n",
      "|    std                | 0.994      |\n",
      "|    value_loss         | 3.06e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 193        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 263        |\n",
      "|    reward             | -2.0573027 |\n",
      "|    std                | 0.993      |\n",
      "|    value_loss         | 559        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 194       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0.00347   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -1.54e+03 |\n",
      "|    reward             | 312.90558 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 2.81e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 195        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | -0.00183   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | 2.83e+03   |\n",
      "|    reward             | -61.668037 |\n",
      "|    std                | 0.992      |\n",
      "|    value_loss         | 6.01e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 196       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 1.1e+03   |\n",
      "|    reward             | 22.026255 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 9.33e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 197        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 22         |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | -946       |\n",
      "|    reward             | -123.09931 |\n",
      "|    std                | 0.988      |\n",
      "|    value_loss         | 1.33e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 197       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -592      |\n",
      "|    reward             | -33.71212 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 2.26e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 198       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -0.000999 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 1.67e+03  |\n",
      "|    reward             | 213.66939 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 2.84e+04  |\n",
      "-------------------------------------\n",
      "day: 823, episode: 130\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 147280301.95\n",
      "total_reward: 17280301.95\n",
      "total_cost: 716644.84\n",
      "total_trades: 6218\n",
      "Sharpe: 0.287\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 198        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | -9.18e-06  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 4.51e+03   |\n",
      "|    reward             | -209.42726 |\n",
      "|    std                | 0.986      |\n",
      "|    value_loss         | 2.06e+05   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 199      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.6    |\n",
      "|    explained_variance | -0.00122 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 305      |\n",
      "|    reward             | 55.84721 |\n",
      "|    std                | 0.985    |\n",
      "|    value_loss         | 1.49e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 4.43e+03  |\n",
      "|    reward             | -248.1784 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 1.31e+05  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 37         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | 310        |\n",
      "|    reward             | -19.528658 |\n",
      "|    std                | 0.979      |\n",
      "|    value_loss         | 988        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0.000161  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -3.01e+03 |\n",
      "|    reward             | 108.48075 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 7.82e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 1.14e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 1.79e+03  |\n",
      "|    reward             | -303.3234 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 2.77e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 201       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -3.53e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 1.03e+03  |\n",
      "|    reward             | 363.96307 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 1.52e+05  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 47         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | -0.000143  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 805        |\n",
      "|    reward             | -251.11676 |\n",
      "|    std                | 0.978      |\n",
      "|    value_loss         | 2.31e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 49         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | 173        |\n",
      "|    reward             | -43.264908 |\n",
      "|    std                | 0.979      |\n",
      "|    value_loss         | 6.46e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 52         |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0.00021    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | 1.71e+03   |\n",
      "|    reward             | -254.79457 |\n",
      "|    std                | 0.978      |\n",
      "|    value_loss         | 2.17e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 5.97e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 3.58e+03  |\n",
      "|    reward             | 200.90117 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 7.92e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 2.28e+03  |\n",
      "|    reward             | 213.70966 |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 4.66e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | -3.3e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 6.55e+03  |\n",
      "|    reward             | -167.9549 |\n",
      "|    std                | 0.972     |\n",
      "|    value_loss         | 2.86e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 9.78e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -596      |\n",
      "|    reward             | 62.005066 |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 8.18e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 1.46e+03  |\n",
      "|    reward             | 159.00452 |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 1.3e+04   |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 200         |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 67          |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | 43          |\n",
      "|    reward             | -101.095825 |\n",
      "|    std                | 0.975       |\n",
      "|    value_loss         | 1.23e+04    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -2.44e+03 |\n",
      "|    reward             | 96.27352  |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 3.7e+04   |\n",
      "-------------------------------------\n",
      "day: 823, episode: 140\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 121606505.28\n",
      "total_reward: -8393494.72\n",
      "total_cost: 628528.89\n",
      "total_trades: 5988\n",
      "Sharpe: 0.026\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 2900       |\n",
      "|    time_elapsed       | 72         |\n",
      "|    total_timesteps    | 14500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2899       |\n",
      "|    policy_loss        | -2.35e+03  |\n",
      "|    reward             | 100.586426 |\n",
      "|    std                | 0.978      |\n",
      "|    value_loss         | 4.41e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 74         |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | 46.9       |\n",
      "|    reward             | -13.277795 |\n",
      "|    std                | 0.975      |\n",
      "|    value_loss         | 1.11e+04   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 200      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 1.13e+03 |\n",
      "|    reward             | 387.1046 |\n",
      "|    std                | 0.973    |\n",
      "|    value_loss         | 9.65e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | -4.29e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -435      |\n",
      "|    reward             | 4.988488  |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 1.19e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 42.1      |\n",
      "|    reward             | 18.487566 |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 25.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 3400       |\n",
      "|    time_elapsed       | 84         |\n",
      "|    total_timesteps    | 17000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3399       |\n",
      "|    policy_loss        | -177       |\n",
      "|    reward             | -182.45201 |\n",
      "|    std                | 0.972      |\n",
      "|    value_loss         | 9.15e+03   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 199      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 1.05e+03 |\n",
      "|    reward             | 78.38318 |\n",
      "|    std                | 0.968    |\n",
      "|    value_loss         | 2.03e+04 |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 3600       |\n",
      "|    time_elapsed       | 90         |\n",
      "|    total_timesteps    | 18000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3599       |\n",
      "|    policy_loss        | -727       |\n",
      "|    reward             | -103.75267 |\n",
      "|    std                | 0.974      |\n",
      "|    value_loss         | 6.77e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 92        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 1.55e-06  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 1.93e+03  |\n",
      "|    reward             | -47.96754 |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 4.07e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 129       |\n",
      "|    reward             | 5.3871326 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 157       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | -3.93e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 165       |\n",
      "|    reward             | -72.35284 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 2.79e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 199      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.5    |\n",
      "|    explained_variance | 2.15e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 2.65e+03 |\n",
      "|    reward             | 317.5433 |\n",
      "|    std                | 0.974    |\n",
      "|    value_loss         | 6.95e+04 |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 102        |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | 366        |\n",
      "|    reward             | -87.132385 |\n",
      "|    std                | 0.974      |\n",
      "|    value_loss         | 1.98e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | -2.74e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 4.12e+03  |\n",
      "|    reward             | 70.46563  |\n",
      "|    std                | 0.974     |\n",
      "|    value_loss         | 1.25e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | -1.08e+03 |\n",
      "|    reward             | 25.960463 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 8.46e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 110        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | -1.01e+03  |\n",
      "|    reward             | -4.4033756 |\n",
      "|    std                | 0.974      |\n",
      "|    value_loss         | 3.66e+04   |\n",
      "--------------------------------------\n",
      "day: 823, episode: 150\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 134744613.62\n",
      "total_reward: 4744613.62\n",
      "total_cost: 549141.83\n",
      "total_trades: 5890\n",
      "Sharpe: 0.150\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 4500       |\n",
      "|    time_elapsed       | 112        |\n",
      "|    total_timesteps    | 22500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4499       |\n",
      "|    policy_loss        | -4.54e+03  |\n",
      "|    reward             | -47.850174 |\n",
      "|    std                | 0.975      |\n",
      "|    value_loss         | 1.39e+05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 115        |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4599       |\n",
      "|    policy_loss        | -816       |\n",
      "|    reward             | -417.62723 |\n",
      "|    std                | 0.975      |\n",
      "|    value_loss         | 3.28e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -1.87e+03 |\n",
      "|    reward             | 105.49992 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 4.82e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 199      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 120      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 1.28e+03 |\n",
      "|    reward             | 151.2457 |\n",
      "|    std                | 0.978    |\n",
      "|    value_loss         | 1.48e+04 |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 4900       |\n",
      "|    time_elapsed       | 122        |\n",
      "|    total_timesteps    | 24500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | -1.25e-05  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4899       |\n",
      "|    policy_loss        | -1.2e+03   |\n",
      "|    reward             | -109.54435 |\n",
      "|    std                | 0.978      |\n",
      "|    value_loss         | 1.27e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 5000       |\n",
      "|    time_elapsed       | 125        |\n",
      "|    total_timesteps    | 25000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4999       |\n",
      "|    policy_loss        | -561       |\n",
      "|    reward             | -11.951443 |\n",
      "|    std                | 0.98       |\n",
      "|    value_loss         | 7.75e+03   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 127       |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -7.68e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 2.31e+03  |\n",
      "|    reward             | 134.42877 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 4.38e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | -8.34e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | -1.23e+03 |\n",
      "|    reward             | 39.75071  |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 1.66e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 5300       |\n",
      "|    time_elapsed       | 132        |\n",
      "|    total_timesteps    | 26500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5299       |\n",
      "|    policy_loss        | -449       |\n",
      "|    reward             | -11.870306 |\n",
      "|    std                | 0.981      |\n",
      "|    value_loss         | 2.13e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 5400       |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 27000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5399       |\n",
      "|    policy_loss        | -2.32e+03  |\n",
      "|    reward             | -151.19019 |\n",
      "|    std                | 0.979      |\n",
      "|    value_loss         | 4.95e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 111       |\n",
      "|    reward             | 247.00867 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 1.1e+04   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 140        |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | 3.5e+03    |\n",
      "|    reward             | -88.300865 |\n",
      "|    std                | 0.976      |\n",
      "|    value_loss         | 8.92e+04   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 5700       |\n",
      "|    time_elapsed       | 142        |\n",
      "|    total_timesteps    | 28500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | -0.000378  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5699       |\n",
      "|    policy_loss        | -1.14e+03  |\n",
      "|    reward             | -109.06578 |\n",
      "|    std                | 0.974      |\n",
      "|    value_loss         | 1.29e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 145       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 1.06e-05  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | -678      |\n",
      "|    reward             | 115.78086 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 8.81e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 1.92e+03  |\n",
      "|    reward             | -75.26913 |\n",
      "|    std                | 0.974     |\n",
      "|    value_loss         | 3.14e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0.000145  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -5.78e+03 |\n",
      "|    reward             | 179.07828 |\n",
      "|    std                | 0.972     |\n",
      "|    value_loss         | 2.51e+05  |\n",
      "-------------------------------------\n",
      "day: 823, episode: 160\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123695360.21\n",
      "total_reward: -6304639.79\n",
      "total_cost: 385681.81\n",
      "total_trades: 4574\n",
      "Sharpe: 0.102\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 6100       |\n",
      "|    time_elapsed       | 152        |\n",
      "|    total_timesteps    | 30500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6099       |\n",
      "|    policy_loss        | -228       |\n",
      "|    reward             | -4.2316623 |\n",
      "|    std                | 0.97       |\n",
      "|    value_loss         | 275        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -1.39e+03 |\n",
      "|    reward             | 86.25304  |\n",
      "|    std                | 0.969     |\n",
      "|    value_loss         | 3.45e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 1.32e+03  |\n",
      "|    reward             | 289.44922 |\n",
      "|    std                | 0.971     |\n",
      "|    value_loss         | 1.74e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 160        |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6399       |\n",
      "|    policy_loss        | 705        |\n",
      "|    reward             | -130.04817 |\n",
      "|    std                | 0.972      |\n",
      "|    value_loss         | 5.69e+03   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 199      |\n",
      "|    iterations         | 6500     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 32500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6499     |\n",
      "|    policy_loss        | -4.1e+03 |\n",
      "|    reward             | 22.27852 |\n",
      "|    std                | 0.969    |\n",
      "|    value_loss         | 1.72e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 171       |\n",
      "|    reward             | 29.750465 |\n",
      "|    std                | 0.967     |\n",
      "|    value_loss         | 725       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 6700       |\n",
      "|    time_elapsed       | 167        |\n",
      "|    total_timesteps    | 33500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6699       |\n",
      "|    policy_loss        | 2.83e+03   |\n",
      "|    reward             | -4.4791846 |\n",
      "|    std                | 0.964      |\n",
      "|    value_loss         | 5.38e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 169       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | -42.5     |\n",
      "|    reward             | -97.43297 |\n",
      "|    std                | 0.961     |\n",
      "|    value_loss         | 3.57e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 200       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -60.4     |\n",
      "|    reward             | -93.01104 |\n",
      "|    std                | 0.962     |\n",
      "|    value_loss         | 3.54e+03  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 174        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.4      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | -1.09e+03  |\n",
      "|    reward             | 123.389496 |\n",
      "|    std                | 0.963      |\n",
      "|    value_loss         | 2.64e+04   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 199      |\n",
      "|    iterations         | 7100     |\n",
      "|    time_elapsed       | 177      |\n",
      "|    total_timesteps    | 35500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7099     |\n",
      "|    policy_loss        | -525     |\n",
      "|    reward             | 6.826555 |\n",
      "|    std                | 0.962    |\n",
      "|    value_loss         | 4.85e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -2.6e+03  |\n",
      "|    reward             | -96.95366 |\n",
      "|    std                | 0.961     |\n",
      "|    value_loss         | 6.79e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 182        |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | 642        |\n",
      "|    reward             | -234.73578 |\n",
      "|    std                | 0.962      |\n",
      "|    value_loss         | 1.33e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 185       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -3.71e+03 |\n",
      "|    reward             | 299.68552 |\n",
      "|    std                | 0.965     |\n",
      "|    value_loss         | 1.17e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 5.96e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 981       |\n",
      "|    reward             | -91.14383 |\n",
      "|    std                | 0.963     |\n",
      "|    value_loss         | 1.42e+05  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 200        |\n",
      "|    iterations         | 7600       |\n",
      "|    time_elapsed       | 189        |\n",
      "|    total_timesteps    | 38000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7599       |\n",
      "|    policy_loss        | -27.9      |\n",
      "|    reward             | -2.8647735 |\n",
      "|    std                | 0.961      |\n",
      "|    value_loss         | 882        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 192       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 3.17e+03  |\n",
      "|    reward             | 141.28293 |\n",
      "|    std                | 0.961     |\n",
      "|    value_loss         | 9.19e+04  |\n",
      "-------------------------------------\n",
      "day: 823, episode: 170\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 105769294.79\n",
      "total_reward: -24230705.21\n",
      "total_cost: 313401.61\n",
      "total_trades: 5494\n",
      "Sharpe: -0.131\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 195       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | -1.19e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -5.58e+03 |\n",
      "|    reward             | 104.12119 |\n",
      "|    std                | 0.963     |\n",
      "|    value_loss         | 3.2e+05   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 197       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -5.7e+03  |\n",
      "|    reward             | 67.146286 |\n",
      "|    std                | 0.964     |\n",
      "|    value_loss         | 3.64e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 200       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -1.15e+03 |\n",
      "|    reward             | -40.46634 |\n",
      "|    std                | 0.965     |\n",
      "|    value_loss         | 1.81e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 202       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -198      |\n",
      "|    reward             | 39.912525 |\n",
      "|    std                | 0.963     |\n",
      "|    value_loss         | 1.79e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 199      |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 205      |\n",
      "|    total_timesteps    | 41000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | 868      |\n",
      "|    reward             | 5.797482 |\n",
      "|    std                | 0.963    |\n",
      "|    value_loss         | 1.18e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 2.29e+03  |\n",
      "|    reward             | 32.104214 |\n",
      "|    std                | 0.965     |\n",
      "|    value_loss         | 6.88e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 1.33e+03  |\n",
      "|    reward             | 17.312155 |\n",
      "|    std                | 0.966     |\n",
      "|    value_loss         | 1.96e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 212       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | -6.68e+03 |\n",
      "|    reward             | -47.63963 |\n",
      "|    std                | 0.968     |\n",
      "|    value_loss         | 3.94e+05  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 8600       |\n",
      "|    time_elapsed       | 215        |\n",
      "|    total_timesteps    | 43000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8599       |\n",
      "|    policy_loss        | -456       |\n",
      "|    reward             | -128.69778 |\n",
      "|    std                | 0.968      |\n",
      "|    value_loss         | 3.25e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 8700       |\n",
      "|    time_elapsed       | 217        |\n",
      "|    total_timesteps    | 43500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8699       |\n",
      "|    policy_loss        | -1.1e+03   |\n",
      "|    reward             | -4.7977867 |\n",
      "|    std                | 0.969      |\n",
      "|    value_loss         | 7.82e+03   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 199         |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | 2.95e+03    |\n",
      "|    reward             | -107.947685 |\n",
      "|    std                | 0.97        |\n",
      "|    value_loss         | 5.43e+04    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 222        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 4.77e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | -636       |\n",
      "|    reward             | -1.7976525 |\n",
      "|    std                | 0.971      |\n",
      "|    value_loss         | 5.9e+03    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 225       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -1.36e+03 |\n",
      "|    reward             | 130.64403 |\n",
      "|    std                | 0.969     |\n",
      "|    value_loss         | 4.3e+04   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 1.22e+03  |\n",
      "|    reward             | 169.18295 |\n",
      "|    std                | 0.969     |\n",
      "|    value_loss         | 1.24e+04  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 230        |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | 2.01e+03   |\n",
      "|    reward             | -15.776354 |\n",
      "|    std                | 0.971      |\n",
      "|    value_loss         | 3.11e+04   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 232       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | -512      |\n",
      "|    reward             | 49.560192 |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 2.15e+04  |\n",
      "-------------------------------------\n",
      "day: 823, episode: 180\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 116821160.32\n",
      "total_reward: -13178839.68\n",
      "total_cost: 233287.05\n",
      "total_trades: 5842\n",
      "Sharpe: -0.002\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 235       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 315       |\n",
      "|    reward             | 23.632711 |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 817       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 237       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -5.37e+03 |\n",
      "|    reward             | 132.07996 |\n",
      "|    std                | 0.97      |\n",
      "|    value_loss         | 1.57e+05  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 240        |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | -3.58e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | -983       |\n",
      "|    reward             | -249.30574 |\n",
      "|    std                | 0.969      |\n",
      "|    value_loss         | 2.8e+04    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 9700       |\n",
      "|    time_elapsed       | 242        |\n",
      "|    total_timesteps    | 48500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9699       |\n",
      "|    policy_loss        | -721       |\n",
      "|    reward             | -114.28076 |\n",
      "|    std                | 0.969      |\n",
      "|    value_loss         | 4.04e+03   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 199        |\n",
      "|    iterations         | 9800       |\n",
      "|    time_elapsed       | 245        |\n",
      "|    total_timesteps    | 49000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 7.75e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9799       |\n",
      "|    policy_loss        | -7.67e+03  |\n",
      "|    reward             | -53.161835 |\n",
      "|    std                | 0.968      |\n",
      "|    value_loss         | 3.99e+05   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 247       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -226      |\n",
      "|    reward             | -46.09018 |\n",
      "|    std                | 0.965     |\n",
      "|    value_loss         | 1.94e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 199       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 250       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -2.42e+03 |\n",
      "|    reward             | 46.937164 |\n",
      "|    std                | 0.961     |\n",
      "|    value_loss         | 8.31e+04  |\n",
      "-------------------------------------\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_a2c_arr, df_actions_a2c_arr = [], []\n",
    "\n",
    "for seed in tqdm(SEEDS, desc='All seeds', leave=True): # Looping from the given seeds\n",
    "\n",
    "  # Train\n",
    "  random.seed(seed); np.random.seed(seed) ; env_train.seed(seed)\n",
    "  agent = DRLAgent(env = env_train)\n",
    "  model_a2c = agent.get_model(\"a2c\")\n",
    "  trained_a2c = agent.train_model(model=model_a2c, \n",
    "                              tb_log_name='a2c',\n",
    "                              total_timesteps=50000)\n",
    "\n",
    "  trained_a2c.save('trained_a2c.model') # save the model\n",
    "\n",
    "  # Prediction\n",
    "  df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c, \n",
    "    environment = e_trade_gym)\n",
    "  df_account_value_a2c.shape\n",
    "  df_account_value_a2c.tail()\n",
    "  df_actions_a2c.head()\n",
    "  df_account_value_a2c_arr.append(df_account_value_a2c)\n",
    "  df_actions_a2c_arr.append(df_actions_a2c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdnktBGyZyea",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# A2C for trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ecthuIQQ9CTj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_account_value_a2c_con = pd.concat((df_account_value_a2c_arr))\n",
    "df_actions_a2c_con = pd.concat((df_actions_a2c_arr))\n",
    "\n",
    "df_account_value_a2c_con_idx = df_account_value_a2c_con.groupby(df_account_value_a2c_con.index)\n",
    "df_actions_a2c_con_idx = df_actions_a2c_con.groupby(df_actions_a2c_con.index)\n",
    "\n",
    "df_account_value_means_a2c = df_account_value_a2c_con_idx.mean()\n",
    "df_actions_means_a2c = df_actions_a2c_con_idx.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2KguXWMIEt_i",
    "outputId": "60f9a9f1-7703-45ed-8e2f-f12963d31489",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2623ffaa-1c4a-4c20-8874-d85f9010b011\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>1.408302e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>1.416708e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>1.414718e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>1.422813e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>1.428322e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2623ffaa-1c4a-4c20-8874-d85f9010b011')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2623ffaa-1c4a-4c20-8874-d85f9010b011 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2623ffaa-1c4a-4c20-8874-d85f9010b011');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           date  account_value\n",
       "312  2021-10-25   1.408302e+08\n",
       "313  2021-10-26   1.416708e+08\n",
       "314  2021-10-27   1.414718e+08\n",
       "315  2021-10-28   1.422813e+08\n",
       "316  2021-10-29   1.428322e+08"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_means_a2c['date'] = df_account_value_a2c_arr[0]['date']\n",
    "df_account_value_means_a2c = df_account_value_means_a2c[['date', 'account_value']]\n",
    "df_account_value_means_a2c.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OB_5WbHdEucK",
    "outputId": "25abb584-442f-4e97-b79d-653cf049e6f7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f6031565-c204-4a1e-8752-cad29cdddc08\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1301</th>\n",
       "      <th>1332</th>\n",
       "      <th>1333</th>\n",
       "      <th>1376</th>\n",
       "      <th>1377</th>\n",
       "      <th>1379</th>\n",
       "      <th>1407</th>\n",
       "      <th>1414</th>\n",
       "      <th>1417</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>78.333333</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>94.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>78.333333</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>94.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>78.333333</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>94.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-07</th>\n",
       "      <td>78.333333</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>94.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-08</th>\n",
       "      <td>78.333333</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>94.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-22</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>42.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>-36.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-25</th>\n",
       "      <td>11.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>-3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-26</th>\n",
       "      <td>-21.666667</td>\n",
       "      <td>27.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-33.333333</td>\n",
       "      <td>-24.333333</td>\n",
       "      <td>-32.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>42.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>-36.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-28</th>\n",
       "      <td>11.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>-3.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows × 9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6031565-c204-4a1e-8752-cad29cdddc08')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f6031565-c204-4a1e-8752-cad29cdddc08 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f6031565-c204-4a1e-8752-cad29cdddc08');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                 1301       1332       1333       1376       1377       1379  \\\n",
       "date                                                                           \n",
       "2020-07-01  78.333333  75.666667  94.333333  66.666667  33.333333  66.666667   \n",
       "2020-07-02  78.333333  75.666667  94.333333  66.666667  33.333333  66.666667   \n",
       "2020-07-06  78.333333  75.666667  94.333333  66.666667  33.333333  66.666667   \n",
       "2020-07-07  78.333333  75.666667  94.333333  66.666667  33.333333  66.666667   \n",
       "2020-07-08  78.333333  75.666667  94.333333  66.666667  33.333333  66.666667   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2021-10-22  45.000000  42.333333  66.666667  33.333333  33.333333  33.333333   \n",
       "2021-10-25  11.666667  33.333333  33.333333   0.000000   0.000000   0.000000   \n",
       "2021-10-26 -21.666667  27.333333   0.000000 -33.333333 -33.333333 -33.333333   \n",
       "2021-10-27  45.000000  42.333333  66.666667  33.333333  33.333333  33.333333   \n",
       "2021-10-28  11.666667  33.333333  33.333333   0.000000   0.000000   0.000000   \n",
       "\n",
       "                 1407       1414       1417  \n",
       "date                                         \n",
       "2020-07-01  19.666667  33.333333  33.333333  \n",
       "2020-07-02  19.666667  33.333333  33.333333  \n",
       "2020-07-06  19.666667  33.333333  33.333333  \n",
       "2020-07-07  19.666667  33.333333  33.333333  \n",
       "2020-07-08  19.666667  33.333333  33.333333  \n",
       "...               ...        ...        ...  \n",
       "2021-10-22  19.666667  34.666667 -36.666667  \n",
       "2021-10-25   0.000000   6.333333  -3.333333  \n",
       "2021-10-26 -24.333333 -32.000000  30.000000  \n",
       "2021-10-27  19.666667  34.666667 -36.666667  \n",
       "2021-10-28   0.000000   7.333333  -3.333333  \n",
       "\n",
       "[316 rows x 9 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions_means_a2c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwnQ1YnpRUJR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## BackTestStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "AZ2aOKKmDxZ0",
    "outputId": "2d867cb3-dd2d-4cae-b83e-4759555fcbf9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.077705\n",
      "Cumulative returns     0.098709\n",
      "Annual volatility      0.226633\n",
      "Sharpe ratio           0.443713\n",
      "Calmar ratio           0.494519\n",
      "Stability              0.567642\n",
      "Max drawdown          -0.157132\n",
      "Omega ratio            1.148725\n",
      "Sortino ratio          0.667177\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.073617\n",
      "Daily value at risk   -0.028154\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all_a2c = backtest_stats(account_value=df_account_value_means_a2c)\n",
    "perf_stats_all_a2c = pd.DataFrame(perf_stats_all_a2c)\n",
    "perf_stats_all_a2c.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "znxjMClCZdPk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_a2c = df_account_value_means_a2c.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "DSI4P3M8Zfic",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_a2c.index = pd.to_datetime(df_date_a2c.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LYdiuqe2Zfti",
    "outputId": "dddcbc3f-fb55-4aec-b39a-909f99cbbbe8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f160bb6b910>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_date_a2c.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "FinIqzi2Zf1e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_a2c.to_csv(\"a2c_account_value.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "72Q3_0LxC792",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del df_account_value_a2c_arr ; del df_actions_a2c_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwoEMtMW9b4z",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3917f16065374e16a14e59097b4d7488"
     ]
    },
    "id": "FsTSGTFq9h36",
    "outputId": "2752738d-5746-4d6c-806b-d276ce3d1ecc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3917f16065374e16a14e59097b4d7488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All seeds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 93         |\n",
      "|    time_elapsed    | 35         |\n",
      "|    total_timesteps | 3296       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.83e+05   |\n",
      "|    critic_loss     | 3.6e+07    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 2472       |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 190\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 137335870.68\n",
      "total_reward: 7335870.68\n",
      "total_cost: 186380.62\n",
      "total_trades: 4293\n",
      "Sharpe: 0.204\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 82         |\n",
      "|    time_elapsed    | 79         |\n",
      "|    total_timesteps | 6592       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 9.12e+04   |\n",
      "|    critic_loss     | 1.34e+08   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 5768       |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 79         |\n",
      "|    time_elapsed    | 123        |\n",
      "|    total_timesteps | 9888       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 5.82e+04   |\n",
      "|    critic_loss     | 4.32e+07   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 9064       |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 200\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 137335870.68\n",
      "total_reward: 7335870.68\n",
      "total_cost: 186380.62\n",
      "total_trades: 4293\n",
      "Sharpe: 0.204\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 78         |\n",
      "|    time_elapsed    | 167        |\n",
      "|    total_timesteps | 13184      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 4.17e+04   |\n",
      "|    critic_loss     | 2.09e+07   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 12360      |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 20         |\n",
      "|    fps             | 78         |\n",
      "|    time_elapsed    | 211        |\n",
      "|    total_timesteps | 16480      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.71e+04   |\n",
      "|    critic_loss     | 1.38e+07   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 15656      |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 24         |\n",
      "|    fps             | 77         |\n",
      "|    time_elapsed    | 255        |\n",
      "|    total_timesteps | 19776      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.17e+04   |\n",
      "|    critic_loss     | 1.38e+07   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 18952      |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 210\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 137335870.68\n",
      "total_reward: 7335870.68\n",
      "total_cost: 186380.62\n",
      "total_trades: 4293\n",
      "Sharpe: 0.204\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 28         |\n",
      "|    fps             | 77         |\n",
      "|    time_elapsed    | 299        |\n",
      "|    total_timesteps | 23072      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.41e+04   |\n",
      "|    critic_loss     | 4.59e+06   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 22248      |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 32         |\n",
      "|    fps             | 76         |\n",
      "|    time_elapsed    | 343        |\n",
      "|    total_timesteps | 26368      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 9.1e+03    |\n",
      "|    critic_loss     | 1.78e+06   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 25544      |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 220\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 137335870.68\n",
      "total_reward: 7335870.68\n",
      "total_cost: 186380.62\n",
      "total_trades: 4293\n",
      "Sharpe: 0.204\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 36         |\n",
      "|    fps             | 76         |\n",
      "|    time_elapsed    | 387        |\n",
      "|    total_timesteps | 29664      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 5.16e+03   |\n",
      "|    critic_loss     | 1.7e+06    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 28840      |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 40         |\n",
      "|    fps             | 76         |\n",
      "|    time_elapsed    | 431        |\n",
      "|    total_timesteps | 32960      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.31e+03   |\n",
      "|    critic_loss     | 1.03e+05   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 32136      |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 44         |\n",
      "|    fps             | 76         |\n",
      "|    time_elapsed    | 474        |\n",
      "|    total_timesteps | 36256      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.33e+03   |\n",
      "|    critic_loss     | 3.14e+04   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 35432      |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 230\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 137335870.68\n",
      "total_reward: 7335870.68\n",
      "total_cost: 186380.62\n",
      "total_trades: 4293\n",
      "Sharpe: 0.204\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 48         |\n",
      "|    fps             | 76         |\n",
      "|    time_elapsed    | 519        |\n",
      "|    total_timesteps | 39552      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.73e+03   |\n",
      "|    critic_loss     | 3.76e+04   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 38728      |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 52         |\n",
      "|    fps             | 76         |\n",
      "|    time_elapsed    | 563        |\n",
      "|    total_timesteps | 42848      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.38e+03   |\n",
      "|    critic_loss     | 2.11e+04   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 42024      |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 240\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 137335870.68\n",
      "total_reward: 7335870.68\n",
      "total_cost: 186380.62\n",
      "total_trades: 4293\n",
      "Sharpe: 0.204\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 56         |\n",
      "|    fps             | 75         |\n",
      "|    time_elapsed    | 607        |\n",
      "|    total_timesteps | 46144      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.13e+03   |\n",
      "|    critic_loss     | 2.13e+04   |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 45320      |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 60         |\n",
      "|    fps             | 75         |\n",
      "|    time_elapsed    | 651        |\n",
      "|    total_timesteps | 49440      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 934        |\n",
      "|    critic_loss     | 1.8e+04    |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 48616      |\n",
      "|    reward          | -25.454384 |\n",
      "-----------------------------------\n",
      "hit end!\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "day: 823, episode: 250\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123139016.98\n",
      "total_reward: -6860983.02\n",
      "total_cost: 129870.13\n",
      "total_trades: 1646\n",
      "Sharpe: 0.017\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 93        |\n",
      "|    time_elapsed    | 35        |\n",
      "|    total_timesteps | 3296      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -6.37e+04 |\n",
      "|    critic_loss     | 1.09e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 2472      |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 83        |\n",
      "|    time_elapsed    | 78        |\n",
      "|    total_timesteps | 6592      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.49e+04 |\n",
      "|    critic_loss     | 4.66e+05  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 5768      |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 80        |\n",
      "|    time_elapsed    | 122       |\n",
      "|    total_timesteps | 9888      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -3.58e+04 |\n",
      "|    critic_loss     | 4.88e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 9064      |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "day: 823, episode: 260\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123139016.98\n",
      "total_reward: -6860983.02\n",
      "total_cost: 129870.13\n",
      "total_trades: 1646\n",
      "Sharpe: 0.017\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 78        |\n",
      "|    time_elapsed    | 167       |\n",
      "|    total_timesteps | 13184     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.79e+04 |\n",
      "|    critic_loss     | 3.48e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 12360     |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 78        |\n",
      "|    time_elapsed    | 211       |\n",
      "|    total_timesteps | 16480     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.57e+04 |\n",
      "|    critic_loss     | 5.17e+05  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 15656     |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "day: 823, episode: 270\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123139016.98\n",
      "total_reward: -6860983.02\n",
      "total_cost: 129870.13\n",
      "total_trades: 1646\n",
      "Sharpe: 0.017\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 77        |\n",
      "|    time_elapsed    | 255       |\n",
      "|    total_timesteps | 19776     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.02e+04 |\n",
      "|    critic_loss     | 6.68e+05  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 18952     |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 77        |\n",
      "|    time_elapsed    | 298       |\n",
      "|    total_timesteps | 23072     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.5e+04  |\n",
      "|    critic_loss     | 2.26e+05  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 22248     |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 342       |\n",
      "|    total_timesteps | 26368     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.05e+04 |\n",
      "|    critic_loss     | 2.06e+05  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 25544     |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "day: 823, episode: 280\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123139016.98\n",
      "total_reward: -6860983.02\n",
      "total_cost: 129870.13\n",
      "total_trades: 1646\n",
      "Sharpe: 0.017\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 386       |\n",
      "|    total_timesteps | 29664     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -7.42e+03 |\n",
      "|    critic_loss     | 9e+04     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 28840     |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 40        |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 429       |\n",
      "|    total_timesteps | 32960     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.86e+03 |\n",
      "|    critic_loss     | 1.16e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 32136     |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "day: 823, episode: 290\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123139016.98\n",
      "total_reward: -6860983.02\n",
      "total_cost: 129870.13\n",
      "total_trades: 1646\n",
      "Sharpe: 0.017\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 44        |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 473       |\n",
      "|    total_timesteps | 36256     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.89e+03 |\n",
      "|    critic_loss     | 5.61e+04  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 35432     |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 48        |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 516       |\n",
      "|    total_timesteps | 39552     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.91e+03 |\n",
      "|    critic_loss     | 5.69e+04  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 38728     |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 52        |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 560       |\n",
      "|    total_timesteps | 42848     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.08e+03 |\n",
      "|    critic_loss     | 6.7e+03   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 42024     |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "day: 823, episode: 300\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123139016.98\n",
      "total_reward: -6860983.02\n",
      "total_cost: 129870.13\n",
      "total_trades: 1646\n",
      "Sharpe: 0.017\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 56        |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 604       |\n",
      "|    total_timesteps | 46144     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -631      |\n",
      "|    critic_loss     | 2.04e+04  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 45320     |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 60        |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 648       |\n",
      "|    total_timesteps | 49440     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -312      |\n",
      "|    critic_loss     | 2.01e+04  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 48616     |\n",
      "|    reward          | -5.982064 |\n",
      "----------------------------------\n",
      "hit end!\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "day: 823, episode: 310\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 145163284.07\n",
      "total_reward: 15163284.07\n",
      "total_cost: 316078.59\n",
      "total_trades: 4242\n",
      "Sharpe: 0.265\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 94        |\n",
      "|    time_elapsed    | 35        |\n",
      "|    total_timesteps | 3296      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1e+05    |\n",
      "|    critic_loss     | 2.09e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 2472      |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 84        |\n",
      "|    time_elapsed    | 78        |\n",
      "|    total_timesteps | 6592      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -6.09e+04 |\n",
      "|    critic_loss     | 2.3e+08   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 5768      |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "day: 823, episode: 320\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 117245967.14\n",
      "total_reward: -12754032.86\n",
      "total_cost: 129870.13\n",
      "total_trades: 2312\n",
      "Sharpe: 0.065\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 81        |\n",
      "|    time_elapsed    | 121       |\n",
      "|    total_timesteps | 9888      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.3e+04  |\n",
      "|    critic_loss     | 8.58e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 9064      |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 79        |\n",
      "|    time_elapsed    | 165       |\n",
      "|    total_timesteps | 13184     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -3.47e+04 |\n",
      "|    critic_loss     | 3.2e+06   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 12360     |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 78        |\n",
      "|    time_elapsed    | 208       |\n",
      "|    total_timesteps | 16480     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.76e+04 |\n",
      "|    critic_loss     | 2.19e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 15656     |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "day: 823, episode: 330\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 117245967.14\n",
      "total_reward: -12754032.86\n",
      "total_cost: 129870.13\n",
      "total_trades: 2312\n",
      "Sharpe: 0.065\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 78        |\n",
      "|    time_elapsed    | 252       |\n",
      "|    total_timesteps | 19776     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.09e+04 |\n",
      "|    critic_loss     | 4.02e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 18952     |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 78        |\n",
      "|    time_elapsed    | 295       |\n",
      "|    total_timesteps | 23072     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.58e+04 |\n",
      "|    critic_loss     | 4.18e+04  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 22248     |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "day: 823, episode: 340\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 117245967.14\n",
      "total_reward: -12754032.86\n",
      "total_cost: 129870.13\n",
      "total_trades: 2312\n",
      "Sharpe: 0.065\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 77        |\n",
      "|    time_elapsed    | 338       |\n",
      "|    total_timesteps | 26368     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -9.08e+03 |\n",
      "|    critic_loss     | 5.47e+04  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 25544     |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 77        |\n",
      "|    time_elapsed    | 382       |\n",
      "|    total_timesteps | 29664     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -6.35e+03 |\n",
      "|    critic_loss     | 3.46e+05  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 28840     |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 40        |\n",
      "|    fps             | 77        |\n",
      "|    time_elapsed    | 426       |\n",
      "|    total_timesteps | 32960     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.07e+03 |\n",
      "|    critic_loss     | 3.84e+05  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 32136     |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "day: 823, episode: 350\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 117245967.14\n",
      "total_reward: -12754032.86\n",
      "total_cost: 129870.13\n",
      "total_trades: 2312\n",
      "Sharpe: 0.065\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 44        |\n",
      "|    fps             | 77        |\n",
      "|    time_elapsed    | 470       |\n",
      "|    total_timesteps | 36256     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -2.56e+03 |\n",
      "|    critic_loss     | 9.09e+05  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 35432     |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 48        |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 514       |\n",
      "|    total_timesteps | 39552     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.64e+03 |\n",
      "|    critic_loss     | 1.52e+04  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 38728     |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "day: 823, episode: 360\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 117245967.14\n",
      "total_reward: -12754032.86\n",
      "total_cost: 129870.13\n",
      "total_trades: 2312\n",
      "Sharpe: 0.065\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 52        |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 557       |\n",
      "|    total_timesteps | 42848     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 83.3      |\n",
      "|    critic_loss     | 1.6e+04   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 42024     |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 56        |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 601       |\n",
      "|    total_timesteps | 46144     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 206       |\n",
      "|    critic_loss     | 1.72e+04  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 45320     |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 60        |\n",
      "|    fps             | 76        |\n",
      "|    time_elapsed    | 645       |\n",
      "|    total_timesteps | 49440     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 272       |\n",
      "|    critic_loss     | 1.06e+04  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 48616     |\n",
      "|    reward          | -98.65315 |\n",
      "----------------------------------\n",
      "day: 823, episode: 370\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 117245967.14\n",
      "total_reward: -12754032.86\n",
      "total_cost: 129870.13\n",
      "total_trades: 2312\n",
      "Sharpe: 0.065\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "env_train.reset()\n",
    "df_account_value_ddpg_arr, df_actions_ddpg_arr = [], []\n",
    "\n",
    "for seed in tqdm(SEEDS, desc='All seeds', leave=True): # Looping from the given seeds\n",
    "\n",
    "  # Train\n",
    "  random.seed(seed); np.random.seed(seed) ; env_train.seed(seed)\n",
    "  agent = DRLAgent(env = env_train)\n",
    "  model_ddpg = agent.get_model(\"ddpg\")\n",
    "  trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)\n",
    "\n",
    "  trained_ddpg.save('trained_ddpg.model') # save the model\n",
    "\n",
    "  # Prediction\n",
    "  df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym)\n",
    "  df_account_value_ddpg.shape\n",
    "  df_account_value_ddpg.tail()\n",
    "  df_actions_ddpg.head()\n",
    "  df_account_value_ddpg_arr.append(df_account_value_ddpg)\n",
    "  df_actions_ddpg_arr.append(df_actions_ddpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppisH0e_mkEm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DDPG for trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tgad_5nwmJGL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_account_value_ddpg_con = pd.concat((df_account_value_ddpg_arr))\n",
    "df_actions_ddpg_con = pd.concat((df_actions_ddpg_arr))\n",
    "\n",
    "df_account_value_ddpg_con_idx = df_account_value_ddpg_con.groupby(df_account_value_ddpg_con.index)\n",
    "df_actions_ddpg_con_idx = df_actions_ddpg_con.groupby(df_actions_ddpg_con.index)\n",
    "\n",
    "df_account_value_means_ddpg = df_account_value_ddpg_con_idx.mean()\n",
    "df_actions_means_ddpg = df_actions_ddpg_con_idx.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "nJ9UzpipmJLv",
    "outputId": "45c4f958-e426-4729-afce-4dd2ba341b7d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-75e879f2-ea14-426b-a7df-2577d3df5311\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>1.405996e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>1.415434e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>1.411906e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>1.419629e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>1.435569e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75e879f2-ea14-426b-a7df-2577d3df5311')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-75e879f2-ea14-426b-a7df-2577d3df5311 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-75e879f2-ea14-426b-a7df-2577d3df5311');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           date  account_value\n",
       "312  2021-10-25   1.405996e+08\n",
       "313  2021-10-26   1.415434e+08\n",
       "314  2021-10-27   1.411906e+08\n",
       "315  2021-10-28   1.419629e+08\n",
       "316  2021-10-29   1.435569e+08"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_means_ddpg['date'] = df_account_value_ddpg_arr[0]['date']\n",
    "df_account_value_means_ddpg = df_account_value_means_ddpg[['date', 'account_value']]\n",
    "df_account_value_means_ddpg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "id": "q2QvH_JfmJUw",
    "outputId": "4440c40e-104d-436b-d54c-5f6f84265d32",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b79e4bc4-62e0-4268-87aa-b008143d7c47\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1301</th>\n",
       "      <th>1332</th>\n",
       "      <th>1333</th>\n",
       "      <th>1376</th>\n",
       "      <th>1377</th>\n",
       "      <th>1379</th>\n",
       "      <th>1407</th>\n",
       "      <th>1414</th>\n",
       "      <th>1417</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-07</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-08</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows × 9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b79e4bc4-62e0-4268-87aa-b008143d7c47')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b79e4bc4-62e0-4268-87aa-b008143d7c47 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b79e4bc4-62e0-4268-87aa-b008143d7c47');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "             1301  1332       1333       1376       1377  1379       1407  \\\n",
       "date                                                                        \n",
       "2020-07-01  100.0   0.0  33.333333  33.333333  33.333333   0.0  33.333333   \n",
       "2020-07-02  100.0   0.0  33.333333  33.333333  33.333333   0.0  33.333333   \n",
       "2020-07-06  100.0   0.0  33.333333  33.333333  33.333333   0.0  33.333333   \n",
       "2020-07-07  100.0   0.0  33.333333  33.333333  33.333333   0.0  33.333333   \n",
       "2020-07-08  100.0   0.0  33.333333  33.333333  33.333333   0.0  33.333333   \n",
       "...           ...   ...        ...        ...        ...   ...        ...   \n",
       "2021-10-22    0.0   0.0   0.000000   0.000000   0.000000   0.0   0.000000   \n",
       "2021-10-25    0.0   0.0   0.000000   0.000000   0.000000   0.0   0.000000   \n",
       "2021-10-26    0.0   0.0   0.000000   0.000000   0.000000   0.0   0.000000   \n",
       "2021-10-27    0.0   0.0   0.000000   0.000000   0.000000   0.0   0.000000   \n",
       "2021-10-28    0.0   0.0   0.000000   0.000000   0.000000   0.0   0.000000   \n",
       "\n",
       "                 1414       1417  \n",
       "date                              \n",
       "2020-07-01  66.666667  33.333333  \n",
       "2020-07-02  66.666667  33.333333  \n",
       "2020-07-06  66.666667  33.333333  \n",
       "2020-07-07  66.666667  33.333333  \n",
       "2020-07-08  66.666667  33.333333  \n",
       "...               ...        ...  \n",
       "2021-10-22   0.000000   0.000000  \n",
       "2021-10-25   0.000000   0.000000  \n",
       "2021-10-26   0.000000   0.000000  \n",
       "2021-10-27   0.000000   0.000000  \n",
       "2021-10-28   0.000000   0.000000  \n",
       "\n",
       "[316 rows x 9 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions_means_ddpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADZqHlsGsvcb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## BackTestStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiIYSDzcs6mk",
    "outputId": "940fa630-09fa-4b60-a882-60e3d8ea7ae2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.082049\n",
      "Cumulative returns     0.104284\n",
      "Annual volatility      0.338621\n",
      "Sharpe ratio           0.398751\n",
      "Calmar ratio           0.362913\n",
      "Stability              0.440343\n",
      "Max drawdown          -0.226085\n",
      "Omega ratio            1.165601\n",
      "Sortino ratio          0.634527\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.996489\n",
      "Daily value at risk   -0.042126\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all_ddpg = backtest_stats(account_value=df_account_value_means_ddpg)\n",
    "perf_stats_all_ddpg = pd.DataFrame(perf_stats_all_ddpg)\n",
    "perf_stats_all_ddpg.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dezYPh6kr9FI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_ddpg = df_account_value_means_ddpg.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgeMcXmsr-_f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_ddpg.index = pd.to_datetime(df_date_ddpg.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 271
    },
    "id": "6S6mmPn6s69I",
    "outputId": "272d81e1-6104-4873-a42d-59a8cd3dc002",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f160917bad0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_date_ddpg.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J87gFVKPs7Ea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_ddpg.to_csv(\"ddpg_account_value.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fzN5TtPTc86",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del df_account_value_ddpg_arr ; del df_actions_ddpg_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lYOXsN89lhF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b1454e66b7614c28aaef77a4acc242ce"
     ]
    },
    "id": "_OttVRvE9qEn",
    "outputId": "115625e9-b48b-4659-e513-ae9fa7dfc4f2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1454e66b7614c28aaef77a4acc242ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All seeds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 266       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 7         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 10.538477 |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 250          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074312477 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.75e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | 36.336826    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 8.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 246          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030725598 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.67e+04     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.000149    |\n",
      "|    reward               | -62.09128    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 8.1e+04      |\n",
      "------------------------------------------\n",
      "day: 823, episode: 380\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 108909810.58\n",
      "total_reward: -21090189.42\n",
      "total_cost: 1170754.42\n",
      "total_trades: 7206\n",
      "Sharpe: -0.309\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 243          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099301115 |\n",
      "|    clip_fraction        | 0.097        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.58e+04     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | -80.26042    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 5.27e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005230659 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.36e+04    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | 0.00368     |\n",
      "|    reward               | -32.909595  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 8.96e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005792617 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.8e+04     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    reward               | -241.82803  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.48e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024704896 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.71e+04     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    reward               | -43.97292    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 7.21e+04     |\n",
      "------------------------------------------\n",
      "day: 823, episode: 390\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 116133384.70\n",
      "total_reward: -13866615.30\n",
      "total_cost: 1171280.30\n",
      "total_trades: 7164\n",
      "Sharpe: -0.329\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 240        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 68         |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01021082 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.8      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.46e+04   |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.000817  |\n",
      "|    reward               | -1.216006  |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 4.05e+04   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035680512 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.07e+04     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    reward               | -12.808908   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 5.72e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006312688 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.8e+04     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    reward               | -21.586903  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.49e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 95         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00523141 |\n",
      "|    clip_fraction        | 0.0171     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.8      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 2.11e+04   |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0027    |\n",
      "|    reward               | -0.7608717 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 3.06e+04   |\n",
      "----------------------------------------\n",
      "day: 823, episode: 400\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 111214919.17\n",
      "total_reward: -18785080.83\n",
      "total_cost: 1143053.83\n",
      "total_trades: 7091\n",
      "Sharpe: -0.447\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027385004 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.96e+04    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.000778   |\n",
      "|    reward               | -20.456928  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.6e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005805681 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.86e+04    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    reward               | -6.5128555  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.72e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 121          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103792725 |\n",
      "|    clip_fraction        | 0.0772       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.46e+04     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    reward               | -4.8271513   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 4.02e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007043152 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.42e+04    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.000756   |\n",
      "|    reward               | 13.447673   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.14e+04    |\n",
      "-----------------------------------------\n",
      "day: 823, episode: 410\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 115566499.88\n",
      "total_reward: -14433500.12\n",
      "total_cost: 1156286.12\n",
      "total_trades: 7176\n",
      "Sharpe: -0.436\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009521777 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.09e+04    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | -61.061447  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.12e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051909573 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.6e+04      |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | 5.5e-05      |\n",
      "|    reward               | -37.682045   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.87e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007358892 |\n",
      "|    clip_fraction        | 0.0477      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.24e+03    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    reward               | 18.624977   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.6e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013218683 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.32e+04    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    reward               | 16.005665   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.59e+04    |\n",
      "-----------------------------------------\n",
      "day: 823, episode: 420\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 102789534.82\n",
      "total_reward: -27210465.18\n",
      "total_cost: 1177408.22\n",
      "total_trades: 7105\n",
      "Sharpe: -0.350\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006232107 |\n",
      "|    clip_fraction        | 0.0553      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.00142     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.87e+04    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    reward               | 31.93623    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.33e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013242164 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | -0.000143    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 5.33e+04     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    reward               | 16.852694    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.22e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005567015 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.000688    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.84e+04    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    reward               | 18.0452     |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1e+05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005073444 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.41e+04    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.000902   |\n",
      "|    reward               | 1.122981    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 6.24e+04    |\n",
      "-----------------------------------------\n",
      "day: 823, episode: 430\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 115079119.16\n",
      "total_reward: -14920880.84\n",
      "total_cost: 1169365.84\n",
      "total_trades: 7210\n",
      "Sharpe: -0.311\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008019074 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.08e+04    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    reward               | -5.488894   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.02e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009107185 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.81e+04    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00101    |\n",
      "|    reward               | -1.5194606  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 7.09e+04    |\n",
      "-----------------------------------------\n",
      "day: 316, episode: 20\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 135900686.41\n",
      "total_reward: 5900686.41\n",
      "total_cost: 50787.59\n",
      "total_trades: 2212\n",
      "Sharpe: 0.768\n",
      "=================================\n",
      "hit end!\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 283       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 7         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 31.515388 |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 261         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008883044 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.61e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    reward               | 26.448648   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 8.66e+03    |\n",
      "-----------------------------------------\n",
      "day: 823, episode: 440\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123418640.60\n",
      "total_reward: -6581359.40\n",
      "total_cost: 1137020.40\n",
      "total_trades: 7168\n",
      "Sharpe: -0.162\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 254         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006650051 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 8.81e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    reward               | -37.271313  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.23e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 247         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013451174 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.55e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    reward               | -34.56108   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.34e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 247          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088583175 |\n",
      "|    clip_fraction        | 0.0682       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.46e+04     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    reward               | -11.016809   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 7.27e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 245         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015414943 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.32e+04    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    reward               | -132.4156   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 5.61e+04    |\n",
      "-----------------------------------------\n",
      "day: 823, episode: 450\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 127814518.73\n",
      "total_reward: -2185481.27\n",
      "total_cost: 1133852.27\n",
      "total_trades: 7085\n",
      "Sharpe: -0.057\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009891236 |\n",
      "|    clip_fraction        | 0.079       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.56e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    reward               | -16.49394   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.37e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 244         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007008191 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.56e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.000827   |\n",
      "|    reward               | 3.034371    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 8.23e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 243         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007149573 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.05e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    reward               | -0.570609   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.85e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007144047 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.53e+03    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    reward               | -5.1523275  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.2e+03     |\n",
      "-----------------------------------------\n",
      "day: 823, episode: 460\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 126026190.89\n",
      "total_reward: -3973809.11\n",
      "total_cost: 1149922.11\n",
      "total_trades: 7118\n",
      "Sharpe: -0.157\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004894768 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.95e+03    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00126    |\n",
      "|    reward               | -22.856592  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.05e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007218197 |\n",
      "|    clip_fraction        | 0.022       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.32e+04    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    reward               | -8.095565   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 7.61e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 240         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006573176 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.83e+04    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    reward               | 31.189955   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.87e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 240          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070261154 |\n",
      "|    clip_fraction        | 0.0553       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.81e+04     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    reward               | 16.54109     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 3.54e+04     |\n",
      "------------------------------------------\n",
      "day: 823, episode: 470\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 128458094.71\n",
      "total_reward: -1541905.29\n",
      "total_cost: 1083044.29\n",
      "total_trades: 6974\n",
      "Sharpe: -0.035\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013243014 |\n",
      "|    clip_fraction        | 0.0649      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.01e+04    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    reward               | -30.900717  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.26e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005785625 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.57e+04    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    reward               | -21.245764  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.5e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006756277 |\n",
      "|    clip_fraction        | 0.0472      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.27e+04    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | 0.000674    |\n",
      "|    reward               | -26.955624  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.44e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052462956 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.03e+04     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    reward               | 17.514381    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 3.76e+04     |\n",
      "------------------------------------------\n",
      "day: 823, episode: 480\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 146897616.36\n",
      "total_reward: 16897616.36\n",
      "total_cost: 1105276.64\n",
      "total_trades: 6955\n",
      "Sharpe: 0.784\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047308384 |\n",
      "|    clip_fraction        | 0.0626       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.71e+04     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    reward               | 7.667822     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 5.93e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004856594 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.64e+04    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.000711   |\n",
      "|    reward               | 50.66587    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.27e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010791529 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.27e+04    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    reward               | 15.215565   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 4.01e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004646043 |\n",
      "|    clip_fraction        | 0.00981     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.67e+04    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    reward               | 11.360838   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 4.17e+04    |\n",
      "-----------------------------------------\n",
      "day: 823, episode: 490\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 129156619.60\n",
      "total_reward: -843380.40\n",
      "total_cost: 1134544.40\n",
      "total_trades: 6979\n",
      "Sharpe: 0.010\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 239          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 196          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060582226 |\n",
      "|    clip_fraction        | 0.0561       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -13          |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.33e+04     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    reward               | 4.4198184    |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 4.36e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006366859 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.12e+04    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -6.84e-05   |\n",
      "|    reward               | 26.468067   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.11e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 239         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008099566 |\n",
      "|    clip_fraction        | 0.0368      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -13         |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.2e+05     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.000281    |\n",
      "|    reward               | -3.7734435  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 1.61e+05    |\n",
      "-----------------------------------------\n",
      "hit end!\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "day: 823, episode: 500\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 119215930.92\n",
      "total_reward: -10784069.08\n",
      "total_cost: 1170550.08\n",
      "total_trades: 7217\n",
      "Sharpe: -0.275\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 273       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 7         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 11.825389 |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 256        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00843907 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.8      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 8.41e+03   |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.00216   |\n",
      "|    reward               | 8.301584   |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 2.31e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 249        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 24         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00872708 |\n",
      "|    clip_fraction        | 0.0824     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.8      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.22e+04   |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.00391   |\n",
      "|    reward               | -64.09362  |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 4.44e+04   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 244          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048393807 |\n",
      "|    clip_fraction        | 0.0468       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.53e+04     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    reward               | -56.57196    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 6.85e+04     |\n",
      "------------------------------------------\n",
      "day: 823, episode: 510\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 116612480.55\n",
      "total_reward: -13387519.45\n",
      "total_cost: 1147961.45\n",
      "total_trades: 7174\n",
      "Sharpe: -0.183\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 242          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049433014 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.01e+05     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    reward               | -24.028805   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.11e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 241         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007879253 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.36e+04    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | 0.00228     |\n",
      "|    reward               | -264.1802   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 6.3e+04     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021201363 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | 0.000278     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.99e+05     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000939    |\n",
      "|    reward               | -31.640715   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.36e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082177315 |\n",
      "|    clip_fraction        | 0.0629       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.000126    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 8.05e+04     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    reward               | -9.99548     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.53e+05     |\n",
      "------------------------------------------\n",
      "day: 823, episode: 520\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 104699391.76\n",
      "total_reward: -25300608.24\n",
      "total_cost: 1164017.99\n",
      "total_trades: 7213\n",
      "Sharpe: -0.202\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002457422 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.000246    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.25e+05    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    reward               | -68.396736  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.63e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006657278 |\n",
      "|    clip_fraction        | 0.0263      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | 0.00101     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.95e+04    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    reward               | 20.783976   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.08e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 95           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008240484 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.8        |\n",
      "|    explained_variance   | -0.000252    |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.1e+05      |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    reward               | -26.562115   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.11e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004915255 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.8       |\n",
      "|    explained_variance   | -0.00104    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.11e+04    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    reward               | -2.2262304  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.5e+05     |\n",
      "-----------------------------------------\n",
      "day: 823, episode: 530\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 108638042.03\n",
      "total_reward: -21361957.97\n",
      "total_cost: 1151216.97\n",
      "total_trades: 7153\n",
      "Sharpe: -0.279\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006899634 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 3.74e-05    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1e+05     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    reward               | -11.859332  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.7e+05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 235         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009296228 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.00137     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.37e+04    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    reward               | -8.300314   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.56e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 130          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091298595 |\n",
      "|    clip_fraction        | 0.0604       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 7.2e+04      |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | 0.000964     |\n",
      "|    reward               | -71.12235    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.64e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 235          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057476317 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | -0.00381     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.16e+05     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | -111.821045  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.26e+05     |\n",
      "------------------------------------------\n",
      "day: 823, episode: 540\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 106421911.67\n",
      "total_reward: -23578088.33\n",
      "total_cost: 1099384.58\n",
      "total_trades: 7161\n",
      "Sharpe: -0.157\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 236        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00880555 |\n",
      "|    clip_fraction        | 0.0684     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -12.9      |\n",
      "|    explained_variance   | -0.00213   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.39e+05   |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.00747   |\n",
      "|    reward               | -113.2776  |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 2.22e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007275273 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.000275    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.4e+04     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00933    |\n",
      "|    reward               | 24.88369    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.2e+05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005633022 |\n",
      "|    clip_fraction        | 0.0174      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.00194     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.01e+05    |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    reward               | 48.1307     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.8e+05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007008074 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.00203     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.08e+05    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    reward               | 55.406933   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.1e+05     |\n",
      "-----------------------------------------\n",
      "day: 823, episode: 550\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 99020970.65\n",
      "total_reward: -30979029.35\n",
      "total_cost: 1087190.40\n",
      "total_trades: 7104\n",
      "Sharpe: -0.235\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 181          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057723764 |\n",
      "|    clip_fraction        | 0.047        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.00168      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.52e+04     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    reward               | 40.759506    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.19e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006329026 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.00393     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.11e+05    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | 77.5244     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.27e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008014027 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.000682    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 6.76e+04    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    reward               | 10.668745   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.08e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 236          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 207          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047401525 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -12.9        |\n",
      "|    explained_variance   | 0.00184      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.1e+05      |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | -15.616279   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.56e+05     |\n",
      "------------------------------------------\n",
      "day: 823, episode: 560\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 115734761.47\n",
      "total_reward: -14265238.53\n",
      "total_cost: 1150559.53\n",
      "total_trades: 7155\n",
      "Sharpe: -0.137\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 236         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006089201 |\n",
      "|    clip_fraction        | 0.0197      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -12.9       |\n",
      "|    explained_variance   | 0.00321     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.28e+05    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    reward               | -0.364388   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.45e+05    |\n",
      "-----------------------------------------\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "env_train.reset()\n",
    "df_account_value_ppo_arr, df_actions_ppo_arr = [], []\n",
    "\n",
    "for seed in tqdm(SEEDS, desc='All seeds', leave=True): # Looping from the given seeds\n",
    "\n",
    "  # Train\n",
    "  random.seed(seed); np.random.seed(seed) ; env_train.seed(seed)\n",
    "  agent = DRLAgent(env = env_train)\n",
    "  PPO_PARAMS = {\n",
    "      \"n_steps\": 2048,\n",
    "      \"ent_coef\": 0.01,\n",
    "      \"learning_rate\": 0.00025,\n",
    "      \"batch_size\": 128,\n",
    "  }\n",
    "  model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "  trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=50000)\n",
    "\n",
    "  trained_ppo.save('trained_ppo.model') # save the model\n",
    "\n",
    "  # Prediction\n",
    "  df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym)\n",
    "  df_account_value_ppo.shape\n",
    "  df_account_value_ppo.tail()\n",
    "  df_actions_ppo.head()\n",
    "  df_account_value_ppo_arr.append(df_account_value_ppo)\n",
    "  df_actions_ppo_arr.append(df_actions_ppo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOdJvfxdmmNY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PPO for trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "UVz5mfsxmJgK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_account_value_ppo_con = pd.concat((df_account_value_ppo_arr))\n",
    "df_actions_ppo_con = pd.concat((df_actions_ppo_arr))\n",
    "\n",
    "df_account_value_ppo_con_idx = df_account_value_ppo_con.groupby(df_account_value_ppo_con.index)\n",
    "df_actions_ppo_con_idx = df_actions_ppo_con.groupby(df_actions_ppo_con.index)\n",
    "\n",
    "df_account_value_means_ppo = df_account_value_ppo_con_idx.mean()\n",
    "df_actions_means_ppo = df_actions_ppo_con_idx.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Jo51qRQImJmR",
    "outputId": "2c11bb9d-b6d6-4b6c-d837-e6eca5dff052",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8cbae091-557d-4861-872b-bf091a6135ed\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>1.341304e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>1.345930e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>1.342190e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>1.347678e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>1.353768e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cbae091-557d-4861-872b-bf091a6135ed')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8cbae091-557d-4861-872b-bf091a6135ed button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8cbae091-557d-4861-872b-bf091a6135ed');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           date  account_value\n",
       "312  2021-10-25   1.341304e+08\n",
       "313  2021-10-26   1.345930e+08\n",
       "314  2021-10-27   1.342190e+08\n",
       "315  2021-10-28   1.347678e+08\n",
       "316  2021-10-29   1.353768e+08"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_means_ppo['date'] = df_account_value_ppo_arr[0]['date']\n",
    "df_account_value_means_ppo = df_account_value_means_ppo[['date', 'account_value']]\n",
    "df_account_value_means_ppo.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Cdj9yAYgmJs9",
    "outputId": "f1f742be-7d24-436e-a8c2-d2fcadf2d952",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8712383f-a35f-4ca3-a3cd-36270ddabe68\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1301</th>\n",
       "      <th>1332</th>\n",
       "      <th>1333</th>\n",
       "      <th>1376</th>\n",
       "      <th>1377</th>\n",
       "      <th>1379</th>\n",
       "      <th>1407</th>\n",
       "      <th>1414</th>\n",
       "      <th>1417</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-07</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-08</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-22</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-25</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-26</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-28</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>5.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows × 9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8712383f-a35f-4ca3-a3cd-36270ddabe68')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8712383f-a35f-4ca3-a3cd-36270ddabe68 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8712383f-a35f-4ca3-a3cd-36270ddabe68');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "            1301      1332      1333      1376  1377  1379  1407       1414  \\\n",
       "date                                                                          \n",
       "2020-07-01   9.0  9.333333  2.333333  1.333333   4.0   5.0   6.0  12.666667   \n",
       "2020-07-02   9.0  9.333333  2.333333  1.333333   4.0   5.0   6.0  12.666667   \n",
       "2020-07-06   9.0  9.333333  2.333333  1.333333   4.0   5.0   6.0  12.666667   \n",
       "2020-07-07   9.0  9.333333  2.333333  1.333333   4.0   5.0   6.0  12.666667   \n",
       "2020-07-08   9.0  9.333333  2.333333  1.333333   4.0   5.0   6.0  12.666667   \n",
       "...          ...       ...       ...       ...   ...   ...   ...        ...   \n",
       "2021-10-22   9.0  9.333333  2.333333  1.333333   4.0   5.0   6.0  12.666667   \n",
       "2021-10-25   9.0  9.333333  2.333333  1.333333   4.0   5.0   6.0  12.666667   \n",
       "2021-10-26   9.0  9.333333  2.333333  1.333333   4.0   5.0   6.0  12.666667   \n",
       "2021-10-27   9.0  9.333333  2.333333  1.333333   4.0   5.0   6.0  12.666667   \n",
       "2021-10-28   9.0  9.333333  2.333333  1.333333   4.0   5.0   6.0  12.666667   \n",
       "\n",
       "                1417  \n",
       "date                  \n",
       "2020-07-01  5.666667  \n",
       "2020-07-02  5.666667  \n",
       "2020-07-06  5.666667  \n",
       "2020-07-07  5.666667  \n",
       "2020-07-08  5.666667  \n",
       "...              ...  \n",
       "2021-10-22  5.666667  \n",
       "2021-10-25  5.666667  \n",
       "2021-10-26  5.666667  \n",
       "2021-10-27  5.666667  \n",
       "2021-10-28  5.666667  \n",
       "\n",
       "[316 rows x 9 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions_means_ppo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJHllBvrtPKZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## BackTestStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "q72HNaK5tT1Q",
    "outputId": "98865a9b-2171-4f49-c80f-cf9a1bd902ae",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.032742\n",
      "Cumulative returns     0.041360\n",
      "Annual volatility      0.053544\n",
      "Sharpe ratio           0.630323\n",
      "Calmar ratio           0.835184\n",
      "Stability              0.361731\n",
      "Max drawdown          -0.039204\n",
      "Omega ratio            1.164912\n",
      "Sortino ratio          0.938570\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.018914\n",
      "Daily value at risk   -0.006612\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all_ppo = backtest_stats(account_value=df_account_value_means_ppo)\n",
    "perf_stats_all_ppo = pd.DataFrame(perf_stats_all_ppo)\n",
    "perf_stats_all_ppo.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BHRapTg5tUF5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_ppo = df_account_value_means_ppo.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dSt96nY_tUNu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_ppo.index = pd.to_datetime(df_date_ppo.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "s1dVyj5ZtUY8",
    "outputId": "3f356534-351e-4e28-9591-9546aca65249",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f160bd8ea10>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEPCAYAAABMTw/iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3iUVdr48e896Z10Qg1FelMighUUewEVddVVdF1dt+lWu6/r4rvW3+679lVX2bVgx3XVVVYUQRCU3pEOIYGE9J5M5vz+eJ6ZTCBlkkySmXB/rouL5Ckz90ySe85znnPuI8YYlFJK9VyO7g5AKaVU59JEr5RSPZwmeqWU6uE00SulVA+niV4ppXo4TfRKKdXDBWyiF5GXRSRPRDb6cOwAEflSRNaIyHoRuaArYlRKqWAQsIkemAuc5+Ox9wFvG2OOB34APNtZQSmlVLAJ2ERvjFkMFHpvE5EhIvKpiKwSkSUiMsJ9OBBvf50A5HRhqEopFdBCuzuANnoBuNUYs11ETsJquZ8J/AFYICK/BGKA6d0XolJKBZagSfQiEgucDLwjIu7NEfb/VwNzjTH/T0SmAK+KyBhjjKsbQlVKqYASNIkeq5up2BgzoYl9N2H35xtjvhGRSCAFyOvC+JRSKiAFbB/9kYwxpcBuEbkCQCzj7d37gLPs7SOBSCC/WwJVSqkAI4FavVJE5gFTsVrmh4AHgC+A54AMIAx40xjzRxEZBbwIxGLdmL3DGLOgO+JWSqlAE7CJXimllH8ETdeNUkqp9gnIm7EpKSkmMzOzu8NQSqmgsWrVqsPGmNSm9gVkos/MzGTlypXdHYZSSgUNEdnb3D7tulFKqR7Op0TfWoExEZlhFxNbKyIrReRUr32PicgmEdkiIk+K12wnpZRSnc/XFv1cWi4wthAYb09m+hHwEoCInAycAowDxgAnAme0N1illFJt51MfvTFmsYhktrC/3OvbGKyx7Nj/RwLhgGCNfT/UnkDr6urIzs6murq6PaerLhQZGUm/fv0ICwvr7lCUUvjxZqyIXAo8DKQBF4KnHMGXQC5Won/aGLOlmfNvAW4BGDBgwFH7s7OziYuLIzMzE+39CVzGGAoKCsjOzmbQoEHdHY5SCj/ejDXGzDfGjABmAnMARGQoMBLoB/QFzhSR05o5/wVjTJYxJis19egRQtXV1SQnJ2uSD3AiQnJysl55KRVA/D7qxq4jP1hEUoBLgeXGmHK7e+c/wJT2PrYm+eCgPyfVE2zOKWV/YWV3h+EXfkn0IjLUPZpGRE7AKh9cgFVs7AwRCRWRMKwbsU123SilVCC54MklnPbYl90dhl/41EfvXWBMRLKxCoyFARhjngcuB64XkTqgCrjKGGNE5F2shUE2YN2Y/dQY82+/vwqllPIjl6tn1QDzddTN1a3sfxR4tInt9cBP2heaas6ePXtYtmwZ11xzjd8ec9GiRTzxxBN89NFHfntMpYJVQUVtd4fgVzozNgjt2bOHN954o7vDUKrHyimu6u4Q/Coga9205sF/b2JzTqlfH3NUn3geuHh0i8fMnDmT/fv3U11dze23384tt9zCp59+yj333EN9fT0pKSksXLiQ8vJyfvnLX7Jy5UpEhAceeIDLL7+cefPm8ac//QljDBdeeCGPPmpdBMXGxlJebk1FePfdd/noo4+YO3cuN9xwA/Hx8axcuZKDBw/y2GOPMWvWLO666y62bNnChAkTmD17Nr/+9a+PinXy5Mn8/e9/Z/Ro6zVNnTqVJ554ApfLxe233051dTVRUVG88sorDB8+vNG5f/jDH4iNjeV3v/sdAGPGjOGjjz4iMzOT1157jSeffJLa2lpOOukknn32WUJCQjr8/isVSDTRH8NefvllkpKSqKqq4sQTT2TGjBncfPPNLF68mEGDBlFYWAjAnDlzSEhIYMOGDQAUFRWRk5PDnXfeyapVq0hMTOScc87hgw8+YObMmS0+Z25uLl9//TVbt27lkksuYdasWTzyyCOtdrNcddVVvP322zz44IPk5uaSm5tLVlYWpaWlLFmyhNDQUD7//HPuuece3nvvPZ9e/5YtW3jrrbdYunQpYWFh/OxnP+P111/n+uuv9/EdVCo4bDtUBkCv6J4x6S8oE31rLe/O8uSTTzJ//nwA9u/fzwsvvMDpp5/umRiUlJQEwOeff86bb77pOS8xMZHFixczdepU3HMErr32WhYvXtxqop85cyYOh4NRo0Zx6JDvk4qvvPJKzjnnHB588EHefvttZs2aBUBJSQmzZ89m+/btiAh1dXU+P+bChQtZtWoVJ554IgBVVVWkpaX5fL5SwSCvtJq/L9kNQGRoz7haDcpE3x0WLVrE559/zjfffEN0dDRTp05lwoQJbN26tcOP7T3u/MiJRhEREZ6v27IaWN++fUlOTmb9+vW89dZbPP/88wDcf//9TJs2jfnz57Nnzx6mTp161LmhoaG4XK6jYjLGMHv2bB5++GGf41Aq2Dz8n63UOF2cPiyV9dnF3R2OX+jNWB+VlJSQmJhIdHQ0W7duZfny5VRXV7N48WJ277Y+/d1dN2effTbPPPOM59yioiImTZrEV199xeHDh6mvr2fevHmccYZV3y09PZ0tW7bgcrk8VwwtiYuLo6ysrNXjrrrqKh577DFKSkoYN26c53X07dsXgLlz5zZ5XmZmJqtXrwZg9erVntd31lln8e6775KXl+d5vXv3NlsCW6mgsz67mPlrDvCTMwYzoncc1XX13R2SX2ii99F5552H0+lk5MiR3HXXXUyePJnU1FReeOEFLrvsMsaPH89VV10FwH333UdRURFjxoxh/PjxfPnll2RkZPDII48wbdo0xo8fz8SJE5kxYwYAjzzyCBdddBEnn3wyGRkZrcYybtw4QkJCGD9+PH/5y1+aPW7WrFm8+eabXHnllZ5td9xxB3fffTfHH388TqezyfMuv/xyCgsLGT16NE8//TTDhg0DYNSoUTz00EOcc845jBs3jrPPPpvc3Fyf30OlAt3Wg1YD6sqs/kSGOqiuc7XpSjpQBeTi4FlZWebIFaa2bNnCyJEjuyki1Vb681LB6JWlu3nw35tZc//ZvPHtPh7/bBtb55xHZFjg99WLyCpjTFZT+7RFr5RStooa6yo3JiLUk9xr6lwtnRIU9GZskPvss8+48847G20bNGiQT339SqnGymvqCQ9xEB7qIMpO9NXOehII7mGWQZXojTFaGfEI5557Lueee253h9FIIHYHKuWLihonMRFWgo8Mszo8qmqD/4Zs0HTdREZGUlBQoEkkwLkXHomMjOzuUJRqs4paJ9HhVvs30qtFH+yCpkXfr18/srOzyc/P7+5QVCvcSwkqFWwqapzERrgTvdUOfvWbvVw/JZPhveO6M7QOCZpEHxYWpkvTKaU6za78cj7bdIgTBvQCGmbFvr5iH1V19fz5ygndGV6HBE3XjVJKdaYLnlwCWCNuACLDG4ZU+ruIYlfTRK+UUkC1PYzSPcQyLa6h/Mj2vPKgniWriV4ppYD4SKsln1dWA0CfhCjPvnqXYdvB1suOBCpN9EopBfRLjAbgUKlVxM/haDyUe1MQd99ooldKKSApJhyA2VMyj9oXFxnKppySLo7If4Jm1I1SSnWmWqeLSZlJ3HthQ42ml2/IYsXuQtbtL2ajtuiVUiq41TjriQoPaTT7/swR6dx9/khG90lga24pzvrgrHujiV4ppYAap4uI0KZT4ug+8dQ4Xew6XNHFUfmHJnqllMLquglvNtEnAARtP32riV5EXhaRPBHZ2Mz+GSKyXkTWishKETnVa98AEVkgIltEZLOIZPovdKWU8h+rRd903fkhqTFEhDrYeCA4++l9adHPBc5rYf9CYLwxZgLwI+Alr33/BB43xowEJgF57YxTKaU6VU0LLfrQEAcjMuJ7boveGLMYKGxhf7lpKCkZAxgAERkFhBpj/ut1XGXHQ1ZKKf+rcdY320cPVj/95pzSoKyg65c+ehG5VES2Ah9jteoBhgHFIvK+iKwRkcdFpNn1uETkFrvrZ6VWqFRKdbUap4uIsOZT4tDUWEqrnRRV1nVhVP7hl0RvjJlvjBkBzATm2JtDgdOA3wEnAoOBG1p4jBeMMVnGmKzU1FR/hKWUUj4xxlDrdBER0nxKjI+yVpkqqz5GE72b3c0zWERSgGxgrTFmlzHGCXwAnODP51NKKX+otcfHR7SwCHicXQvnlaV7mP3yt10Sl790eGasiAwFdhpjjIicAEQABUAR0EtEUo0x+cCZwMqOPp9SSvlbjdNK9OEttOjdif6DtQcorqwjr7SatPjgWEmt1UQvIvOAqUCKiGQDD4C1Uq4x5nngcuB6EakDqoCr7Juz9SLyO2ChWFPNVgEvdsqrUEqpDqh1ulv0LST6CKvrptjuo9+UU9pzEr0x5upW9j8KPNrMvv8C49oXmlJKdQ13i76lUTfuFr3bhgMlTBuR1qlx+YvOjFVKHfPcLfrmxtHD0Yl+44HgGVOviV4pdcyrcVqrRzU3MxYgLjLM83WfhEhN9EopFUxq6lrvugkPdXj2Xzy+Dzkl1RSU1/gthooaZ6ctV6iJXil1zHOvExsV3nyLHqzum/jIUE4fZs31ac+qUxuyS8i862O2H2q8NOEj/9nK5IcXtvnxfKGJXil1zMstsZYP7N3KKJq4yDAGp8Yyxq5muaEd3Td//3oXACv3FjXaXlxVR2J0eJsfzxe6wpRS6ph30F4nNsNrQfCmXJnVn+SYcBKiwxiQFN2uImdb7UXGE6PDGm0vqarzzL71N030SqljXk5xFb2iw1rtuvnp1CGer0dmxPH9ofI2P9f2POuc6rrGq1WVVNbSq5Na9Np1o5Q65h0sqW61NX+k9PhI8svafjO23mVVvzzyxmtxVR0JndSi10SvlDrm5ZRUk5HQtlmuKbERlFTVeYZmttWRib6kqo5e0ZrolVKqUxwsqWpzok+NiwCgoLy2Xc9Z7WzounG5DCXaoldKqc5RVVtPUWVdu1r0AIfbMJbee9ES7xZ9WY0TY9BEr5RSncHXETdHcrfo29JPX+PVive+GVtiF0rTm7FKKdUJcourANrRoreSclta9DVeyd27b7+kykr02qJXSqlO4J4sldGrbS365Bi7j77C9z76aq/k7t2iL66yHkNvxiqlVCfILbFa9K3Nij1SZJiDEId4yif4wrtfvsbra3eNe23RK6VUJ8gtqSbRh8lSRxIRYiNCqajxfXhloz56u3W/I6+cR/6zFYBemuiVUsr/ctsxWcotNiKUsur2tejdXTezX/6WA/Z9gs4qgaCJXil1TMttx2Qpt9iIUMpr6nw+vvGoGyvpl1Y3nB/ZwuLkHaGJXil1TMstqSKjV/sSfUxESJu6btzJPTzUwbKdBby6fC9hLSxI7i9a1Ewpdcyqqq2nuLKu/V03kWGeoZEtqXHWsymn1NNd41668G9f7STEIe167rbQFr1S6pjlHnHT/q6bEJ9G3Xy68SCXPbuMb3cXNNqeXVTVrsJobaWJXil1zDroXnCkI330PtyMLbVb/e+sym603T3pqrP5lOhF5GURyRORjc3snyEi60VkrYisFJFTj9gfLyLZIvK0P4JWSil/yLETfZ92j7oJo9yHFr37Jqx7vPwbN5/EqzdNYtbE/oA1Uer5H05sVwy+8LVFPxc4r4X9C4HxxpgJwI+Al47YPwdY3ObolFKqEx10T5bqSNdNrROXy7R4nPdoG4DRGQmcdlwq10waQESog4cvHct5Y3q3KwZf+JTojTGLgcIW9pebhrJsMYDnVYvIRCAdWNCBOJVSyu9ySqpJiglv97DG2MhQjIHKupZH3rhvvva1yyxEhFmpd0ByNCvvm96pSR782EcvIpeKyFbgY6xWPSLiAP4f8Dsfzr/F7vZZmZ+f76+wlFKqWQdLqttc+sCbu1Sxu6+/ObX1LsJDHFw3ZSApsRGEew2pjIsMQ6RzR974LdEbY+YbY0YAM7G6agB+BnxijMlu/kzP+S8YY7KMMVmpqan+CksppZp1qLSa9PiIdp8/JDUWsMoYtKSmzkV4qIOfnD6Yr++chqMLhlR68/s4emPMYhEZLCIpwBTgNBH5GRALhItIuTHmLn8/r1JKtVV+WQ1j+iS0+/whaVai35nfcqKvra8nPNSBiHTa7NeW+CXRi8hQYKcxxojICUAEUGCMudbrmBuALE3ySqlAUO8yFFTUehYQaY/YiFAyEiJbbdHXOl2Numu6mk+JXkTmAVOBFBHJBh4AwgCMMc8DlwPXi0gdUAVcZbzXzFJKqQBTWFFLvct0KNEDDEiKJruossVjap0uzw3Y7uBTojfGXN3K/keBR1s5Zi7WME2llOp27hmpaR1M9OnxkazLLm7xmJpgaNErpVRP8sXWQzz9xQ6ADrfo0+MjOFRajTHmqNEzP399NZOHJFtdN6Ga6JVSqsv86s21lNqlC/omtm9WrFt6fCTVdS5Kq52NVogqrqzl4w25gDW8MqIbE73WulFKHXMG28Mif3/u8HZXrnRLs8fh55U2Hku/dr/VnVNcVesZXtldNNErpY45NU4X00em8fNpQzv8WOl218+h0sZVKNfssxJ9UUUdNfUuwkO7flilmyZ6pdQxp7iylsRo/1SOHJAcDcD3h8oabV/jbtFX1nb78EpN9EqpY05hRS2JMf5J9BkJUQxMjuabXQ215l0uw9p9RQAUV9VR46zv1uGVmuiVUseUqtp6apwuekX7byHuk4cks3xXAc56q3jZrsMVlFY7GZgcTWVtPeXVTiK0Ra+UUl2jqLIWgCQ/dd0ATBmSQlm1k005pQCstlvz04anAZBXVqM3Y5VSqjOt2ltEabW16EdhhZXoe/kz0Q9OBmDZTqv7Zs2+YuIiQ8nKTPQco8MrlVKqk5TXOLn8uWXc8s+VAGzPs26a9unV/vLER0qNi2B4ehzLdh4GYOOBEsb1S2i0Fq226JVSqpPstAuOLd9lrZ308fpcesdHdqhqZVOmDEnmuz2F1Djr2VNQweCUWCb0T6R/kjVOvzurf2miV0r1aNu9KkvmlVXz1ff5XDguw+814ScPTqK6zsU3Owsos2/EhjiEe84fCUCfXh2bmNURWgJBKdWjubtqAJ5btJO6esPF4/v4/Xl62zNsV++1bsRmJscAcP7YDFbeN91v4/bbQxO9UqpH25rbkOhfWbqH/klRjO/n324baBjFs9qeETvQnkgFDUsOdhftulFK9VjGGDYeKOGicRmebReO7dMpa7T2irHG5X+94zCxEaFkpsT4/TnaSxO9UiqoVNXW+3zsodIaCipqOTEzybNt1sS+nREWcRGhhNr9/lOGJBPWjROkjhQ4kSilVCtW7Cpg/IMLeG7RTp+O33igBIAxfeO5cFwGJ2YmMjQtrlNiExGcLmtozWR7XH2g0D56pVTQeGLBNmrrXfy/Bdv46dQhrR6/MacEERiZEc8z15xAV61wOjKjcz5M2ktb9EqpgPWnT7aQedfHGGOoqq33lP51ugw1zsZdOO+tyva04N02HihlSGos0eFWm7Yz+uabMqJ3fJc8j6800SulAtYLi3cBkF1UxcacEpwuw9ThqQCUVNV5jqt1uvjtO+u46KmvG52/KaeEMX26Pukm+akypr9o141SKmBZ67HWsHJvIXn2wh7ThqexaFs+xZV1pMVZJQZ25jdMinK5DA6HcLi8htySasb09f9QyuZ8/pvTKaqsa/3ALqaJXikVsNLjIzlUWsOibfnU1LkYkBTNEHsZwGKvhLolt9Tz9fd5ZRwoqmLJdqvuzGg/lzpoSWfd6O0oTfRKqYBVZi/g/enGgzhEOHd0uqeOvLvcMMA2r9Wdvt1dyP/8a5Pn+1Hd0HUTaFrtoxeRl0UkT0Q2NrN/hoisF5G1IrJSRE61t08QkW9EZJO9/yp/B6+UCm5fbs3jy215ze4vqapjcGoMNU4XVXX1HD8g0ZPoS7xa9DnF1QxMjqZvryhW2MXLAKaPTCchyn8LjAQrX27GzgXOa2H/QmC8MWYC8CPgJXt7JXC9MWa0ff7/iUivDsSqlOpB6upd3Dj3O2585bsm9xtjKKmq45QhKZ5tJwxI9NSRL65qaNEfLKkiIyGSSYOSWLG7kJTYCMb2TeDZa0/o3BcRJFpN9MaYxUBhC/vLTcPg1BjA2Nu/N8Zst7/OAfKA1A5HrI5Z76zc71k0QgW/r3ccbnF/eY2TepfxlPkFGJERR0x4CKEOaXTTM7ekmoyEKCYNSuJweQ2Hy2uYPDipW2vABxK/vAsicqmIbAU+xmrVH7l/EhAONDudTURusbt+Vubn5/sjLNWD7Cuo5PfvrudPn2zp7lCUn2QXVnq+drmOnsjkvtnaKyqcqycNYNrwVMJCHIgIaXERHCqp9px7qLSa3gmRnDSoodRBTITegnTzS6I3xsw3xowAZgJzvPeJSAbwKnCjMcbVwmO8YIzJMsZkpaZqw181ts9OCvPXHGDP4Ypujkb5Q6l9oxUa31h1yy6qAiA+KoyHLxvLKzdO8uwbmBzD7gLr9+BwRQ119YaMhEgGeRUSi9VE7+HX6xq7m2ewiKQAiEg8Viv/XmPMcn8+lzq2ZBc1tP6e/GJ7N0ai/KXMK9HnldU02lddV88fPtxESmx4o1a6W2ZKDHsLrN+Jg3bLvnd8ZKOZr5roG3Q40YvIULHfXRE5AYgACkQkHJgP/NMY825Hn0cd2/YXVRLiEK6fMpAP1hxgl9cEGRWcyqob+tjzj0j0j326jW2Hynh81ngSm5hlmpkcTWFFLSVVdeTaid69glNYiJXsYyM10bv5MrxyHvANMFxEskXkJhG5VURutQ+5HNgoImuBZ4Cr7JuzVwKnAzfYQy/XisiETnodqofbX1hFn16R/GzqUMJDHTz1xY7uDkl1UFm1E/dqfgdLqz3bF3+fz8tLdzN7ykCmjUhr8txh6dbEpI/X5za06O2FuCNDQwDto/fW6jthjLm6lf2PAo82sf014LX2h6ZUg4P2qIrUuAiunjSAV7/ZywMXj/IMtVPBp6y6juG949mZV84Oe13X4spafvfOOo5Li+XuC0Y2e+4Zw1I5ZWgycz7azKnHpRAe4vCs8BQRFkJZjZM4TfQeOvZIBZTyGicfrDlwVDnZ/PIa0uKs5dguPb4vTpdhwaZD3RGi8pOyaieJ0WEMSYtl20FrZuvCLXnkldXwyOVjiQwLafZch0P485UTiAxz8N/Nh0hPiPAs9h1hD6nUFn0DTfQqoDz44SZ+9dZaVu8rarQ9v6zGs+7m2L4J9I6PZMkR47C35JaS9dB/eXX53i6rO67ar6zaSVxkKCN6x3kSvfum7MiM1ssWpMdH8vis8QBkJDSMtY8Ms9Kao4tKEgcDTfSqXVbvK2LGM0spbmJYXEes2msl+JV7GhJ9VW095TVOUu0WvYiQlZnIyj2N5/FtOFDC4fJa7v9gI/fM36DJPsCVVdcRFxnG+H4JHCytZnNOKYfLa4gOD/HUj2/N9FHpPHjJaG48OdOz7bFZ4zgxM5HMlOjmTzzGaKJXbVbvMtw3fyPr9hezYnezk6bb7Ls9heyxx0a/vmIfCzYdxOUyHC63WnnuRA+QNTCR3JJqckuqPNvcs2avmNiPed/u94y9b4oxhvs+2OD5YFFdz92in3l8XyLDHLy6fA+Hyxuu3Hw1++RMzh/bsPj3xIFJvHPryUSENt/1c6zRRK/a7L1V2Wy2y8Ku21/sl8csKK/hF2+sZkBSNM/Z9UlueXUVFzy5hLe+2w9AqlcCGJhsTYxxD60DK9FHhDq45qQBAHyzs6DZVv2B4ipeW76Pn7y6qlNa/st2Hmbt/mKc9S6W7jisVxdHqKt3UV7rJD4yjF7R4cyc0Jf5aw6wM7+clFi9we5vmuhVq1btLeKK55exbMdhymucPPbZNk4Y0ItRGfF864cWfb3L8Ku31lJUWccz157A+WMz+OK3Z/CXq8ZTV+/i6S+toZTeLfp4uyKh9ypDh8trSI4J9wy9u+v9DXyxtenKiO4+4ZKqWk599EvmLt3d4dfhZozhmhdXMPOZpTz95Q6ufWkF3+3RKwdv2UVVGAP9k6zuldknZ1Jd52LjgdI2t+hV6zTRqxbVOl3c8e46vttTxE3/WMkd767jcHkN/3PxaGZM6MPKvUV89b1vtYneXZXNrOeWccbjX3quBIwx/P7ddSzZfpgHLxntWSQiNMTBpcf34+PbTuO6yQOZOaEPx6XHeh7LXXq21CvRF1bUkhwb0Wi0xe5myiVstRN9Xb3hQHEVD360mY/X57bhnWne94caJnM9+6VV3mlTjrWWaVVtPX/+7/cs31Xgl+cKVu4uusxkK9GPzIhnkj0DNjpcu1z8TRO9atKOvHJ+OW8NFz/1NTvzK3jksrFU1dXzyYaDXDQugwn9e3HDKZkMTI5mzkebqW+iKJW3jQdK+N0761i5t4i9BZU8udAqY7Alt4z3Vx/gqqz+/ODE/kedFxkWwpyZY/i/HxzfqM81oYkWfWFFrWetzud/OBGwptI3ZUN2wyLS/RKjmDggkV+/tZYVfkjA3+5ueIzoiBDiI0PZklvKrvxyZj6zlCcXbuf1FfuOOs/7fkNPt88uX+DuggOYM2MMaXERnOxVllj5hyZ6dZTNOaU88OFG/r0uh22Hypg+Mp0fTBpAH3vm4bUnDQQgIjSE2886jh155azZ13zXRL3LcO/8DYSHOLjshL6cOjSFb/cU8ua3+/jN22sB+OHkgY3qlLTGk+i9StUWlNeSbCf688b0JiY8hMKKo9fvrK6rZ8n2hquQ6SPTefH6LPolRfHLeWuodTZbe88nOfZ9g/AQBw9cPIqx/RLYklvGLa+uIr+8ht7xkRRWNJ7yv2hbHlMe/oIvth7yvC53PfaeaE9BBTHhIY3644f3juPbe6dzZRMf+KpjNNGrRooqarn2peUs3VFAWlwE100eyP9eOgaAF67P4qZTBzUqMjV9VDphIcKCzc1PXnrzu32syy7h8SvG8ecrJzBrYj/Kqp3c9f4GTxfKgKS2DYULD3UQFRbiSYQ78srJLaliQHLD4yTGhDdZFfGbnQVU1NZzxjCrSur0kekkxoRz/4WjyCurYcHmg22K5UiHSqvpkxPpsRQAACAASURBVBDJxgfP5dLj+9GvVzQbDpSwI6+cey8YyZi+CRSUN47LPfrnV2+u5dy/LGb8HxfwyH+2Mv7BBbzix/sHgWJvQSUDk2Pa9OGu2k8TvWrkkf9s9SzoMK5fAnNmjiE93mrJj+mbwP0XjfLMQASIjwxjypAUPtt0sNmRJf9el8PIjHguGd8HgAvGZvDQzDG8cuOJnmMSotu+3FtCVJgn0f/lv98TFRbCdZMHevYnxYQ3Wqik1uni040H+Wh9LjHhIcyZMYbbzjqOyYOtD67Th6XSKzqMr7e3vCBGa/JKa0iLj/QsetHL67VNH5lO8hFxgXWvABpK96bFRfC3xbsAePDfm/0+X6G77Smo0HHuXUgTvfJYuaeQt1buZ0Rva9SKO/m05tzR6ewtqGy0QLObMYYtuWVM6N/L03oLD3Xww8kDmTa86YJVvkqICuNQWQ2PfbqVjzfkctOpg0j2GrGRGB3eKEH+/I3V3PraKt5bnc3U4WkMSI7mN2cPIzTE+jMIcQij+8SzKae0Q3HllVWTHt8Qh3c9nvioUJJirSsN7w9GZ31Dd9HskzO5Iqtfo8d8ccmuDsUUSOpdhv2FlQxIimn9YOUXmuiVx9xle0iJDef1H5/EeaN7c++FzReV8nb2yHQArnj+G/69LqfRvoOl1ZRU1TEqI67Jcx+fNY6//qB9RU0TosJY/H0+zy7ayayJ/fjp1KGN9ifFhFNoJ/qSyrpGQy3PHpXe5GOOyohn26Ey6urb309/qNTqh3fzbtGLCMkx4dTVm0YLb5TXNHydHGutqOR20bgMXlm6h4Lyxv36wSqnuIq6euMZcaM6n1b9OQZsyimhpKqu1dEMWw+WcfyARJJjI3j+uok+P35afCS9osMorqzjl/PWUF1XzxVZ1g219fbolhHN1C5xH9cexw/sRWl1HQ9cPJopQ5KP2p8YHU5BudVy/nJbHvUuQ2xEKOU1zmavJk4YkMiLS3azaFt+sx8GLamqraekqo40r0SfaCd6d4+Xe2RQYUWt56byYa8knhIbQb/EaB69fCz9EqNJj4/kkw25PP/VTu69cFSbYwo07hnL3iNuVOfSRN8D7S2ooF9iNCF2Zrnwya8B2P3wBc3e/Kpx1rP7cAXnje7drud8YtZ4Fm49xLaDZTz+2TYuO6EfIQ5h4ZZDxEWGMr5fr/a9mBbcff5I7j6/+auOgcnRVNbWk1dWw4rdBcRFhvL1HWdyoLiq2XsC00elMzA5mp+9vopTh6Zw21nHcfyARJ9j2m+vhNUvsaHIVkKUldjdPw/3xK/vdhcS6hCe+2onn29puNpwj0S56sSGVv0Zw1L5cls+917ocygByzOGXvvou4x23QQJl8vw+oq9/P3r3U3e9Kyuq+fZRTs45ZEvOOPxRTz26VagcUvRvQbnxgMlnPLIF2zOKaWkqo77PtjApxsPUu8yDOvddBdLa6aPSufhy8Zx06mDySurYemOw9S7DJ9vyePMEWmeG5NdaWiaNcFqR1453+0pImtgIgnRYYzq03xlxLAQB6/ddBI3njKIlXuKeObLti1w4l7eLtOrtZoY427RW4l+0qAksgYmcu8HG5j6xCLeOGJMfXITM0MHpcSSU1zVI0op7C2oJCLUQXpcZOsHK7/QFn2QeOyzbTz/lTXLcsrgZE+yWrGrgF2HK3j6ix0cKK7i1KEp5JVV8/evd3P5xH7c9d56z2Nc/eJy3rxlMs8uso69/18b6Z0Qycfrc3l9xT5EYOJA31uvTTlrZBqpcRE8+ulW7r1wJIUVte3qAvEHd6L//TvryCmpbtTv3ZL+SdHcc8FI9hdWekol+GqvZ8ZnQ6LvdUSLPiI0hJdmZ/Hrt9YyKCWWn5wxGKfLcMojXwAQ08TM0D69Iqm0u4WCfbGVPYcrGJgc3Wj0lupcmugDRHZRJQlRYcRFHt2l8NZ3+3j+q51cODaDzzYd5MN1OYzqE8/rK/Zy7/yNAAxJjeH1H5/EKUNT2JJbyvl/XcLFT1ldNk9dfTyfbMjli615XPDXJVTWWrNF3WO3Z03sx4frcjhtaAp9e0Ud9fxtERkWwoOXjOZnr6/mmhdXEB7i8IxX72ppcREkx4RTUlXHvReMZPaUga2f5GVwagwLNh+i1uny+YpkT0EFCVFhjbqG3DdjZ0zo47UtnFdunNTo3DNHpPHF1rwmu9fcP5fsoqqgT/TuMfSq62iiDwBr9hVx9YvL6R0fyfs/O8Vzsw6sKf73/2sTpw5N4f9+MIFz/7KYHXll3P3+BuZ923DJ/8oNkzyThUb0jmNoWizFlbW8eH0Wxw9I5OLxfdhbUMHP31hNdlEV/7hxEjOfXcrJQ5J57PJx/GLaUJL8VDXw/DG9mTbc6lM+c0Rakx9eXUFEeOfWKcRGhDa6OeqrwSmx1LsM+worPVcHLamqrWfBpkOM7ZvQaHtkWAjf3Tu90eibprx0fRb1zXTNuBe+zimuYswRjx9MjDHsL6rklKFa5qAraaLvZrsPV3DTP1ZSXediT0El1760gj4JkdS5DMYYltiTd35zzjDCQhw4HOK5cffTqUO4/azjyC+r8VQBBCvBvXHzSYSHOBq1/gYmx/Cvn59KhV0e9q1bpjAiIw6HQ8hM8V8LS0T402Vj+e3b6/j12cP89rjtMTi19QTdnCF2ct+VX+5Top+7bA95ZTU8Y5dZ9uZdebM5DofgoOnujIxe1geVd1nmQLL7cAWbckq4aFyfFo8rqqyjsra+0c1q1fk00XcCYwyfbTpIalykp8975Z5CnliwjSmDU7j0+L4MSI4mv6yG2S9/C8CXv5vK0h2HefTTrdQ664mLDEMEkmPCSYwJ5/j+1qgVd7dmenwEd543AqBRkndLa+ZGV4hDiLdb2JO8Shn4W0ZCFG/cPLnTHr8rDE61Pvx2NVMB01tJZR3PLdrBmSPSODHT/++re+HrwopaSirriI8KDajyAbNf/pZ9hZVMHZ5GTHgIv5i3hr69orjniAW+s5sYlaQ6nyb6dqp3GTbnlDIiI45/LNvDs4t2MrpPPL2iw9l+qMxTw2Xhb88gr7SG3769lpySapbvKuQvn39P/6Qo6pxW0ao3bj6JQSkxDEqJ4YeTBx71PE6Xy/NH7Tjif9V54iPDSImNYFd+eavH/vObPZTVOPn9ucM7JZbQEAcJUWEs2HyIp77YTq/ocE4dmsKjl48jKgDK+roLwa3bX0xZdR0fr89lQFI0t511HE8u3M6FYzPo0yuKS55eCkC/RB1a2ZV8SvQi8jJwEZBnjBnTxP4ZwBzABTiBXxljvrb3zQbusw99yBjzD38E3p1KKuu4/18b+XBdDonRYRRX1WEMLNl+mIHJ0fRJiOK2s47jxcW7uPy5ZRRX1hETHsJL12cxJC2Wxd/ns2T7YYoqa3n8inEtjtMOcQghjpBG34Mm+q4yODWGXfmtt+jXHyhhaGqsT4tat1dSTDhbcktJi4tgQv9efLguhx9M6h8QZX2H9Y7jYGk1S3cc5kN7dvS+wko+WZ/LC4t38cLiXZ4rJIC+2qLvUr626OcCTwP/bGb/QuBDY4wRkXHA28AIEUkCHgCyAAOsEpEPjTFBvdzOr99eyxdb85g1sR+1Thd5ZdU8fc0J1DpdnptmAOEhwqvL93L/RaO49qQBRIZZCXtQSgyzvRYzbgt3gg/RoWldYlByDAubWaXK2878co7zoR+/IxKjw9gNnDM6nV9MO44Fmw+xM7+iyxP9odJqFmw6SGiIgyuz+hPiEMLs38dnF1lDgG8+bRAvLtnNHfbw3p+cPphXl+/FIXDDyYM8M4JV1/Ap0RtjFotIZgv7va9tY7CSOsC5wH+NMYUAIvJf4DxgXnuCbU1FjRMREAR3g9ch4hkaZ4yhxukir7SGqrp6duWXs+VgGddNHkhFjZOCilpEYEyfBM85+wsr+WZnAU6X4aoT+/P+6my+2JrHz6cN4ffnjmgxnl+ceRy/OPM4v75Gh6dF79eHVc1Ii4+gsKIGl8s0Gvdd63QRFiKICHX1LvYVVLZ7VrGv3B/uA5NiSI+PICY8hJ15rXcr+VNhRS1X/u0bz8Swu9/fwIvXZ1FRa9XqiQxzcN3kgfzizON4cUlDeeW7LxjJz88cSohIoxXAVNfw2zsuIpcCDwNpgHuidl9gv9dh2fa2TjHxof9SXXd0Mar+SVFU1NRTVm2VtD2yKqN7tSO3uMhQrps8kMGpsTz8yRYK7JKy76/OZuXeIiYPTuLWM4Z00qtomTvX6GSTrpEcE47LQHFVnWfYq7PexbQnFjFtRCo3njKIPy/4HqfLdGiEjy/K7CJo/ZOiERGGpMWy04f7Bx1VUlnHi0t2sTm3lC+25hER6mDezZO5+sXlALy9cj9VtfVMHZ7KXK+5Ae/cOoUrnv/G8318Nw2zVX5M9MaY+cB8ETkdq79+elvOF5FbgFsABgzwbQbjkX5/7gic9S5cBgwGY6Cmrp4NB0ronRBJRGgIEaEOhqTGEh0RQnq8Ndvw+4NlJMWEkxQbTnVtPS8v3e25BB3RO47fnDOMOR9tZtW+Im47cyi3Tx/WbV0nIXoztku5yxEUlNeQFBNOXlk1mw6UcqC4iteW7+O15Q1zGcb07bz+eWiocNk/yeoeHJIa65elD1vz4boDngXaAf7fleOZMiSZz39zOjOeXkpOcRU1Thd9ExvfFB7RznIayv/8fg1ld/MMFpEU4AAw1Wt3P2BRM+e9ALwAkJWV1a6CHjedOqg9px01c3PaiDSeXLidEzOTmDo8FRFh4sBEqmrr21TgqjN4+ug10XcJ99KEh8trOS4dznriK8rshHtcWizbvbpOhqV1bmKbPjKducv2eIbTDkmNYf6aA1TUOJvsDlmxq4AVuwu57ayjuw83Hijh292FTBuRxqBW5lCs3V9CSmw4S+44k72FFYzobX2gDU2LY/bJmbyweBcJUWFEhzeOIS4yjEmZSd1WAkM18EuiF5GhwE77ZuwJQARQAHwG/ElE3NnxHOBufzxnZ4oMC+GO8xr3v7t/ububw+H+XxN9V3C36N3j191J/ienD2bGhL5c9txSqutcpMRGdPrP5N4LR/LTqUM8XSBD7K6i3Ycrjpote6i0mltfW0VxVR0/nza00RWoMYbfvr2ObYfK+ONHm5k9ZSAPzjhqMB3PLdrJ6n1FrNpbxPH9exEVHnLU38G4fgk4XYaCilqimxjm+fatUzr8ulXH+Tq8ch5WyzxFRLKxRtKEARhjngcuB64XkTqgCrjKWGX2CkVkDvCd/VB/dN+YVe0Tojdju1SyXRaioKKGjTlWbf3HZo3jion9EBG+u3c6FTX1RHRBdc6wEIdnWUdomLm7Pa+sUaJ3uQy/eXutZ0nI0qo6Er3KaqzZX8y2Q2X8/tzhrM8u5s3v9nPn+SMatcid9S6eXLidyDAHYSEOLhib0WRMY73KTx/ZoleBw9dRN1e3sv9R4NFm9r0MvNz20FRTdHhl10qMDschkF9Ww0G7/MDZI9M9E9jiIpsuRNcVMpNjSIuL4JWle7hkfF/P78Q7q/azdEcBpwxNZumOAoqPSPSr9lijm686sT/H9+/FZ5sO8dW2fM73SubbDpVRVVfPI5ePZcaE5sdP9EmIJDkmnIKK2iarbqrAoB/BQUZnxnatEIfQNzGKzTmlrNxbxDmj0hslze4UHurgngtG8qu31vLrt9bSNzGKUIfw0fpcRvSO48enDmbpjgKKKmsZREM//PoDJfTtFUVKbAS9BoWRFhfBe6uzOfW4FN5blc3rK/Z57j2c0Mo9KRFhbL8EFm3LD4gZuqppmuiDjGd4peb5LjMsLc4zaerWqd0zrLY5Myb04fMth1iw2Vo4pq7eIAKPzxrvqZbpvUB6vcuwak8h4+wul9AQB5ce35e/Ld7FxIc+p9bpIsqe2BcXGepTTZpxfa1Er+PjA5f+ZIKM+/Jcu266ztD0WBZuzWPSoKRWW7hdTUR4+prG1TLdk7v22MXYiu2+eoD/bj5ITkk1913UUGUyKzOJvy3eRa3TxWs3ncS67GIe/2wbveMjfSqc5u6nb+pmrAoMmuiDzJHFzVTnG2mPNPlpgLXmm+Me/ZNoV7ws8kr03+wsIDYilHO9ZvF6L614ytBkz8RCX3/HJg9O4oKxvcnqhKqdyj800QcZnTDV9S4cl0FGQiQnDU7u7lDaJC4yFIdAYUUNV7+wnGtOGsCB4ir6JUY1uiLsk9AwkkdEPAXHmltA/ejnCePZayf6N3jlV5rog4x23XS9sBBH0CV5sFr2vaLD2ZFXzje7CtieV0ZMROhRxdfcC9Wk2YujjO6TwM2nDeK6yZndELXqDJrog4ynWJsmeuWD4elxfPV9PmDN7j1cXsu04WlHHeddATPEIdx74agui1F1vs6f5aH8SidMqbaYODDRU+hvoL2mcEcXgFfBRxN9kNFaN6otThjYMHP1DxePZlRGfKcuIakCk3bdBBnPhClt0isfHOdVaG1033g+uf20boxGdRdt0QcZnTCl2sK7m8Y93FIdezTRBxkddaPawvvKLyxE/9yPVfqTDzINSwlqole+GdxKvXnV82kffZBp6LrRRK988/Ftp1Fbf/QSm+rYoYk+yIRomWLVRlHhIUShdWiOZdp1E2TctW60Qa+U8pUm+iDjuRmrmV4p5SNN9EHG3WOjXTdKKV9pog8y7lE3vtQJV0op0EQfdBpuxnZzIEqpoKHpIshorRulVFtpog8y2nWjlGorTfRBRidMKaXaqtVELyIvi0ieiGxsZv+1IrJeRDaIyDIRGe+179cisklENorIPBGJbOoxlO/cXTYG082RKKWChS8t+rnAeS3s3w2cYYwZC8wBXgAQkb7AbUCWMWYMEAL8oEPRKi1PrJRqs1ZLIBhjFotIZgv7l3l9uxzod8TjR4lIHRAN5LQvTOXm7rIRNOErpXzj7z76m4D/ABhjDgBPAPuAXKDEGLOguRNF5BYRWSkiK/Pz8/0cVs+hDXqlVFv5LdGLyDSsRH+n/X0iMAMYBPQBYkTkh82db4x5wRiTZYzJSk1N9VdYPY7OiFVKtZVfEr2IjANeAmYYYwrszdOB3caYfGNMHfA+cLI/nk8ppZTvOpzoRWQAVhK/zhjzvdeufcBkEYkWa9D3WcCWjj6fUkqptmn1ZqyIzAOmAikikg08AIQBGGOeB/4HSAaetSfxOO0umBUi8i6wGnACa7BH5CillOo6voy6ubqV/T8GftzMvgewPhiUUkp1E50Zq5RSPZwmeqWU6uE00SulVA+niV4ppXo4TfRBSotXKqV8pYleKaV6OE30SinVw2miDzJGy9ArpdpIE71SSvVwmuiDjN6EVUq1lSb6IKNdN0qpttJEr5RSPZwmeqWU6uE00Qcp7apXSvlKE71SSvVwmuiVUqqH00SvlFI9nCb6IDNpUBIAZwxP7eZIlFLBotWlBFVgGd+/Fzv/dAEhDr0dq5Tyjbbog5AmeaVUW2iiV0qpHk4TvVJK9XCa6JVSqodrNdGLyMsikiciG5vZf62IrBeRDSKyTETGe+3rJSLvishWEdkiIlP8GbxSSqnW+dKinwuc18L+3cAZxpixwBzgBa99fwU+NcaMAMYDW9oZp1JKqXZqdXilMWaxiGS2sH+Z17fLgX4AIpIAnA7cYB9XC9S2P1SllFLt4e9x9DcB/7G/HgTkA6/Y3TmrgNuNMRVNnSgitwC32N+Wi8i2dsaQAhxu57mdLVBj07h8F4gxuQVqbIEaFwRubO2Ja2BzO8T4sJKF3aL/yBgzpoVjpgHPAqcaYwpEJAurhX+KMWaFiPwVKDXG3N/G4NtERFYaY7I68znaK1Bj07h8F4gxuQVqbIEaFwRubP6Oyy+jbkRkHPASMMMYU2BvzgayjTEr7O/fBU7wx/MppZTyXYcTvYgMAN4HrjPGfO/ebow5COwXkeH2prOAzR19PqWUUm3Tah+9iMwDpgIpIpINPACEARhjngf+B0gGnhVr5Wqn1yXHL4HXRSQc2AXc6O8X0IQXWj+k2wRqbBqX7wIxJrdAjS1Q44LAjc2vcfnUR6+UUip46cxYpZTq4TTRK6VUD6eJ3s/EvlGhgpf+DHsO/VlagjLRi8glIjKku+NQPZZnkEIgJQoRGS4iAfk3KyLXuOtcBdJ7RpDmOH8LqjdBRKaLyDfA34GM7o7Hm4hcbI9QuktEmp2h1tVEZKaIzOnuOI4UiHGJyHki8hnwhIhcCmACYLSCiJwtIiuAHxNgf7P23+QS4P+A4yFg3rMLReQjYI6InNLd8Xizf/efEpGkrnrOgF9K0G4dxADzgDjgPuBXWNN9vxYRhzHG1Y0hIiLTgfuxhpqeCPxSRL40xnzcXfHZLb8fAXcBA0VkgTFmSVfHcURMgpWobgyUuOyYwoA/AVOAR7HqNV0hIhuNMdu7Ma5QrN+rq4E7jTHve+/vroRqxxYJ/ANIAx4CZgDR9v4QY0x9d8RmP/9ErGHgfwDigdkicpwxZm535gv7fbsU+F+sXLZIROZ3RTwB1TpoirGUA68ZY6YaYxYCn2H9YtHdSd42HatExKfA37B+iD8SkZjuis9+3u1YrayfYVUW7Vb2z7Ie2EGAxGXHVAt8ilWF9UNgGVCHVZm1O+OqA1zAu+4kLyKniUhYd8XlFVsV8Lr9N/kZ1nt2nb2/25K8bTqwxBjzCfAv4CBwm4gkGGNc3dW1ZH8w7wJOBW4HfohdBLKzBWyiF5HbROQREbkCwBjzlr3dARRhzbqN6ObYrrQ3LQNOEZFIY0weUA2EYLWouzKuWSJyktemZcaYMmPMi0CMiNxkH9elP3f7/XpRRH5sb/qqu+M6MiZjzOfGGKeIXIA103s48CcRuco+vkuSg1dc7gJ/zwMZIvKKiGwA7sDquvxRV8Z1RGw3Axhj/mVvD8H6UNwkIv27Kp7m4gK+BC4WkUT7A6kOKAHutOPusishEZktImd7bdpojCkwxrxnx3WZPaG0cxljAuofIMCvgaXALKwa9jcAqV7HnAxsDZDYZgPDgFeAD7F+yV7B6p64B3B0QVxpwFdADvCB+znteN1fnw9sAhK7+D27Aau43Xl2jHcDQ7z2d3lcTcR0DzDU3jcJGOYV22dAZjfFdR+QCMwEXgdG2D/TGcDHwIBufs8Ge+0fC3wHxHXz79e99t/DU8BHwBL77/FcrKKLMV0UVyJWfa9cYD0QYm930DBR9RRgIXDCEeeKv+MJuBa9sV7pNOA+Y8y7WIl1PF6LnxirBn62iFzSzbH9Bphgx/djrH7BJ4wxN2LV3h9kuqDrxlhXEf/Ceo9ygZ/Yu8TYl6rGmP9gfTDdIiJx7iulLnAW8KixurV+i9W3e61X7N0R15ExhbtjMsZ8axpqNm3BKrXt7IKYmoorAviJMeYD4BZjzFb7d3A9UIzVIuwqTb1nP3TvNMZswLqS/UEXxtRUXJHA9caYX2J1Df7R/nusBqJMM2XS/c0YUwQsAEZilWj/H699xv5/KbAWOF9ERriv4tz7/SmgEr3XpftK4DQA+wf4PTBaREbYx8UDW+nCX/RmYvuPHduJWC3CNcaYj+3jJgIrjnqgzovrKayicQuAC0Ukw07yDhp+zncCD2P13ffuorjWABcBGGNWAt8AfY8YCdElcbUQ03KgTxOjM27AusFYQCdqIa6lwCAROeWIBDUbiMLqwuxUrbxnfUXkVPs4wbr6ieyK7qRW3rNhInKaMWafMea/9nEXAjs7Oy47Nvfr/6cxphjrSuIyERlo/02GeMX/f1hXuV9hXYl0SndctyZ6u2/P88K8Wr87gDgRGWt//xWQAMTax5Vi3cRID5DY4ux/iMgFIvIt1qig97oqLmNMnTHGiXW/YCtwm3u/MaZerHkHz2F17ZxgjHmqE2Lz/D55vV9LAYeInG5/vxHrqqOPfc5QrD+ETomrDTHleMV0vVhrJA8Cfmqsfl6/aud7dbmIrAMG23FV+zuuNsaWgz3M2W6FpgEVndEibUdcve1zTheRr4DjsO53dIojYnO32Kvt/7/DWpDpf+3v6+2Enw48DXwBTDDGPOR9vj91S6IXkVNE5B/AfSKS5H5hXqMJvsW6XD5HREKNMZuBvoB3If4fGGPmBlBsJ9r7twO3GmMuty/fOjuukCNaAIex7hUMF5F+IpJiXwEdBn5hjLnMGJPjx7gmiYjnQ8Vru/t3aztWH/xVYg27y8b6gM6095f4O652xtQbK7GD1TVyizFmtjHmkD9i6kBc6V5xfY/1u3W9P+PqQGy9afg5AvzOGPNyAMTl/Z7tAX5mjLnUGOPXlaRaiE3k6IEFTwNDRWS0iKSKyCCsv8lfGmMuMcbk+jO2I3V5oheRwVgtuC+xWr1zxBrpgLGGk2GM2YHVRTIEa7w1QA3WDw37GL+3ZvwRmzFmuzFmdRfGVW+MMSISISIR9veLsX75N2LdjEo3xpR49T37K65fAfOxPnzOt7eF2HG5f/HL7BgisCYihWHdqCqwj8s3fhyr3sGYDtvHrTWN10IOlLg2GGO+8WdcfojN061lrGGqgRKX+z3bZ4zZ5M+4fIjN2C32KBFx90Lss4/fYMebaP+t7vN3bE0yXXiH3G6E/gB40/46CbgZq0shw972ENbwsUysUQYfYt3M+BudPIIlUGPzIa4/Aq9ijw4BbgXysCb/hHViXDOwxsNfjjVk8sj9DwLv2O9VBjAXq2/3b9ijEI6FmAI5rkCOLVDj8jG2B7CG6Y6zv78a2As81pl/k83G2+lPABcDvwAm298PxupXG2B/Pwp4BGt0zanAG9hD3ez9sUCvYyk2P8Q13fv7TowrxP4XCXwC3GZvd2ANt3uDxkMpHfh5+F0gxhTIcQVybIEal59im4w1Cs/vsfkUf6c9sPUJ+2+sy5T7sYaqnWvvewL4rdcbdh3WJ2CC9w/tWIvND3F1Viu5pbjcY4LPAtYBKU2c7/f3KxBjCuS4Ajm2QI3LT7F16pWFkCxgqAAABKJJREFUz6+jE9+gi4E7vL6/FXjP/noG1mXWSfb3ZwILu+IHF8ixBVFcPwHmH3GMA+uS+UH7+0n2/36f/BGoMQVyXIEcW6DGFeixteWfX2/G2sPSpopVmmAhVr+xWwHWqAGwxpevAf5s36wYDewVkWjonPo1gRpbkMZViNWy8Yx+sJ//IeBOESkBThDxb+GtQIwpkOMK5NgCNa5Aj629Oly90h7a1xurT8qFNSnhZuB2Y0yuiIQZa8RKBtbdcIwxB4G/ilXO92WskSTXG2MqOxpPMMTWw+JyF4kagjXVfCnwK2PNlOyRMQVyXIEcW6DGFeix+UUHL2vc9RuGYVWXBKv/+Cng/SOO+Tcw3f46zf4/lM67eRKQsfXAuJLc8QHTenpMgRxXIMcWqHEFemz++teuFr09XnQOECIin2DVfK4Ha1y3iNwO5IjIGcaYr8SqzpYPfC8i/wtcJCJTjTWhqKw9MQRbbD08rmnGqreT11NjCuS4Ajm2QI0r0GPztzb30YvIGVhjxxOxygHMwao5M01EJoGnz+oPWONcwRqCdANWf1cc1iei3+t0BGpsx0BchT05pkCOK5BjC9S4Aj22TtGOy5zTgOu8vn8W+CnWG7DK3ubA6u96G6smzSTgn1j1HDrt8iRQY9O4gjumQI4rkGML1LgCPbZOeb3teIOisaYbu/usrgUetr9ei1W7Aay6NG926YsJ0Ng0ruCOKZDjCuTYAjWuQI+tM/61uevGGFNpjKkxDcuFnY3VbwXWYhsjxVqUdx7WpVGXrYITqLFpXMEdUyDHFcixBWpcgR5bZ2j38Er7RobBqhT3ob25DGvlmTHAbmPMAej6VeEDNTaNK7hjCuS4Ajm2QI0r0GPzp45MmHIBYVhV4sbZn373Ay5jzNfuN6ebBGpsGldwxxTIcQVybIEaV6DH5j8d6ffBKtTjAr4GburufqhgiE3jCu6YAjmuQI4tUOMK9Nj89c9dlKddRKQfVnGtPxtjatr9QJ0gUGPTuHwXiDFB4MYFgRtboMYFgR2bv3Qo0SullAp8AbU4uFJKKf/TRK+UUj2cJnqllOrhNNErpVQPp4leKaV6OE30Sh1BRP4gIr9rYf9MERnVlTEp1RGa6JVqu5mAJnoVNHQcvVKAiNwLzMZaQGI/ViGrEuAWIByrZvl1wATgI3tfCXC5/RDPAKlAJXCzMWZrV8avVEs00atjnohMBOYCJ2EV+lsNPA+8YowpsI95CDhkjHlKROYCHxlj3rX3LQRuNcZsF5GTsMrdntn1r0SppnV4cXCleoDTgPnGXmhdRNxVDMfYCb4XEAt8duSJIhILnAy841XFNqLTI1aqDTTRK9W8ucBMY8w6EbkBmNrEMQ6g2BgzoQvjUqpN9GasUrAYmCkiUSISB1xsb48DckUkDGsFIrcyex/GmFJgt4hcAdbiFCIyvutCV6p1mujVMc8Ysxp4C1gH/Af4zt51P7ACWAp431x9E/i9iKwRkSFYHwI3icg6YBMwo6tiV8oXejNWKaV6OG3RK6VUD6eJXimlejhN9Eop1cNpoldKqR5OE71SSvVwmuiVUqqH00SvlFI93P8H/hBYcBJQuPwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_date_ppo.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "tXIRWMvFtUfK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_ppo.to_csv(\"PPO_account_value.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "q8jqPU1tWX3c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del df_account_value_ppo_arr ; del df_actions_ppo_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHafAuN290Uz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1ff982f303e5411aaa278b9f710f0c9c"
     ]
    },
    "id": "_EDwu_kO92JY",
    "outputId": "a5ad9ace-04bc-4f62-9e6b-de670bd12b61",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff982f303e5411aaa278b9f710f0c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All seeds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 100       |\n",
      "|    time_elapsed    | 32        |\n",
      "|    total_timesteps | 3296      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2e+04     |\n",
      "|    critic_loss     | 1.29e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 2472      |\n",
      "|    reward          | 57.319347 |\n",
      "----------------------------------\n",
      "day: 823, episode: 570\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 121691399.93\n",
      "total_reward: -8308600.07\n",
      "total_cost: 129870.13\n",
      "total_trades: 4938\n",
      "Sharpe: -0.034\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 88        |\n",
      "|    time_elapsed    | 74        |\n",
      "|    total_timesteps | 6592      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.32e+04  |\n",
      "|    critic_loss     | 4.23e+08  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 5768      |\n",
      "|    reward          | 57.319347 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 85        |\n",
      "|    time_elapsed    | 116       |\n",
      "|    total_timesteps | 9888      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.69e+04  |\n",
      "|    critic_loss     | 1.59e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 9064      |\n",
      "|    reward          | 57.319347 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 83        |\n",
      "|    time_elapsed    | 157       |\n",
      "|    total_timesteps | 13184     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.36e+04  |\n",
      "|    critic_loss     | 5.35e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 12360     |\n",
      "|    reward          | 57.319347 |\n",
      "----------------------------------\n",
      "day: 823, episode: 580\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 121691399.93\n",
      "total_reward: -8308600.07\n",
      "total_cost: 129870.13\n",
      "total_trades: 4938\n",
      "Sharpe: -0.034\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 82        |\n",
      "|    time_elapsed    | 198       |\n",
      "|    total_timesteps | 16480     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.1e+04   |\n",
      "|    critic_loss     | 2.54e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 15656     |\n",
      "|    reward          | 57.319347 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 82        |\n",
      "|    time_elapsed    | 239       |\n",
      "|    total_timesteps | 19776     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.74e+04  |\n",
      "|    critic_loss     | 6.51e+05  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 18952     |\n",
      "|    reward          | 57.319347 |\n",
      "----------------------------------\n",
      "day: 823, episode: 590\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 121691399.93\n",
      "total_reward: -8308600.07\n",
      "total_cost: 129870.13\n",
      "total_trades: 4938\n",
      "Sharpe: -0.034\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 82        |\n",
      "|    time_elapsed    | 280       |\n",
      "|    total_timesteps | 23072     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.51e+04  |\n",
      "|    critic_loss     | 1.24e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 22248     |\n",
      "|    reward          | 57.319347 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 81        |\n",
      "|    time_elapsed    | 321       |\n",
      "|    total_timesteps | 26368     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.31e+04  |\n",
      "|    critic_loss     | 1.27e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 25544     |\n",
      "|    reward          | 57.319347 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 81        |\n",
      "|    time_elapsed    | 362       |\n",
      "|    total_timesteps | 29664     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.04e+04  |\n",
      "|    critic_loss     | 1.78e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 28840     |\n",
      "|    reward          | 57.319347 |\n",
      "----------------------------------\n",
      "hit end!\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 99        |\n",
      "|    time_elapsed    | 33        |\n",
      "|    total_timesteps | 3296      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.67e+04  |\n",
      "|    critic_loss     | 1.42e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 2472      |\n",
      "|    reward          | -68.33019 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 89        |\n",
      "|    time_elapsed    | 73        |\n",
      "|    total_timesteps | 6592      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.95e+04  |\n",
      "|    critic_loss     | 7.73e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 5768      |\n",
      "|    reward          | -68.33019 |\n",
      "----------------------------------\n",
      "day: 823, episode: 610\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 121990554.57\n",
      "total_reward: -8009445.43\n",
      "total_cost: 179764.44\n",
      "total_trades: 3455\n",
      "Sharpe: 0.079\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 86        |\n",
      "|    time_elapsed    | 113       |\n",
      "|    total_timesteps | 9888      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.34e+04  |\n",
      "|    critic_loss     | 4.38e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 9064      |\n",
      "|    reward          | -68.33019 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 85        |\n",
      "|    time_elapsed    | 154       |\n",
      "|    total_timesteps | 13184     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.13e+04  |\n",
      "|    critic_loss     | 5.08e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 12360     |\n",
      "|    reward          | -68.33019 |\n",
      "----------------------------------\n",
      "day: 823, episode: 620\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 121990554.57\n",
      "total_reward: -8009445.43\n",
      "total_cost: 179764.44\n",
      "total_trades: 3455\n",
      "Sharpe: 0.079\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 84        |\n",
      "|    time_elapsed    | 194       |\n",
      "|    total_timesteps | 16480     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.56e+04  |\n",
      "|    critic_loss     | 2.22e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 15656     |\n",
      "|    reward          | -68.33019 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 83        |\n",
      "|    time_elapsed    | 235       |\n",
      "|    total_timesteps | 19776     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.9e+04   |\n",
      "|    critic_loss     | 2.05e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 18952     |\n",
      "|    reward          | -68.33019 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 83        |\n",
      "|    time_elapsed    | 276       |\n",
      "|    total_timesteps | 23072     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.32e+04  |\n",
      "|    critic_loss     | 1.45e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 22248     |\n",
      "|    reward          | -68.33019 |\n",
      "----------------------------------\n",
      "day: 823, episode: 630\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 121990554.57\n",
      "total_reward: -8009445.43\n",
      "total_cost: 179764.44\n",
      "total_trades: 3455\n",
      "Sharpe: 0.079\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 83        |\n",
      "|    time_elapsed    | 317       |\n",
      "|    total_timesteps | 26368     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.77e+04  |\n",
      "|    critic_loss     | 1.36e+07  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 25544     |\n",
      "|    reward          | -68.33019 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 82        |\n",
      "|    time_elapsed    | 358       |\n",
      "|    total_timesteps | 29664     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.36e+04  |\n",
      "|    critic_loss     | 9.77e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 28840     |\n",
      "|    reward          | -68.33019 |\n",
      "----------------------------------\n",
      "hit end!\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cuda device\n",
      "day: 823, episode: 640\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 125989730.06\n",
      "total_reward: -4010269.94\n",
      "total_cost: 149130.07\n",
      "total_trades: 5893\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 100      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 3296     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.1e+04  |\n",
      "|    critic_loss     | 3.43e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2472     |\n",
      "|    reward          | 9.40622  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 73       |\n",
      "|    total_timesteps | 6592     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.51e+04 |\n",
      "|    critic_loss     | 1.2e+08  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5768     |\n",
      "|    reward          | 9.40622  |\n",
      "---------------------------------\n",
      "day: 823, episode: 650\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 125989730.06\n",
      "total_reward: -4010269.94\n",
      "total_cost: 149130.07\n",
      "total_trades: 5893\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 9888     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.61e+04 |\n",
      "|    critic_loss     | 4.53e+07 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9064     |\n",
      "|    reward          | 9.40622  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 155      |\n",
      "|    total_timesteps | 13184    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.65e+04 |\n",
      "|    critic_loss     | 8.12e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12360    |\n",
      "|    reward          | 9.40622  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 196      |\n",
      "|    total_timesteps | 16480    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.35e+04 |\n",
      "|    critic_loss     | 4.57e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15656    |\n",
      "|    reward          | 9.40622  |\n",
      "---------------------------------\n",
      "day: 823, episode: 660\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 125989730.06\n",
      "total_reward: -4010269.94\n",
      "total_cost: 149130.07\n",
      "total_trades: 5893\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 237      |\n",
      "|    total_timesteps | 19776    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.16e+04 |\n",
      "|    critic_loss     | 4.11e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 18952    |\n",
      "|    reward          | 9.40622  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 82       |\n",
      "|    time_elapsed    | 278      |\n",
      "|    total_timesteps | 23072    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 8.52e+03 |\n",
      "|    critic_loss     | 3.67e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 22248    |\n",
      "|    reward          | 9.40622  |\n",
      "---------------------------------\n",
      "day: 823, episode: 670\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 125989730.06\n",
      "total_reward: -4010269.94\n",
      "total_cost: 149130.07\n",
      "total_trades: 5893\n",
      "Sharpe: 0.057\n",
      "=================================\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 82       |\n",
      "|    time_elapsed    | 318      |\n",
      "|    total_timesteps | 26368    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.38e+03 |\n",
      "|    critic_loss     | 2.35e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25544    |\n",
      "|    reward          | 9.40622  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 82       |\n",
      "|    time_elapsed    | 360      |\n",
      "|    total_timesteps | 29664    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.43e+03 |\n",
      "|    critic_loss     | 1.79e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 28840    |\n",
      "|    reward          | 9.40622  |\n",
      "---------------------------------\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "env_train.reset()\n",
    "df_account_value_td3_arr, df_actions_td3_arr = [], []\n",
    "\n",
    "for seed in tqdm(SEEDS, desc='All seeds', leave=True): # Looping from the given seeds\n",
    "\n",
    "  # Train\n",
    "  random.seed(seed); np.random.seed(seed) ; env_train.seed(seed)\n",
    "\n",
    "  agent = DRLAgent(env = env_train)\n",
    "  TD3_PARAMS = {\"batch_size\": 100, \n",
    "                \"buffer_size\": 1000000, \n",
    "                \"learning_rate\": 0.001}\n",
    "\n",
    "  model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "  trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=30000)\n",
    "\n",
    "  trained_td3.save('trained_td3.model') # save the model\n",
    "\n",
    "  # Prediction\n",
    "  df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_td3, \n",
    "    environment = e_trade_gym)\n",
    "  df_account_value_td3.shape\n",
    "  df_account_value_td3.tail()\n",
    "  df_account_value_td3_arr.append(df_account_value_td3)\n",
    "  df_actions_td3_arr.append(df_actions_td3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9z0fFfDHmo4I",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TD3 for trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IA4mARzdmKMx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_account_value_td3_con = pd.concat((df_account_value_td3_arr))\n",
    "df_actions_td3_con = pd.concat((df_actions_td3_arr))\n",
    "\n",
    "df_account_value_td3_con_idx = df_account_value_td3_con.groupby(df_account_value_td3_con.index)\n",
    "df_actions_td3_con_idx = df_actions_td3_con.groupby(df_actions_td3_con.index)\n",
    "\n",
    "df_account_value_means_td3 = df_account_value_td3_con_idx.mean()\n",
    "df_actions_means_td3 = df_actions_td3_con_idx.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "GHkSaT3GmKTU",
    "outputId": "c12972ec-8567-45a7-fc4e-c0ccc4908e42",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-92fbfbba-f065-4f40-84d8-4290ff9ec443\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>1.357942e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>1.364985e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>1.366720e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>1.369839e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>1.377747e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92fbfbba-f065-4f40-84d8-4290ff9ec443')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-92fbfbba-f065-4f40-84d8-4290ff9ec443 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-92fbfbba-f065-4f40-84d8-4290ff9ec443');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           date  account_value\n",
       "312  2021-10-25   1.357942e+08\n",
       "313  2021-10-26   1.364985e+08\n",
       "314  2021-10-27   1.366720e+08\n",
       "315  2021-10-28   1.369839e+08\n",
       "316  2021-10-29   1.377747e+08"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_means_td3['date'] = df_account_value_td3_arr[0]['date']\n",
    "df_account_value_means_td3 = df_account_value_means_td3[['date', 'account_value']]\n",
    "df_account_value_means_td3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "kwJjz7DEmKYj",
    "outputId": "48e79c8a-14c8-4318-d576-acab33344846",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b3a02b5b-c33f-4e33-9b0d-9d93ab57c72e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1301</th>\n",
       "      <th>1332</th>\n",
       "      <th>1333</th>\n",
       "      <th>1376</th>\n",
       "      <th>1377</th>\n",
       "      <th>1379</th>\n",
       "      <th>1407</th>\n",
       "      <th>1414</th>\n",
       "      <th>1417</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-07</th>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-08</th>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows × 9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3a02b5b-c33f-4e33-9b0d-9d93ab57c72e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b3a02b5b-c33f-4e33-9b0d-9d93ab57c72e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b3a02b5b-c33f-4e33-9b0d-9d93ab57c72e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "             1301       1332   1333       1376   1377       1379  1407  \\\n",
       "date                                                                     \n",
       "2020-07-01  100.0  66.666667  100.0  66.666667  100.0  66.666667   0.0   \n",
       "2020-07-02  100.0  66.666667  100.0  66.666667  100.0  66.666667   0.0   \n",
       "2020-07-06  100.0  66.666667  100.0  66.666667  100.0  66.666667   0.0   \n",
       "2020-07-07  100.0  66.666667  100.0  66.666667  100.0  66.666667   0.0   \n",
       "2020-07-08  100.0  66.666667  100.0  66.666667  100.0  66.666667   0.0   \n",
       "...           ...        ...    ...        ...    ...        ...   ...   \n",
       "2021-10-22    0.0   0.000000    0.0   0.000000    0.0   0.000000   0.0   \n",
       "2021-10-25    0.0   0.000000    0.0   0.000000    0.0   0.000000   0.0   \n",
       "2021-10-26    0.0   0.000000    0.0   0.000000    0.0   0.000000   0.0   \n",
       "2021-10-27    0.0   0.000000    0.0   0.000000    0.0   0.000000   0.0   \n",
       "2021-10-28    0.0   0.000000    0.0   0.000000    0.0   0.000000   0.0   \n",
       "\n",
       "                 1414       1417  \n",
       "date                              \n",
       "2020-07-01  66.666667  66.666667  \n",
       "2020-07-02  66.666667  66.666667  \n",
       "2020-07-06  66.666667  66.666667  \n",
       "2020-07-07  66.666667  66.666667  \n",
       "2020-07-08  66.666667  66.666667  \n",
       "...               ...        ...  \n",
       "2021-10-22   0.000000   0.000000  \n",
       "2021-10-25   0.000000   0.000000  \n",
       "2021-10-26   0.000000   0.000000  \n",
       "2021-10-27   0.000000   0.000000  \n",
       "2021-10-28   0.000000   0.000000  \n",
       "\n",
       "[316 rows x 9 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions_means_td3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-IUncw1tr7_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## BackTestStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ULkI0zu3twRb",
    "outputId": "667854f3-2e1d-46d8-ae35-24ce87feeddb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.047258\n",
      "Cumulative returns     0.059805\n",
      "Annual volatility      0.424169\n",
      "Sharpe ratio           0.312491\n",
      "Calmar ratio           0.167826\n",
      "Stability              0.365353\n",
      "Max drawdown          -0.281588\n",
      "Omega ratio            1.144162\n",
      "Sortino ratio          0.516690\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.911668\n",
      "Daily value at risk   -0.052914\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all_td3 = backtest_stats(account_value=df_account_value_means_td3)\n",
    "perf_stats_all_td3 = pd.DataFrame(perf_stats_all_td3)\n",
    "perf_stats_all_td3.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "C5KtIxp0twU4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_td3 = df_account_value_means_td3.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8CyLoRd0twX4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_td3.index = pd.to_datetime(df_date_td3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZIT_WZxgtwaa",
    "outputId": "d8515a3a-6065-4234-ef9a-e122c7f570e2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f160bef1850>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_date_td3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hIuA5JudtwfO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_td3.to_csv(\"TD3_account_value.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OPOhOe-ZX0R6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del df_account_value_td3_arr ; del df_actions_td3_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oY0ou--D9-n2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b01b5a4a28de467ba2a44d47483487b1"
     ]
    },
    "id": "iXkKHcTJ-BbV",
    "outputId": "dc529df8-98e4-4187-fbe9-fcb8b6511550",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01b5a4a28de467ba2a44d47483487b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All seeds:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n",
      "day: 823, episode: 680\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123611444.69\n",
      "total_reward: -6388555.31\n",
      "total_cost: 129870.13\n",
      "total_trades: 3753\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 51         |\n",
      "|    time_elapsed    | 64         |\n",
      "|    total_timesteps | 3296       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.13e+05   |\n",
      "|    critic_loss     | 5.02e+06   |\n",
      "|    ent_coef        | 0.135      |\n",
      "|    ent_coef_loss   | 287        |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 3195       |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 130        |\n",
      "|    total_timesteps | 6592       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.42e+05   |\n",
      "|    critic_loss     | 4.34e+07   |\n",
      "|    ent_coef        | 0.188      |\n",
      "|    ent_coef_loss   | 242        |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 6491       |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 196        |\n",
      "|    total_timesteps | 9888       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.35e+05   |\n",
      "|    critic_loss     | 6.74e+06   |\n",
      "|    ent_coef        | 0.261      |\n",
      "|    ent_coef_loss   | 200        |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 9787       |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 690\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123611444.69\n",
      "total_reward: -6388555.31\n",
      "total_cost: 129870.13\n",
      "total_trades: 3753\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 261        |\n",
      "|    total_timesteps | 13184      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 8.11e+04   |\n",
      "|    critic_loss     | 2.56e+06   |\n",
      "|    ent_coef        | 0.362      |\n",
      "|    ent_coef_loss   | 144        |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 13083      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 20         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 327        |\n",
      "|    total_timesteps | 16480      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 5.19e+04   |\n",
      "|    critic_loss     | 3.19e+07   |\n",
      "|    ent_coef        | 0.504      |\n",
      "|    ent_coef_loss   | 98         |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 16379      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 700\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123611444.69\n",
      "total_reward: -6388555.31\n",
      "total_cost: 129870.13\n",
      "total_trades: 3753\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 24         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 392        |\n",
      "|    total_timesteps | 19776      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 6.14e+04   |\n",
      "|    critic_loss     | 8.83e+07   |\n",
      "|    ent_coef        | 0.7        |\n",
      "|    ent_coef_loss   | 52.1       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 19675      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 28         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 458        |\n",
      "|    total_timesteps | 23072      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.51e+04   |\n",
      "|    critic_loss     | 1.99e+05   |\n",
      "|    ent_coef        | 0.974      |\n",
      "|    ent_coef_loss   | 3.89       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 22971      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 32         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 524        |\n",
      "|    total_timesteps | 26368      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.87e+04   |\n",
      "|    critic_loss     | 5.5e+05    |\n",
      "|    ent_coef        | 1.35       |\n",
      "|    ent_coef_loss   | -44.1      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 26267      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 710\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123611444.69\n",
      "total_reward: -6388555.31\n",
      "total_cost: 129870.13\n",
      "total_trades: 3753\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 36         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 591        |\n",
      "|    total_timesteps | 29664      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.57e+04   |\n",
      "|    critic_loss     | 6.49e+05   |\n",
      "|    ent_coef        | 1.88       |\n",
      "|    ent_coef_loss   | -91.1      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 29563      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 40         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 657        |\n",
      "|    total_timesteps | 32960      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.84e+04   |\n",
      "|    critic_loss     | 4.54e+07   |\n",
      "|    ent_coef        | 2.62       |\n",
      "|    ent_coef_loss   | -139       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 32859      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 720\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123611444.69\n",
      "total_reward: -6388555.31\n",
      "total_cost: 129870.13\n",
      "total_trades: 3753\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 44         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 722        |\n",
      "|    total_timesteps | 36256      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.07e+04   |\n",
      "|    critic_loss     | 2.04e+06   |\n",
      "|    ent_coef        | 3.64       |\n",
      "|    ent_coef_loss   | -188       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 36155      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 48         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 788        |\n",
      "|    total_timesteps | 39552      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.33e+04   |\n",
      "|    critic_loss     | 5.82e+05   |\n",
      "|    ent_coef        | 5.06       |\n",
      "|    ent_coef_loss   | -232       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 39451      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 52         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 853        |\n",
      "|    total_timesteps | 42848      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 4.32e+04   |\n",
      "|    critic_loss     | 3.17e+05   |\n",
      "|    ent_coef        | 7.03       |\n",
      "|    ent_coef_loss   | -288       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 42747      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 730\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123611444.69\n",
      "total_reward: -6388555.31\n",
      "total_cost: 129870.13\n",
      "total_trades: 3753\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 56         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 919        |\n",
      "|    total_timesteps | 46144      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 5.59e+04   |\n",
      "|    critic_loss     | 3.52e+05   |\n",
      "|    ent_coef        | 9.78       |\n",
      "|    ent_coef_loss   | -329       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 46043      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 60         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 985        |\n",
      "|    total_timesteps | 49440      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 7.35e+04   |\n",
      "|    critic_loss     | 1.57e+06   |\n",
      "|    ent_coef        | 13.6       |\n",
      "|    ent_coef_loss   | -369       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 49339      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 740\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123611444.69\n",
      "total_reward: -6388555.31\n",
      "total_cost: 129870.13\n",
      "total_trades: 3753\n",
      "Sharpe: 0.138\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 64         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 1051       |\n",
      "|    total_timesteps | 52736      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.03e+05   |\n",
      "|    critic_loss     | 2.73e+06   |\n",
      "|    ent_coef        | 18.9       |\n",
      "|    ent_coef_loss   | -423       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 52635      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 68         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 1117       |\n",
      "|    total_timesteps | 56032      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.43e+05   |\n",
      "|    critic_loss     | 3.89e+07   |\n",
      "|    ent_coef        | 26.3       |\n",
      "|    ent_coef_loss   | -473       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 55931      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 72         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 1184       |\n",
      "|    total_timesteps | 59328      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.91e+05   |\n",
      "|    critic_loss     | 2.62e+06   |\n",
      "|    ent_coef        | 36.5       |\n",
      "|    ent_coef_loss   | -513       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 59227      |\n",
      "|    reward          | -54.022785 |\n",
      "-----------------------------------\n",
      "hit end!\n",
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 50        |\n",
      "|    time_elapsed    | 64        |\n",
      "|    total_timesteps | 3296      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.5e+04   |\n",
      "|    critic_loss     | 1.71e+06  |\n",
      "|    ent_coef        | 0.134     |\n",
      "|    ent_coef_loss   | 274       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 3195      |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 50        |\n",
      "|    time_elapsed    | 130       |\n",
      "|    total_timesteps | 6592      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.69e+04  |\n",
      "|    critic_loss     | 4.54e+06  |\n",
      "|    ent_coef        | 0.186     |\n",
      "|    ent_coef_loss   | 228       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 6491      |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "day: 823, episode: 760\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123088024.27\n",
      "total_reward: -6911975.73\n",
      "total_cost: 204433.97\n",
      "total_trades: 3587\n",
      "Sharpe: 0.097\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 197       |\n",
      "|    total_timesteps | 9888      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.02e+04  |\n",
      "|    critic_loss     | 3.29e+06  |\n",
      "|    ent_coef        | 0.258     |\n",
      "|    ent_coef_loss   | 185       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 9787      |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 264       |\n",
      "|    total_timesteps | 13184     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.74e+04  |\n",
      "|    critic_loss     | 1.77e+06  |\n",
      "|    ent_coef        | 0.359     |\n",
      "|    ent_coef_loss   | 138       |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 13083     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "day: 823, episode: 770\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123088024.27\n",
      "total_reward: -6911975.73\n",
      "total_cost: 204433.97\n",
      "total_trades: 3587\n",
      "Sharpe: 0.097\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 331       |\n",
      "|    total_timesteps | 16480     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.07e+04  |\n",
      "|    critic_loss     | 4.59e+07  |\n",
      "|    ent_coef        | 0.499     |\n",
      "|    ent_coef_loss   | 92.5      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 16379     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 397       |\n",
      "|    total_timesteps | 19776     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.44e+04  |\n",
      "|    critic_loss     | 4.05e+06  |\n",
      "|    ent_coef        | 0.693     |\n",
      "|    ent_coef_loss   | 50.2      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 19675     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 463       |\n",
      "|    total_timesteps | 23072     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.2e+04   |\n",
      "|    critic_loss     | 1.65e+05  |\n",
      "|    ent_coef        | 0.964     |\n",
      "|    ent_coef_loss   | 4.95      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 22971     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "day: 823, episode: 780\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123088024.27\n",
      "total_reward: -6911975.73\n",
      "total_cost: 204433.97\n",
      "total_trades: 3587\n",
      "Sharpe: 0.097\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 530       |\n",
      "|    total_timesteps | 26368     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 9.06e+03  |\n",
      "|    critic_loss     | 3.62e+05  |\n",
      "|    ent_coef        | 1.34      |\n",
      "|    ent_coef_loss   | -38.8     |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 26267     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 596       |\n",
      "|    total_timesteps | 29664     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.08e+04  |\n",
      "|    critic_loss     | 1.92e+08  |\n",
      "|    ent_coef        | 1.86      |\n",
      "|    ent_coef_loss   | -83.4     |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 29563     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "day: 823, episode: 790\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123088024.27\n",
      "total_reward: -6911975.73\n",
      "total_cost: 204433.97\n",
      "total_trades: 3587\n",
      "Sharpe: 0.097\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 40        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 661       |\n",
      "|    total_timesteps | 32960     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.63e+04  |\n",
      "|    critic_loss     | 1.42e+05  |\n",
      "|    ent_coef        | 2.59      |\n",
      "|    ent_coef_loss   | -130      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 32859     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 44        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 726       |\n",
      "|    total_timesteps | 36256     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.04e+04  |\n",
      "|    critic_loss     | 8.11e+04  |\n",
      "|    ent_coef        | 3.6       |\n",
      "|    ent_coef_loss   | -173      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 36155     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 48        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 792       |\n",
      "|    total_timesteps | 39552     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.63e+04  |\n",
      "|    critic_loss     | 3.76e+06  |\n",
      "|    ent_coef        | 5.01      |\n",
      "|    ent_coef_loss   | -217      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 39451     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "day: 823, episode: 800\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123088024.27\n",
      "total_reward: -6911975.73\n",
      "total_cost: 204433.97\n",
      "total_trades: 3587\n",
      "Sharpe: 0.097\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 52        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 858       |\n",
      "|    total_timesteps | 42848     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.54e+04  |\n",
      "|    critic_loss     | 1.33e+05  |\n",
      "|    ent_coef        | 6.96      |\n",
      "|    ent_coef_loss   | -266      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 42747     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 56        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 923       |\n",
      "|    total_timesteps | 46144     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.84e+04  |\n",
      "|    critic_loss     | 1.26e+05  |\n",
      "|    ent_coef        | 9.68      |\n",
      "|    ent_coef_loss   | -302      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 46043     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "day: 823, episode: 810\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123088024.27\n",
      "total_reward: -6911975.73\n",
      "total_cost: 204433.97\n",
      "total_trades: 3587\n",
      "Sharpe: 0.097\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 60        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 990       |\n",
      "|    total_timesteps | 49440     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 6.7e+04   |\n",
      "|    critic_loss     | 3.44e+05  |\n",
      "|    ent_coef        | 13.5      |\n",
      "|    ent_coef_loss   | -349      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 49339     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 64        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 1055      |\n",
      "|    total_timesteps | 52736     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 8.79e+04  |\n",
      "|    critic_loss     | 7.08e+05  |\n",
      "|    ent_coef        | 18.7      |\n",
      "|    ent_coef_loss   | -399      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 52635     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 68        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 1121      |\n",
      "|    total_timesteps | 56032     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.26e+05  |\n",
      "|    critic_loss     | 1.1e+08   |\n",
      "|    ent_coef        | 26        |\n",
      "|    ent_coef_loss   | -444      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 55931     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "day: 823, episode: 820\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 123088024.27\n",
      "total_reward: -6911975.73\n",
      "total_cost: 204433.97\n",
      "total_trades: 3587\n",
      "Sharpe: 0.097\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 72        |\n",
      "|    fps             | 49        |\n",
      "|    time_elapsed    | 1187      |\n",
      "|    total_timesteps | 59328     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.72e+05  |\n",
      "|    critic_loss     | 4.51e+06  |\n",
      "|    ent_coef        | 36.2      |\n",
      "|    ent_coef_loss   | -492      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 59227     |\n",
      "|    reward          | -67.93814 |\n",
      "----------------------------------\n",
      "hit end!\n",
      "{'batch_size': 128, 'buffer_size': 1000000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cuda device\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 51         |\n",
      "|    time_elapsed    | 63         |\n",
      "|    total_timesteps | 3296       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.19e+05   |\n",
      "|    critic_loss     | 5.99e+06   |\n",
      "|    ent_coef        | 0.135      |\n",
      "|    ent_coef_loss   | 214        |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 3195       |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 830\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 129450852.39\n",
      "total_reward: -549147.61\n",
      "total_cost: 129870.13\n",
      "total_trades: 3292\n",
      "Sharpe: 0.132\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 129        |\n",
      "|    total_timesteps | 6592       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.06e+05   |\n",
      "|    critic_loss     | 3.65e+06   |\n",
      "|    ent_coef        | 0.187      |\n",
      "|    ent_coef_loss   | 180        |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 6491       |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 196        |\n",
      "|    total_timesteps | 9888       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 5.56e+04   |\n",
      "|    critic_loss     | 9.1e+06    |\n",
      "|    ent_coef        | 0.26       |\n",
      "|    ent_coef_loss   | 144        |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 9787       |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 16         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 263        |\n",
      "|    total_timesteps | 13184      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 4.06e+04   |\n",
      "|    critic_loss     | 4.8e+06    |\n",
      "|    ent_coef        | 0.361      |\n",
      "|    ent_coef_loss   | 109        |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 13083      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 840\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 129450852.39\n",
      "total_reward: -549147.61\n",
      "total_cost: 129870.13\n",
      "total_trades: 3292\n",
      "Sharpe: 0.132\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 20         |\n",
      "|    fps             | 49         |\n",
      "|    time_elapsed    | 329        |\n",
      "|    total_timesteps | 16480      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.47e+04   |\n",
      "|    critic_loss     | 1.33e+07   |\n",
      "|    ent_coef        | 0.502      |\n",
      "|    ent_coef_loss   | 73.6       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 16379      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 24         |\n",
      "|    fps             | 49         |\n",
      "|    time_elapsed    | 395        |\n",
      "|    total_timesteps | 19776      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.96e+04   |\n",
      "|    critic_loss     | 8.32e+05   |\n",
      "|    ent_coef        | 0.698      |\n",
      "|    ent_coef_loss   | 38.4       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 19675      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 850\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 129450852.39\n",
      "total_reward: -549147.61\n",
      "total_cost: 129870.13\n",
      "total_trades: 3292\n",
      "Sharpe: 0.132\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 28         |\n",
      "|    fps             | 49         |\n",
      "|    time_elapsed    | 462        |\n",
      "|    total_timesteps | 23072      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.8e+04    |\n",
      "|    critic_loss     | 3.1e+06    |\n",
      "|    ent_coef        | 0.971      |\n",
      "|    ent_coef_loss   | 3.14       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 22971      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 32         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 526        |\n",
      "|    total_timesteps | 26368      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.02e+04   |\n",
      "|    critic_loss     | 2.67e+06   |\n",
      "|    ent_coef        | 1.35       |\n",
      "|    ent_coef_loss   | -32.2      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 26267      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 36         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 591        |\n",
      "|    total_timesteps | 29664      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.26e+04   |\n",
      "|    critic_loss     | 5.83e+06   |\n",
      "|    ent_coef        | 1.88       |\n",
      "|    ent_coef_loss   | -67.4      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 29563      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 860\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 129450852.39\n",
      "total_reward: -549147.61\n",
      "total_cost: 129870.13\n",
      "total_trades: 3292\n",
      "Sharpe: 0.132\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 40         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 656        |\n",
      "|    total_timesteps | 32960      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.34e+04   |\n",
      "|    critic_loss     | 6.48e+05   |\n",
      "|    ent_coef        | 2.61       |\n",
      "|    ent_coef_loss   | -103       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 32859      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 44         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 721        |\n",
      "|    total_timesteps | 36256      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.67e+04   |\n",
      "|    critic_loss     | 2.21e+05   |\n",
      "|    ent_coef        | 3.63       |\n",
      "|    ent_coef_loss   | -138       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 36155      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 870\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 129450852.39\n",
      "total_reward: -549147.61\n",
      "total_cost: 129870.13\n",
      "total_trades: 3292\n",
      "Sharpe: 0.132\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 48         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 786        |\n",
      "|    total_timesteps | 39552      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.2e+04    |\n",
      "|    critic_loss     | 1e+06      |\n",
      "|    ent_coef        | 5.05       |\n",
      "|    ent_coef_loss   | -173       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 39451      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 52         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 852        |\n",
      "|    total_timesteps | 42848      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 3.03e+04   |\n",
      "|    critic_loss     | 9.94e+05   |\n",
      "|    ent_coef        | 7.02       |\n",
      "|    ent_coef_loss   | -209       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 42747      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 56         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 918        |\n",
      "|    total_timesteps | 46144      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 4.04e+04   |\n",
      "|    critic_loss     | 1.55e+05   |\n",
      "|    ent_coef        | 9.76       |\n",
      "|    ent_coef_loss   | -244       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 46043      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 880\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 129450852.39\n",
      "total_reward: -549147.61\n",
      "total_cost: 129870.13\n",
      "total_trades: 3292\n",
      "Sharpe: 0.132\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 60         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 984        |\n",
      "|    total_timesteps | 49440      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 5.5e+04    |\n",
      "|    critic_loss     | 4.08e+05   |\n",
      "|    ent_coef        | 13.6       |\n",
      "|    ent_coef_loss   | -280       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 49339      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 64         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 1050       |\n",
      "|    total_timesteps | 52736      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 7.56e+04   |\n",
      "|    critic_loss     | 2.41e+05   |\n",
      "|    ent_coef        | 18.9       |\n",
      "|    ent_coef_loss   | -315       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 52635      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "day: 823, episode: 890\n",
      "begin_total_asset: 130000000.00\n",
      "end_total_asset: 129450852.39\n",
      "total_reward: -549147.61\n",
      "total_cost: 129870.13\n",
      "total_trades: 3292\n",
      "Sharpe: 0.132\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 68         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 1116       |\n",
      "|    total_timesteps | 56032      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.02e+05   |\n",
      "|    critic_loss     | 1.15e+06   |\n",
      "|    ent_coef        | 26.2       |\n",
      "|    ent_coef_loss   | -350       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 55931      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 72         |\n",
      "|    fps             | 50         |\n",
      "|    time_elapsed    | 1182       |\n",
      "|    total_timesteps | 59328      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.4e+05    |\n",
      "|    critic_loss     | 8.04e+06   |\n",
      "|    ent_coef        | 36.4       |\n",
      "|    ent_coef_loss   | -385       |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 59227      |\n",
      "|    reward          | -57.210423 |\n",
      "-----------------------------------\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "env_train.reset()\n",
    "df_account_value_sac_arr, df_actions_sac_arr = [], []\n",
    "\n",
    "for seed in tqdm(SEEDS, desc='All seeds', leave=True): # Looping from the given seeds\n",
    "\n",
    "  # Train\n",
    "  random.seed(seed); np.random.seed(seed) ; env_train.seed(seed)\n",
    "  agent = DRLAgent(env = env_train)\n",
    "  SAC_PARAMS = {\n",
    "      \"batch_size\": 128,\n",
    "      \"buffer_size\": 1000000,\n",
    "      \"learning_rate\": 0.0001,\n",
    "      \"learning_starts\": 100,\n",
    "      \"ent_coef\": \"auto_0.1\",\n",
    "  }\n",
    "\n",
    "  model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "  trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=60000)\n",
    "\n",
    "  trained_sac.save('trained_sac.model') # save the model\n",
    "\n",
    "  # Prediction\n",
    "  df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_sac, \n",
    "    environment = e_trade_gym)\n",
    "  df_account_value_sac.shape\n",
    "  df_account_value_sac.tail()\n",
    "  df_actions_sac.head()\n",
    "  df_account_value_sac_arr.append(df_account_value_sac)\n",
    "  df_actions_sac_arr.append(df_actions_sac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RdZVslfmAAv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SAC for trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XKHuroJR-2Hz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_account_value_sac_con = pd.concat((df_account_value_sac_arr))\n",
    "df_actions_sac_con = pd.concat((df_actions_sac_arr))\n",
    "\n",
    "df_account_value_sac_con_idx = df_account_value_sac_con.groupby(df_account_value_sac_con.index)\n",
    "df_actions_sac_con_idx = df_actions_sac_con.groupby(df_actions_sac_con.index)\n",
    "\n",
    "df_account_value_means_sac = df_account_value_sac_con_idx.mean()\n",
    "df_actions_means_sac = df_actions_sac_con_idx.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gjhtMOmw-3eC",
    "outputId": "0a4404e4-2805-458a-a8bd-d097115e0824",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-18f7a7b9-cbd4-4d41-90b0-01ad756f2c15\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>1.437009e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2021-10-26</td>\n",
       "      <td>1.451156e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>1.445124e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2021-10-28</td>\n",
       "      <td>1.458852e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>1.469682e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18f7a7b9-cbd4-4d41-90b0-01ad756f2c15')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-18f7a7b9-cbd4-4d41-90b0-01ad756f2c15 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-18f7a7b9-cbd4-4d41-90b0-01ad756f2c15');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           date  account_value\n",
       "312  2021-10-25   1.437009e+08\n",
       "313  2021-10-26   1.451156e+08\n",
       "314  2021-10-27   1.445124e+08\n",
       "315  2021-10-28   1.458852e+08\n",
       "316  2021-10-29   1.469682e+08"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_means_sac['date'] = df_account_value_sac_arr[0]['date']\n",
    "df_account_value_means_sac = df_account_value_means_sac[['date', 'account_value']]\n",
    "df_account_value_means_sac.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8E-TblGw-4dS",
    "outputId": "de40707f-4f98-41d8-b08a-a7d02f2fcd85",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cb7495fd-8204-4bd9-bdb3-a1ac736534f8\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1301</th>\n",
       "      <th>1332</th>\n",
       "      <th>1333</th>\n",
       "      <th>1376</th>\n",
       "      <th>1377</th>\n",
       "      <th>1379</th>\n",
       "      <th>1407</th>\n",
       "      <th>1414</th>\n",
       "      <th>1417</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-07</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-08</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows × 9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb7495fd-8204-4bd9-bdb3-a1ac736534f8')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-cb7495fd-8204-4bd9-bdb3-a1ac736534f8 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-cb7495fd-8204-4bd9-bdb3-a1ac736534f8');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                 1301       1332       1333       1376  1377       1379  \\\n",
       "date                                                                      \n",
       "2020-07-01  33.333333  66.666667  66.666667  33.333333   0.0  33.333333   \n",
       "2020-07-02  33.333333  66.666667  66.666667  33.333333   0.0  33.333333   \n",
       "2020-07-06  33.333333  66.666667  66.666667  33.333333   0.0  33.333333   \n",
       "2020-07-07  33.333333  66.666667  66.666667  33.333333   0.0  33.333333   \n",
       "2020-07-08  33.333333  66.666667  66.666667  33.333333   0.0  33.333333   \n",
       "...               ...        ...        ...        ...   ...        ...   \n",
       "2021-10-22   0.000000   0.000000   0.000000   0.000000   0.0   0.000000   \n",
       "2021-10-25   0.000000   0.000000   0.000000   0.000000   0.0   0.000000   \n",
       "2021-10-26   0.000000   0.000000   0.000000   0.000000   0.0   0.000000   \n",
       "2021-10-27   0.000000   0.000000   0.000000   0.000000   0.0   0.000000   \n",
       "2021-10-28   0.000000   0.000000   0.000000   0.000000   0.0   0.000000   \n",
       "\n",
       "                 1407   1414       1417  \n",
       "date                                     \n",
       "2020-07-01  33.333333  100.0  33.333333  \n",
       "2020-07-02  33.333333  100.0  33.333333  \n",
       "2020-07-06  33.333333  100.0  33.333333  \n",
       "2020-07-07  33.333333  100.0  33.333333  \n",
       "2020-07-08  33.333333  100.0  33.333333  \n",
       "...               ...    ...        ...  \n",
       "2021-10-22   0.000000    0.0   0.000000  \n",
       "2021-10-25   0.000000    0.0   0.000000  \n",
       "2021-10-26   0.000000    0.0   0.000000  \n",
       "2021-10-27   0.000000    0.0   0.000000  \n",
       "2021-10-28   0.000000    0.0   0.000000  \n",
       "\n",
       "[316 rows x 9 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions_means_sac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zvFeM83uPD_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## BackTestStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "J8I-WqHkuRLo",
    "outputId": "7c6d00d4-221e-419c-9e08-9125d39c3c3e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.102440\n",
      "Cumulative returns     0.130525\n",
      "Annual volatility      0.301843\n",
      "Sharpe ratio           0.472800\n",
      "Calmar ratio           0.508679\n",
      "Stability              0.395904\n",
      "Max drawdown          -0.201386\n",
      "Omega ratio            1.163815\n",
      "Sortino ratio          0.731495\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.936273\n",
      "Daily value at risk   -0.037462\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all_sac = backtest_stats(account_value=df_account_value_means_sac)\n",
    "perf_stats_all_sac = pd.DataFrame(perf_stats_all_sac)\n",
    "perf_stats_all_sac.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xS9x8LnquRQb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_sac = df_account_value_means_sac.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "SOwO62LCuRUX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_sac.index = pd.to_datetime(df_date_sac.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "X2Bi74JkuRYU",
    "outputId": "91d55699-dbd3-4588-e767-ae2ffd92dd75",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f160bbcc410>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_date_sac.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "PDpOZGuAuRkh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_date_sac.to_csv(\"SAC_account_value.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "V5uEQoqdZN_P",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "del df_account_value_sac_arr ; del df_actions_sac_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gLXy-VMr4O4q",
    "outputId": "93482e7e-abd7-426e-ac60-8419a610818f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f160c5c6d90>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_date_a2c = df_date_a2c.rename(columns={'account_value': 'a2c'})\n",
    "df_date_ddpg = df_date_ddpg.rename(columns={'account_value': 'ddpg'})\n",
    "df_date_ppo = df_date_ppo.rename(columns={'account_value': 'ppo'})\n",
    "df_date_td3 = df_date_td3.rename(columns={'account_value': 'td3'})\n",
    "df_date_sac = df_date_sac.rename(columns={'account_value': 'sac'})\n",
    "\n",
    "ax = df_date_a2c.plot()\n",
    "df_date_ddpg.plot(ax=ax)\n",
    "df_date_ppo.plot(ax=ax)\n",
    "df_date_td3.plot(ax=ax)\n",
    "df_date_sac.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "C-IhFEGCsHOf",
    "outputId": "d7a2a215-e2ba-4883-a5ad-5fa0216dfd08",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat 'SAC_account_value.csv.gz': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cp a2c_account_value.csv.gz \"/content/drive/My Drive\"\n",
    "!cp ddpg_account_value.csv.gz \"/content/drive/My Drive\"\n",
    "!cp PPO_account_value.csv.gz \"/content/drive/My Drive\"\n",
    "!cp TD3_account_value.csv.gz \"/content/drive/My Drive\"\n",
    "!cp SAC_account_value.csv.gz \"/content/drive/My Drive\"\n",
    "!cp trained_a2c.model \"/content/drive/My Drive\"\n",
    "!cp trained_ddpg.model \"/content/drive/My Drive\"\n",
    "!cp trained_ppo.model \"/content/drive/My Drive\"\n",
    "!cp trained_td3.model \"/content/drive/My Drive\"\n",
    "!cp trained_sac.model \"/content/drive/My Drive\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CS295RLMP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08b9083a117e4c2389e58207a2a48c0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09565454f532499cbf10b68b997a9f06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "097d0ebcdb6b45d6ba515cee27ca9a06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53d015f578a0426e89f5fdefd2845748",
      "placeholder": "​",
      "style": "IPY_MODEL_c9b89d31a2bf40c3b6c369537e98cf83",
      "value": " 0/3 [00:00&lt;?, ?it/s]"
     }
    },
    "0a801025efaa41b481ee9a29918c5c9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0ac2d6ddf14e4193998c7d2d79501a7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5178d683afe844c9b0bcbab6b80876da",
       "IPY_MODEL_7fda54a53c7c4cd0b438eacd7a44ecb7",
       "IPY_MODEL_097d0ebcdb6b45d6ba515cee27ca9a06"
      ],
      "layout": "IPY_MODEL_c8504cef76dd45bb9555245207a463c7"
     }
    },
    "5178d683afe844c9b0bcbab6b80876da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08b9083a117e4c2389e58207a2a48c0b",
      "placeholder": "​",
      "style": "IPY_MODEL_09565454f532499cbf10b68b997a9f06",
      "value": "All seeds:   0%"
     }
    },
    "53d015f578a0426e89f5fdefd2845748": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6550d0095c1343289ef5575b1f414ea4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fda54a53c7c4cd0b438eacd7a44ecb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6550d0095c1343289ef5575b1f414ea4",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0a801025efaa41b481ee9a29918c5c9b",
      "value": 0
     }
    },
    "c8504cef76dd45bb9555245207a463c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9b89d31a2bf40c3b6c369537e98cf83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}